{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T05:35:43.956217Z",
     "start_time": "2022-04-02T05:35:43.942214Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "datadirs = ''\n",
    "sys.path.insert(1, datadirs)\n",
    "savepath = datadirs+'save/'\n",
    "datapath = datadirs+'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T05:35:51.293751Z",
     "start_time": "2022-04-02T05:35:44.534204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T05:35:51.674706Z",
     "start_time": "2022-04-02T05:35:51.294751Z"
    }
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "# python -m visdom.server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T05:35:51.690709Z",
     "start_time": "2022-04-02T05:35:51.675707Z"
    }
   },
   "outputs": [],
   "source": [
    "from pars import PARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T05:36:15.512072Z",
     "start_time": "2022-04-02T05:36:09.701539Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from setup_net import *\n",
    "from loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-30T15:31:17.419660Z",
     "start_time": "2022-03-30T15:31:17.404101Z"
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T05:36:15.527075Z",
     "start_time": "2022-04-02T05:36:15.513072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture: CONV6\n",
      "nonlinear: hardtanh\n",
      "batch_size: 500\n",
      "headsize: 64\n",
      "dataset: Cifar100\n",
      "loss: SimCLR\n",
      "OPT: Adam\n",
      "LR: 0.0005\n",
      "epochs: 100\n",
      "clf_dataset: Cifar10\n",
      "clf_loss: CE\n",
      "clf_opt: Adam\n",
      "clf_lr: 5e-05\n",
      "clf_epochs: 150\n",
      "repeat: 1\n",
      "device: cuda:0\n",
      "datapath: data/\n",
      "savepath: save/\n",
      "loadnet: False\n",
      "loadclf: False\n",
      "lam: 1\n",
      "decoder_channel: 3\n",
      "decoder_layer: 1\n",
      "clfnonlinear: None\n",
      "headnonlinear: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pars = PARS(device, datapath, savepath)\n",
    "pars.architecture = 'CONV6'\n",
    "pars.LR = 5e-4\n",
    "pars.clf_lr = 5e-5\n",
    "pars.epochs = 100\n",
    "pars.clf_epochs = 150\n",
    "pars.nonlinear = 'hardtanh'\n",
    "pars.repeat = 1\n",
    "pars.loadnet = False\n",
    "pars.decoder_channel = 3\n",
    "print(pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T06:08:56.208431Z",
     "start_time": "2022-04-02T05:36:16.774373Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_3/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_1_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(3, 32, 32))\n",
      "    (deconv): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 0.8512, time: 25.4070\n",
      "reconstruction loss = 0.0676, similarity loss: 0.7836\n",
      "Epoch 1, loss = 0.5908, time: 16.6738\n",
      "reconstruction loss = 0.0671, similarity loss: 0.5237\n",
      "Epoch 2, loss = 0.6114, time: 16.5367\n",
      "reconstruction loss = 0.0646, similarity loss: 0.5468\n",
      "Epoch 3, loss = 0.6442, time: 16.6018\n",
      "reconstruction loss = 0.0645, similarity loss: 0.5797\n",
      "Epoch 4, loss = 0.6485, time: 16.7058\n",
      "reconstruction loss = 0.0633, similarity loss: 0.5852\n",
      "Epoch 5, loss = 0.6081, time: 16.6368\n",
      "reconstruction loss = 0.0770, similarity loss: 0.5311\n",
      "Epoch 6, loss = 0.4577, time: 17.8480\n",
      "reconstruction loss = 0.0670, similarity loss: 0.3906\n",
      "Epoch 7, loss = 0.4566, time: 18.5432\n",
      "reconstruction loss = 0.0660, similarity loss: 0.3906\n",
      "Epoch 8, loss = 0.5312, time: 20.3439\n",
      "reconstruction loss = 0.0674, similarity loss: 0.4638\n",
      "Epoch 9, loss = 0.4707, time: 20.1446\n",
      "reconstruction loss = 0.0668, similarity loss: 0.4039\n",
      "Epoch 10, loss = 0.4518, time: 18.1267\n",
      "reconstruction loss = 0.0635, similarity loss: 0.3883\n",
      "Epoch 11, loss = 0.3740, time: 16.5168\n",
      "reconstruction loss = 0.0694, similarity loss: 0.3046\n",
      "Epoch 12, loss = 0.3873, time: 16.2153\n",
      "reconstruction loss = 0.0647, similarity loss: 0.3227\n",
      "Epoch 13, loss = 0.4290, time: 16.9380\n",
      "reconstruction loss = 0.0650, similarity loss: 0.3640\n",
      "Epoch 14, loss = 0.3982, time: 17.5393\n",
      "reconstruction loss = 0.0640, similarity loss: 0.3342\n",
      "Epoch 15, loss = 0.3646, time: 17.8049\n",
      "reconstruction loss = 0.0649, similarity loss: 0.2997\n",
      "Epoch 16, loss = 0.3968, time: 17.3214\n",
      "reconstruction loss = 0.0655, similarity loss: 0.3313\n",
      "Epoch 17, loss = 0.3467, time: 17.3358\n",
      "reconstruction loss = 0.0637, similarity loss: 0.2829\n",
      "Epoch 18, loss = 0.3433, time: 17.3527\n",
      "reconstruction loss = 0.0649, similarity loss: 0.2784\n",
      "Epoch 19, loss = 0.3439, time: 17.3671\n",
      "reconstruction loss = 0.0640, similarity loss: 0.2800\n",
      "Epoch 20, loss = 0.3451, time: 17.2839\n",
      "reconstruction loss = 0.0641, similarity loss: 0.2810\n",
      "Epoch 21, loss = 0.3550, time: 17.2078\n",
      "reconstruction loss = 0.0639, similarity loss: 0.2911\n",
      "Epoch 22, loss = 0.3273, time: 17.3204\n",
      "reconstruction loss = 0.0621, similarity loss: 0.2652\n",
      "Epoch 23, loss = 0.3084, time: 17.1773\n",
      "reconstruction loss = 0.0637, similarity loss: 0.2447\n",
      "Epoch 24, loss = 0.3161, time: 17.3790\n",
      "reconstruction loss = 0.0626, similarity loss: 0.2535\n",
      "Epoch 25, loss = 0.3410, time: 17.2410\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2757\n",
      "Epoch 26, loss = 0.2941, time: 17.2531\n",
      "reconstruction loss = 0.0641, similarity loss: 0.2300\n",
      "Epoch 27, loss = 0.3086, time: 17.2184\n",
      "reconstruction loss = 0.0636, similarity loss: 0.2450\n",
      "Epoch 28, loss = 0.3309, time: 17.3649\n",
      "reconstruction loss = 0.0662, similarity loss: 0.2647\n",
      "Epoch 29, loss = 0.3081, time: 17.6452\n",
      "reconstruction loss = 0.0627, similarity loss: 0.2454\n",
      "Epoch 30, loss = 0.3289, time: 18.1384\n",
      "reconstruction loss = 0.0692, similarity loss: 0.2597\n",
      "Epoch 31, loss = 0.3491, time: 18.0628\n",
      "reconstruction loss = 0.0635, similarity loss: 0.2856\n",
      "Epoch 32, loss = 0.3513, time: 17.8561\n",
      "reconstruction loss = 0.0646, similarity loss: 0.2866\n",
      "Epoch 33, loss = 0.3606, time: 17.9757\n",
      "reconstruction loss = 0.0667, similarity loss: 0.2939\n",
      "Epoch 34, loss = 0.3205, time: 17.8782\n",
      "reconstruction loss = 0.0646, similarity loss: 0.2559\n",
      "Epoch 35, loss = 0.2689, time: 17.9159\n",
      "reconstruction loss = 0.0650, similarity loss: 0.2040\n",
      "Epoch 36, loss = 0.3484, time: 17.9210\n",
      "reconstruction loss = 0.0656, similarity loss: 0.2827\n",
      "Epoch 37, loss = 0.3220, time: 17.9421\n",
      "reconstruction loss = 0.0659, similarity loss: 0.2561\n",
      "Epoch 38, loss = 0.3339, time: 17.8281\n",
      "reconstruction loss = 0.0636, similarity loss: 0.2703\n",
      "Epoch 39, loss = 0.3384, time: 17.9673\n",
      "reconstruction loss = 0.0670, similarity loss: 0.2714\n",
      "Epoch 40, loss = 0.2998, time: 17.8299\n",
      "reconstruction loss = 0.0637, similarity loss: 0.2361\n",
      "Epoch 41, loss = 0.3360, time: 17.8469\n",
      "reconstruction loss = 0.0669, similarity loss: 0.2692\n",
      "Epoch 42, loss = 0.3242, time: 17.9402\n",
      "reconstruction loss = 0.0672, similarity loss: 0.2570\n",
      "Epoch 43, loss = 0.3033, time: 17.7706\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2381\n",
      "Epoch 44, loss = 0.3243, time: 17.8536\n",
      "reconstruction loss = 0.0626, similarity loss: 0.2617\n",
      "Epoch 45, loss = 0.3501, time: 18.0553\n",
      "reconstruction loss = 0.0658, similarity loss: 0.2842\n",
      "Epoch 46, loss = 0.3114, time: 17.6547\n",
      "reconstruction loss = 0.0649, similarity loss: 0.2464\n",
      "Epoch 47, loss = 0.3102, time: 16.5128\n",
      "reconstruction loss = 0.0645, similarity loss: 0.2457\n",
      "Epoch 48, loss = 0.3124, time: 16.5088\n",
      "reconstruction loss = 0.0624, similarity loss: 0.2501\n",
      "Epoch 49, loss = 0.3079, time: 16.5596\n",
      "reconstruction loss = 0.0639, similarity loss: 0.2440\n",
      "Epoch 50, loss = 0.3033, time: 16.4479\n",
      "reconstruction loss = 0.0636, similarity loss: 0.2397\n",
      "Epoch 51, loss = 0.2864, time: 16.4899\n",
      "reconstruction loss = 0.0671, similarity loss: 0.2194\n",
      "Epoch 52, loss = 0.3042, time: 16.4106\n",
      "reconstruction loss = 0.0634, similarity loss: 0.2407\n",
      "Epoch 53, loss = 0.3512, time: 16.1097\n",
      "reconstruction loss = 0.0681, similarity loss: 0.2831\n",
      "Epoch 54, loss = 0.2996, time: 16.1837\n",
      "reconstruction loss = 0.0634, similarity loss: 0.2362\n",
      "Epoch 55, loss = 0.3045, time: 16.2247\n",
      "reconstruction loss = 0.0628, similarity loss: 0.2418\n",
      "Epoch 56, loss = 0.2678, time: 16.0498\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2025\n",
      "Epoch 57, loss = 0.3158, time: 16.1517\n",
      "reconstruction loss = 0.0630, similarity loss: 0.2528\n",
      "Epoch 58, loss = 0.3113, time: 16.1410\n",
      "reconstruction loss = 0.0641, similarity loss: 0.2472\n",
      "Epoch 59, loss = 0.2849, time: 16.2239\n",
      "reconstruction loss = 0.0667, similarity loss: 0.2182\n",
      "Epoch 60, loss = 0.3140, time: 16.2302\n",
      "reconstruction loss = 0.0634, similarity loss: 0.2506\n",
      "Epoch 61, loss = 0.3012, time: 16.2347\n",
      "reconstruction loss = 0.0620, similarity loss: 0.2392\n",
      "Epoch 62, loss = 0.3289, time: 16.3140\n",
      "reconstruction loss = 0.0665, similarity loss: 0.2623\n",
      "Epoch 63, loss = 0.2917, time: 16.2027\n",
      "reconstruction loss = 0.0629, similarity loss: 0.2288\n",
      "Epoch 64, loss = 0.2937, time: 16.2120\n",
      "reconstruction loss = 0.0676, similarity loss: 0.2261\n",
      "Epoch 65, loss = 0.2761, time: 16.0767\n",
      "reconstruction loss = 0.0667, similarity loss: 0.2095\n",
      "Epoch 66, loss = 0.2842, time: 16.2397\n",
      "reconstruction loss = 0.0648, similarity loss: 0.2193\n",
      "Epoch 67, loss = 0.3079, time: 16.1427\n",
      "reconstruction loss = 0.0631, similarity loss: 0.2448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.3607, time: 16.2127\n",
      "reconstruction loss = 0.0666, similarity loss: 0.2941\n",
      "Epoch 69, loss = 0.3334, time: 16.1447\n",
      "reconstruction loss = 0.0666, similarity loss: 0.2668\n",
      "Epoch 70, loss = 0.2913, time: 16.1241\n",
      "reconstruction loss = 0.0641, similarity loss: 0.2272\n",
      "Epoch 71, loss = 0.3131, time: 16.3780\n",
      "reconstruction loss = 0.0663, similarity loss: 0.2468\n",
      "Epoch 72, loss = 0.2814, time: 16.4393\n",
      "reconstruction loss = 0.0643, similarity loss: 0.2171\n",
      "Epoch 73, loss = 0.3207, time: 16.1217\n",
      "reconstruction loss = 0.0642, similarity loss: 0.2565\n",
      "Epoch 74, loss = 0.3165, time: 16.2997\n",
      "reconstruction loss = 0.0605, similarity loss: 0.2560\n",
      "Epoch 75, loss = 0.2956, time: 16.4304\n",
      "reconstruction loss = 0.0644, similarity loss: 0.2312\n",
      "Epoch 76, loss = 0.2915, time: 16.4294\n",
      "reconstruction loss = 0.0650, similarity loss: 0.2265\n",
      "Epoch 77, loss = 0.3578, time: 16.3390\n",
      "reconstruction loss = 0.0652, similarity loss: 0.2926\n",
      "Epoch 78, loss = 0.2926, time: 16.2832\n",
      "reconstruction loss = 0.0632, similarity loss: 0.2294\n",
      "Epoch 79, loss = 0.3345, time: 16.3087\n",
      "reconstruction loss = 0.0660, similarity loss: 0.2685\n",
      "Epoch 80, loss = 0.2948, time: 16.2307\n",
      "reconstruction loss = 0.0669, similarity loss: 0.2279\n",
      "Epoch 81, loss = 0.2908, time: 16.1281\n",
      "reconstruction loss = 0.0650, similarity loss: 0.2259\n",
      "Epoch 82, loss = 0.3109, time: 16.3276\n",
      "reconstruction loss = 0.0663, similarity loss: 0.2447\n",
      "Epoch 83, loss = 0.3242, time: 16.1931\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2589\n",
      "Epoch 84, loss = 0.2855, time: 16.2969\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2201\n",
      "Epoch 85, loss = 0.2696, time: 16.3014\n",
      "reconstruction loss = 0.0646, similarity loss: 0.2050\n",
      "Epoch 86, loss = 0.2888, time: 16.1961\n",
      "reconstruction loss = 0.0661, similarity loss: 0.2227\n",
      "Epoch 87, loss = 0.2846, time: 16.2340\n",
      "reconstruction loss = 0.0670, similarity loss: 0.2176\n",
      "Epoch 88, loss = 0.2854, time: 16.1754\n",
      "reconstruction loss = 0.0659, similarity loss: 0.2195\n",
      "Epoch 89, loss = 0.3093, time: 16.3711\n",
      "reconstruction loss = 0.0658, similarity loss: 0.2435\n",
      "Epoch 90, loss = 0.3080, time: 16.3042\n",
      "reconstruction loss = 0.0652, similarity loss: 0.2428\n",
      "Epoch 91, loss = 0.2909, time: 16.1098\n",
      "reconstruction loss = 0.0644, similarity loss: 0.2264\n",
      "Epoch 92, loss = 0.2842, time: 16.1653\n",
      "reconstruction loss = 0.0655, similarity loss: 0.2187\n",
      "Epoch 93, loss = 0.2653, time: 16.1037\n",
      "reconstruction loss = 0.0648, similarity loss: 0.2004\n",
      "Epoch 94, loss = 0.3046, time: 16.2957\n",
      "reconstruction loss = 0.0644, similarity loss: 0.2402\n",
      "Epoch 95, loss = 0.2919, time: 16.2044\n",
      "reconstruction loss = 0.0679, similarity loss: 0.2240\n",
      "Epoch 96, loss = 0.2886, time: 16.1804\n",
      "reconstruction loss = 0.0659, similarity loss: 0.2227\n",
      "Epoch 97, loss = 0.2639, time: 16.7901\n",
      "reconstruction loss = 0.0685, similarity loss: 0.1954\n",
      "Epoch 98, loss = 0.3251, time: 16.9319\n",
      "reconstruction loss = 0.0662, similarity loss: 0.2589\n",
      "Epoch 99, loss = 0.2920, time: 16.8394\n",
      "reconstruction loss = 0.0611, similarity loss: 0.2309\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.9545, val.loss = 1.6340, val.acc = 0.4412\n",
      "Epoch 1, loss = 1.5680, val.loss = 1.4795, val.acc = 0.4964\n",
      "Epoch 2, loss = 1.4505, val.loss = 1.4045, val.acc = 0.5276\n",
      "Epoch 3, loss = 1.3813, val.loss = 1.3578, val.acc = 0.5434\n",
      "Epoch 4, loss = 1.3328, val.loss = 1.3250, val.acc = 0.5522\n",
      "Epoch 5, loss = 1.2957, val.loss = 1.3002, val.acc = 0.5612\n",
      "Epoch 6, loss = 1.2655, val.loss = 1.2806, val.acc = 0.5682\n",
      "Epoch 7, loss = 1.2400, val.loss = 1.2643, val.acc = 0.5734\n",
      "Epoch 8, loss = 1.2179, val.loss = 1.2506, val.acc = 0.5814\n",
      "Epoch 9, loss = 1.1982, val.loss = 1.2387, val.acc = 0.5826\n",
      "Epoch 10, loss = 1.1805, val.loss = 1.2283, val.acc = 0.5852\n",
      "Epoch 11, loss = 1.1643, val.loss = 1.2190, val.acc = 0.5872\n",
      "Epoch 12, loss = 1.1494, val.loss = 1.2107, val.acc = 0.5896\n",
      "Epoch 13, loss = 1.1355, val.loss = 1.2032, val.acc = 0.5926\n",
      "Epoch 14, loss = 1.1226, val.loss = 1.1964, val.acc = 0.5952\n",
      "Epoch 15, loss = 1.1104, val.loss = 1.1902, val.acc = 0.5974\n",
      "Epoch 16, loss = 1.0989, val.loss = 1.1845, val.acc = 0.5980\n",
      "Epoch 17, loss = 1.0880, val.loss = 1.1793, val.acc = 0.5990\n",
      "Epoch 18, loss = 1.0776, val.loss = 1.1744, val.acc = 0.6010\n",
      "Epoch 19, loss = 1.0677, val.loss = 1.1699, val.acc = 0.6038\n",
      "Epoch 20, loss = 1.0583, val.loss = 1.1657, val.acc = 0.6044\n",
      "Epoch 21, loss = 1.0492, val.loss = 1.1618, val.acc = 0.6056\n",
      "Epoch 22, loss = 1.0405, val.loss = 1.1582, val.acc = 0.6060\n",
      "Epoch 23, loss = 1.0322, val.loss = 1.1548, val.acc = 0.6074\n",
      "Epoch 24, loss = 1.0241, val.loss = 1.1516, val.acc = 0.6076\n",
      "Epoch 25, loss = 1.0163, val.loss = 1.1486, val.acc = 0.6086\n",
      "Epoch 26, loss = 1.0088, val.loss = 1.1459, val.acc = 0.6094\n",
      "Epoch 27, loss = 1.0015, val.loss = 1.1432, val.acc = 0.6112\n",
      "Epoch 28, loss = 0.9945, val.loss = 1.1407, val.acc = 0.6124\n",
      "Epoch 29, loss = 0.9876, val.loss = 1.1385, val.acc = 0.6136\n",
      "Epoch 30, loss = 0.9810, val.loss = 1.1363, val.acc = 0.6146\n",
      "Epoch 31, loss = 0.9745, val.loss = 1.1342, val.acc = 0.6152\n",
      "Epoch 32, loss = 0.9682, val.loss = 1.1323, val.acc = 0.6154\n",
      "Epoch 33, loss = 0.9621, val.loss = 1.1305, val.acc = 0.6148\n",
      "Epoch 34, loss = 0.9562, val.loss = 1.1288, val.acc = 0.6154\n",
      "Epoch 35, loss = 0.9504, val.loss = 1.1272, val.acc = 0.6156\n",
      "Epoch 36, loss = 0.9447, val.loss = 1.1256, val.acc = 0.6172\n",
      "Epoch 37, loss = 0.9392, val.loss = 1.1242, val.acc = 0.6184\n",
      "Epoch 38, loss = 0.9338, val.loss = 1.1228, val.acc = 0.6188\n",
      "Epoch 39, loss = 0.9285, val.loss = 1.1216, val.acc = 0.6190\n",
      "Epoch 40, loss = 0.9233, val.loss = 1.1205, val.acc = 0.6202\n",
      "Epoch 41, loss = 0.9183, val.loss = 1.1193, val.acc = 0.6208\n",
      "Epoch 42, loss = 0.9133, val.loss = 1.1182, val.acc = 0.6208\n",
      "Epoch 43, loss = 0.9085, val.loss = 1.1172, val.acc = 0.6210\n",
      "Epoch 44, loss = 0.9038, val.loss = 1.1163, val.acc = 0.6210\n",
      "Epoch 45, loss = 0.8991, val.loss = 1.1154, val.acc = 0.6210\n",
      "Epoch 46, loss = 0.8945, val.loss = 1.1146, val.acc = 0.6214\n",
      "Epoch 47, loss = 0.8900, val.loss = 1.1138, val.acc = 0.6218\n",
      "Epoch 48, loss = 0.8857, val.loss = 1.1131, val.acc = 0.6218\n",
      "Epoch 49, loss = 0.8813, val.loss = 1.1124, val.acc = 0.6216\n",
      "Epoch 50, loss = 0.8771, val.loss = 1.1118, val.acc = 0.6212\n",
      "Epoch 51, loss = 0.8729, val.loss = 1.1112, val.acc = 0.6210\n",
      "Epoch 52, loss = 0.8689, val.loss = 1.1107, val.acc = 0.6222\n",
      "Epoch 53, loss = 0.8648, val.loss = 1.1101, val.acc = 0.6224\n",
      "Epoch 54, loss = 0.8609, val.loss = 1.1097, val.acc = 0.6232\n",
      "Epoch 55, loss = 0.8570, val.loss = 1.1092, val.acc = 0.6232\n",
      "Epoch 56, loss = 0.8532, val.loss = 1.1089, val.acc = 0.6236\n",
      "Epoch 57, loss = 0.8494, val.loss = 1.1085, val.acc = 0.6242\n",
      "Epoch 58, loss = 0.8457, val.loss = 1.1081, val.acc = 0.6250\n",
      "Epoch 59, loss = 0.8421, val.loss = 1.1079, val.acc = 0.6252\n",
      "Epoch 60, loss = 0.8385, val.loss = 1.1076, val.acc = 0.6246\n",
      "Epoch 61, loss = 0.8350, val.loss = 1.1073, val.acc = 0.6240\n",
      "Epoch 62, loss = 0.8315, val.loss = 1.1071, val.acc = 0.6246\n",
      "Epoch 63, loss = 0.8280, val.loss = 1.1069, val.acc = 0.6250\n",
      "Epoch 64, loss = 0.8246, val.loss = 1.1067, val.acc = 0.6246\n",
      "Epoch 65, loss = 0.8213, val.loss = 1.1066, val.acc = 0.6248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.8180, val.loss = 1.1065, val.acc = 0.6250\n",
      "Epoch 67, loss = 0.8148, val.loss = 1.1064, val.acc = 0.6250\n",
      "Epoch 68, loss = 0.8116, val.loss = 1.1064, val.acc = 0.6252\n",
      "Epoch 69, loss = 0.8084, val.loss = 1.1062, val.acc = 0.6252\n",
      "Epoch 70, loss = 0.8053, val.loss = 1.1063, val.acc = 0.6246\n",
      "Epoch 71, loss = 0.8022, val.loss = 1.1062, val.acc = 0.6246\n",
      "Epoch 72, loss = 0.7992, val.loss = 1.1063, val.acc = 0.6242\n",
      "Epoch 73, loss = 0.7962, val.loss = 1.1063, val.acc = 0.6248\n",
      "Epoch 74, loss = 0.7932, val.loss = 1.1064, val.acc = 0.6246\n",
      "Epoch 75, loss = 0.7903, val.loss = 1.1064, val.acc = 0.6242\n",
      "Epoch 76, loss = 0.7874, val.loss = 1.1065, val.acc = 0.6238\n",
      "Epoch 77, loss = 0.7846, val.loss = 1.1066, val.acc = 0.6240\n",
      "Epoch 78, loss = 0.7818, val.loss = 1.1067, val.acc = 0.6248\n",
      "Epoch 79, loss = 0.7790, val.loss = 1.1068, val.acc = 0.6244\n",
      "Epoch 80, loss = 0.7762, val.loss = 1.1070, val.acc = 0.6240\n",
      "Epoch 81, loss = 0.7735, val.loss = 1.1071, val.acc = 0.6242\n",
      "Epoch 82, loss = 0.7708, val.loss = 1.1073, val.acc = 0.6238\n",
      "Epoch 83, loss = 0.7682, val.loss = 1.1075, val.acc = 0.6226\n",
      "Epoch 84, loss = 0.7655, val.loss = 1.1077, val.acc = 0.6222\n",
      "Epoch 85, loss = 0.7629, val.loss = 1.1079, val.acc = 0.6226\n",
      "Epoch 86, loss = 0.7604, val.loss = 1.1082, val.acc = 0.6224\n",
      "Epoch 87, loss = 0.7578, val.loss = 1.1084, val.acc = 0.6216\n",
      "Epoch 88, loss = 0.7553, val.loss = 1.1087, val.acc = 0.6220\n",
      "Epoch 89, loss = 0.7528, val.loss = 1.1089, val.acc = 0.6220\n",
      "Epoch 90, loss = 0.7504, val.loss = 1.1092, val.acc = 0.6224\n",
      "Epoch 91, loss = 0.7479, val.loss = 1.1095, val.acc = 0.6220\n",
      "Epoch 92, loss = 0.7455, val.loss = 1.1098, val.acc = 0.6220\n",
      "Epoch 93, loss = 0.7432, val.loss = 1.1101, val.acc = 0.6226\n",
      "Epoch 94, loss = 0.7408, val.loss = 1.1104, val.acc = 0.6222\n",
      "Epoch 95, loss = 0.7385, val.loss = 1.1108, val.acc = 0.6220\n",
      "Epoch 96, loss = 0.7362, val.loss = 1.1111, val.acc = 0.6218\n",
      "Epoch 97, loss = 0.7339, val.loss = 1.1115, val.acc = 0.6218\n",
      "Epoch 98, loss = 0.7316, val.loss = 1.1118, val.acc = 0.6218\n",
      "Epoch 99, loss = 0.7294, val.loss = 1.1122, val.acc = 0.6226\n",
      "Epoch 100, loss = 0.7272, val.loss = 1.1126, val.acc = 0.6224\n",
      "Epoch 101, loss = 0.7250, val.loss = 1.1129, val.acc = 0.6230\n",
      "Epoch 102, loss = 0.7228, val.loss = 1.1134, val.acc = 0.6232\n",
      "Epoch 103, loss = 0.7206, val.loss = 1.1138, val.acc = 0.6232\n",
      "Epoch 104, loss = 0.7185, val.loss = 1.1142, val.acc = 0.6234\n",
      "Epoch 105, loss = 0.7164, val.loss = 1.1146, val.acc = 0.6226\n",
      "Epoch 106, loss = 0.7143, val.loss = 1.1150, val.acc = 0.6228\n",
      "Epoch 107, loss = 0.7122, val.loss = 1.1155, val.acc = 0.6230\n",
      "Epoch 108, loss = 0.7102, val.loss = 1.1159, val.acc = 0.6230\n",
      "Epoch 109, loss = 0.7082, val.loss = 1.1164, val.acc = 0.6230\n",
      "Epoch 110, loss = 0.7061, val.loss = 1.1168, val.acc = 0.6240\n",
      "Epoch 111, loss = 0.7042, val.loss = 1.1173, val.acc = 0.6240\n",
      "Epoch 112, loss = 0.7022, val.loss = 1.1178, val.acc = 0.6242\n",
      "Epoch 113, loss = 0.7002, val.loss = 1.1183, val.acc = 0.6240\n",
      "Epoch 114, loss = 0.6983, val.loss = 1.1188, val.acc = 0.6244\n",
      "Epoch 115, loss = 0.6964, val.loss = 1.1193, val.acc = 0.6248\n",
      "Epoch 116, loss = 0.6945, val.loss = 1.1198, val.acc = 0.6250\n",
      "Epoch 117, loss = 0.6926, val.loss = 1.1203, val.acc = 0.6248\n",
      "Epoch 118, loss = 0.6907, val.loss = 1.1208, val.acc = 0.6244\n",
      "Epoch 119, loss = 0.6889, val.loss = 1.1214, val.acc = 0.6236\n",
      "Epoch 120, loss = 0.6870, val.loss = 1.1219, val.acc = 0.6240\n",
      "Epoch 121, loss = 0.6852, val.loss = 1.1225, val.acc = 0.6244\n",
      "Epoch 122, loss = 0.6834, val.loss = 1.1231, val.acc = 0.6238\n",
      "Epoch 123, loss = 0.6817, val.loss = 1.1237, val.acc = 0.6240\n",
      "Epoch 124, loss = 0.6799, val.loss = 1.1242, val.acc = 0.6240\n",
      "Epoch 125, loss = 0.6781, val.loss = 1.1248, val.acc = 0.6240\n",
      "Epoch 126, loss = 0.6764, val.loss = 1.1254, val.acc = 0.6242\n",
      "Epoch 127, loss = 0.6747, val.loss = 1.1260, val.acc = 0.6240\n",
      "Epoch 128, loss = 0.6730, val.loss = 1.1266, val.acc = 0.6234\n",
      "Epoch 129, loss = 0.6713, val.loss = 1.1272, val.acc = 0.6228\n",
      "Epoch 130, loss = 0.6697, val.loss = 1.1279, val.acc = 0.6234\n",
      "Epoch 131, loss = 0.6680, val.loss = 1.1285, val.acc = 0.6224\n",
      "Epoch 132, loss = 0.6664, val.loss = 1.1292, val.acc = 0.6224\n",
      "Epoch 133, loss = 0.6648, val.loss = 1.1299, val.acc = 0.6218\n",
      "Epoch 134, loss = 0.6632, val.loss = 1.1305, val.acc = 0.6216\n",
      "Epoch 135, loss = 0.6616, val.loss = 1.1313, val.acc = 0.6212\n",
      "Epoch 136, loss = 0.6601, val.loss = 1.1320, val.acc = 0.6210\n",
      "Epoch 137, loss = 0.6586, val.loss = 1.1327, val.acc = 0.6212\n",
      "Epoch 138, loss = 0.6570, val.loss = 1.1335, val.acc = 0.6218\n",
      "Epoch 139, loss = 0.6555, val.loss = 1.1343, val.acc = 0.6218\n",
      "Epoch 140, loss = 0.6540, val.loss = 1.1351, val.acc = 0.6224\n",
      "Epoch 141, loss = 0.6526, val.loss = 1.1359, val.acc = 0.6226\n",
      "Epoch 142, loss = 0.6512, val.loss = 1.1368, val.acc = 0.6220\n",
      "Epoch 143, loss = 0.6497, val.loss = 1.1377, val.acc = 0.6208\n",
      "Epoch 144, loss = 0.6483, val.loss = 1.1386, val.acc = 0.6204\n",
      "Epoch 145, loss = 0.6469, val.loss = 1.1395, val.acc = 0.6196\n",
      "Epoch 146, loss = 0.6455, val.loss = 1.1404, val.acc = 0.6194\n",
      "Epoch 147, loss = 0.6441, val.loss = 1.1414, val.acc = 0.6198\n",
      "Epoch 148, loss = 0.6428, val.loss = 1.1425, val.acc = 0.6194\n",
      "Epoch 149, loss = 0.6414, val.loss = 1.1434, val.acc = 0.6190\n",
      "Rep: 1, te.acc = 0.6066\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6066]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 1\n",
    "vis = visdom.Visdom(port=8097,env='ae'+str(pars.decoder_channel)+'_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T06:40:47.633678Z",
     "start_time": "2022-04-02T06:08:56.210433Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_3/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_5_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(3, 32, 32))\n",
      "    (deconv): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 0.9982, time: 17.1765\n",
      "reconstruction loss = 0.0650, similarity loss: 0.6734\n",
      "Epoch 1, loss = 0.9441, time: 16.7957\n",
      "reconstruction loss = 0.0527, similarity loss: 0.6805\n",
      "Epoch 2, loss = 0.7917, time: 16.8167\n",
      "reconstruction loss = 0.0420, similarity loss: 0.5817\n",
      "Epoch 3, loss = 0.7666, time: 16.7539\n",
      "reconstruction loss = 0.0412, similarity loss: 0.5607\n",
      "Epoch 4, loss = 0.6793, time: 16.7686\n",
      "reconstruction loss = 0.0349, similarity loss: 0.5049\n",
      "Epoch 5, loss = 0.6993, time: 16.7349\n",
      "reconstruction loss = 0.0398, similarity loss: 0.5002\n",
      "Epoch 6, loss = 0.6201, time: 16.7173\n",
      "reconstruction loss = 0.0354, similarity loss: 0.4430\n",
      "Epoch 7, loss = 0.5716, time: 16.7235\n",
      "reconstruction loss = 0.0309, similarity loss: 0.4172\n",
      "Epoch 8, loss = 0.5138, time: 16.7914\n",
      "reconstruction loss = 0.0277, similarity loss: 0.3751\n",
      "Epoch 9, loss = 0.5485, time: 16.8112\n",
      "reconstruction loss = 0.0269, similarity loss: 0.4142\n",
      "Epoch 10, loss = 0.4982, time: 16.7979\n",
      "reconstruction loss = 0.0302, similarity loss: 0.3474\n",
      "Epoch 11, loss = 0.4373, time: 16.6903\n",
      "reconstruction loss = 0.0263, similarity loss: 0.3058\n",
      "Epoch 12, loss = 0.5319, time: 16.8472\n",
      "reconstruction loss = 0.0292, similarity loss: 0.3860\n",
      "Epoch 13, loss = 0.4367, time: 16.7369\n",
      "reconstruction loss = 0.0240, similarity loss: 0.3167\n",
      "Epoch 14, loss = 0.4588, time: 16.7315\n",
      "reconstruction loss = 0.0256, similarity loss: 0.3306\n",
      "Epoch 15, loss = 0.4537, time: 16.7578\n",
      "reconstruction loss = 0.0256, similarity loss: 0.3257\n",
      "Epoch 16, loss = 0.4282, time: 16.8189\n",
      "reconstruction loss = 0.0253, similarity loss: 0.3017\n",
      "Epoch 17, loss = 0.3893, time: 16.4567\n",
      "reconstruction loss = 0.0247, similarity loss: 0.2660\n",
      "Epoch 18, loss = 0.4680, time: 16.2331\n",
      "reconstruction loss = 0.0237, similarity loss: 0.3495\n",
      "Epoch 19, loss = 0.4103, time: 16.2187\n",
      "reconstruction loss = 0.0209, similarity loss: 0.3058\n",
      "Epoch 20, loss = 0.4192, time: 16.2196\n",
      "reconstruction loss = 0.0211, similarity loss: 0.3135\n",
      "Epoch 21, loss = 0.4155, time: 16.1476\n",
      "reconstruction loss = 0.0244, similarity loss: 0.2934\n",
      "Epoch 22, loss = 0.3949, time: 16.2378\n",
      "reconstruction loss = 0.0226, similarity loss: 0.2821\n",
      "Epoch 23, loss = 0.3908, time: 16.2707\n",
      "reconstruction loss = 0.0240, similarity loss: 0.2708\n",
      "Epoch 24, loss = 0.4009, time: 16.1988\n",
      "reconstruction loss = 0.0213, similarity loss: 0.2945\n",
      "Epoch 25, loss = 0.4036, time: 16.2677\n",
      "reconstruction loss = 0.0212, similarity loss: 0.2975\n",
      "Epoch 26, loss = 0.3928, time: 16.1087\n",
      "reconstruction loss = 0.0206, similarity loss: 0.2895\n",
      "Epoch 27, loss = 0.4310, time: 16.1962\n",
      "reconstruction loss = 0.0190, similarity loss: 0.3359\n",
      "Epoch 28, loss = 0.3484, time: 16.3522\n",
      "reconstruction loss = 0.0210, similarity loss: 0.2432\n",
      "Epoch 29, loss = 0.3889, time: 16.8412\n",
      "reconstruction loss = 0.0214, similarity loss: 0.2820\n",
      "Epoch 30, loss = 0.3751, time: 16.7115\n",
      "reconstruction loss = 0.0189, similarity loss: 0.2807\n",
      "Epoch 31, loss = 0.3986, time: 16.7498\n",
      "reconstruction loss = 0.0199, similarity loss: 0.2990\n",
      "Epoch 32, loss = 0.3878, time: 16.8291\n",
      "reconstruction loss = 0.0207, similarity loss: 0.2843\n",
      "Epoch 33, loss = 0.3505, time: 16.8009\n",
      "reconstruction loss = 0.0200, similarity loss: 0.2507\n",
      "Epoch 34, loss = 0.3912, time: 16.6334\n",
      "reconstruction loss = 0.0214, similarity loss: 0.2843\n",
      "Epoch 35, loss = 0.3778, time: 16.5904\n",
      "reconstruction loss = 0.0220, similarity loss: 0.2678\n",
      "Epoch 36, loss = 0.3843, time: 16.7109\n",
      "reconstruction loss = 0.0196, similarity loss: 0.2864\n",
      "Epoch 37, loss = 0.3921, time: 16.6736\n",
      "reconstruction loss = 0.0240, similarity loss: 0.2720\n",
      "Epoch 38, loss = 0.3746, time: 16.6867\n",
      "reconstruction loss = 0.0185, similarity loss: 0.2823\n",
      "Epoch 39, loss = 0.3520, time: 16.8223\n",
      "reconstruction loss = 0.0185, similarity loss: 0.2597\n",
      "Epoch 40, loss = 0.3276, time: 16.8168\n",
      "reconstruction loss = 0.0157, similarity loss: 0.2493\n",
      "Epoch 41, loss = 0.3576, time: 16.7155\n",
      "reconstruction loss = 0.0182, similarity loss: 0.2667\n",
      "Epoch 42, loss = 0.4023, time: 16.6404\n",
      "reconstruction loss = 0.0178, similarity loss: 0.3132\n",
      "Epoch 43, loss = 0.3481, time: 16.7024\n",
      "reconstruction loss = 0.0181, similarity loss: 0.2576\n",
      "Epoch 44, loss = 0.4131, time: 16.6611\n",
      "reconstruction loss = 0.0186, similarity loss: 0.3203\n",
      "Epoch 45, loss = 0.3846, time: 16.6815\n",
      "reconstruction loss = 0.0192, similarity loss: 0.2887\n",
      "Epoch 46, loss = 0.3522, time: 16.6030\n",
      "reconstruction loss = 0.0177, similarity loss: 0.2636\n",
      "Epoch 47, loss = 0.3772, time: 16.6773\n",
      "reconstruction loss = 0.0166, similarity loss: 0.2940\n",
      "Epoch 48, loss = 0.3391, time: 16.7783\n",
      "reconstruction loss = 0.0160, similarity loss: 0.2591\n",
      "Epoch 49, loss = 0.3521, time: 16.6998\n",
      "reconstruction loss = 0.0189, similarity loss: 0.2574\n",
      "Epoch 50, loss = 0.3770, time: 16.6720\n",
      "reconstruction loss = 0.0174, similarity loss: 0.2900\n",
      "Epoch 51, loss = 0.3770, time: 16.7072\n",
      "reconstruction loss = 0.0168, similarity loss: 0.2930\n",
      "Epoch 52, loss = 0.3582, time: 16.7159\n",
      "reconstruction loss = 0.0161, similarity loss: 0.2780\n",
      "Epoch 53, loss = 0.3971, time: 16.6742\n",
      "reconstruction loss = 0.0219, similarity loss: 0.2877\n",
      "Epoch 54, loss = 0.3555, time: 16.6659\n",
      "reconstruction loss = 0.0184, similarity loss: 0.2633\n",
      "Epoch 55, loss = 0.3381, time: 16.7476\n",
      "reconstruction loss = 0.0180, similarity loss: 0.2482\n",
      "Epoch 56, loss = 0.3057, time: 16.7230\n",
      "reconstruction loss = 0.0175, similarity loss: 0.2182\n",
      "Epoch 57, loss = 0.3433, time: 16.7856\n",
      "reconstruction loss = 0.0175, similarity loss: 0.2558\n",
      "Epoch 58, loss = 0.3456, time: 16.7159\n",
      "reconstruction loss = 0.0175, similarity loss: 0.2582\n",
      "Epoch 59, loss = 0.3533, time: 16.6744\n",
      "reconstruction loss = 0.0182, similarity loss: 0.2623\n",
      "Epoch 60, loss = 0.3248, time: 16.7075\n",
      "reconstruction loss = 0.0174, similarity loss: 0.2380\n",
      "Epoch 61, loss = 0.3186, time: 16.8686\n",
      "reconstruction loss = 0.0153, similarity loss: 0.2420\n",
      "Epoch 62, loss = 0.3671, time: 16.9179\n",
      "reconstruction loss = 0.0196, similarity loss: 0.2689\n",
      "Epoch 63, loss = 0.3492, time: 16.7317\n",
      "reconstruction loss = 0.0166, similarity loss: 0.2664\n",
      "Epoch 64, loss = 0.3425, time: 16.4603\n",
      "reconstruction loss = 0.0169, similarity loss: 0.2579\n",
      "Epoch 65, loss = 0.3263, time: 16.2039\n",
      "reconstruction loss = 0.0162, similarity loss: 0.2452\n",
      "Epoch 66, loss = 0.3299, time: 16.1081\n",
      "reconstruction loss = 0.0181, similarity loss: 0.2394\n",
      "Epoch 67, loss = 0.3209, time: 16.1237\n",
      "reconstruction loss = 0.0156, similarity loss: 0.2429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.3117, time: 16.1072\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2356\n",
      "Epoch 69, loss = 0.3241, time: 16.2189\n",
      "reconstruction loss = 0.0167, similarity loss: 0.2408\n",
      "Epoch 70, loss = 0.3187, time: 16.1210\n",
      "reconstruction loss = 0.0154, similarity loss: 0.2417\n",
      "Epoch 71, loss = 0.3373, time: 16.0565\n",
      "reconstruction loss = 0.0151, similarity loss: 0.2620\n",
      "Epoch 72, loss = 0.3580, time: 16.2377\n",
      "reconstruction loss = 0.0177, similarity loss: 0.2697\n",
      "Epoch 73, loss = 0.3265, time: 16.1650\n",
      "reconstruction loss = 0.0157, similarity loss: 0.2478\n",
      "Epoch 74, loss = 0.3412, time: 16.0947\n",
      "reconstruction loss = 0.0174, similarity loss: 0.2543\n",
      "Epoch 75, loss = 0.3335, time: 16.1387\n",
      "reconstruction loss = 0.0175, similarity loss: 0.2460\n",
      "Epoch 76, loss = 0.3000, time: 16.2158\n",
      "reconstruction loss = 0.0156, similarity loss: 0.2223\n",
      "Epoch 77, loss = 0.3493, time: 16.1222\n",
      "reconstruction loss = 0.0160, similarity loss: 0.2690\n",
      "Epoch 78, loss = 0.3271, time: 16.2087\n",
      "reconstruction loss = 0.0160, similarity loss: 0.2470\n",
      "Epoch 79, loss = 0.2863, time: 16.1837\n",
      "reconstruction loss = 0.0155, similarity loss: 0.2089\n",
      "Epoch 80, loss = 0.3427, time: 16.1454\n",
      "reconstruction loss = 0.0163, similarity loss: 0.2611\n",
      "Epoch 81, loss = 0.3752, time: 16.1650\n",
      "reconstruction loss = 0.0213, similarity loss: 0.2689\n",
      "Epoch 82, loss = 0.3214, time: 16.1357\n",
      "reconstruction loss = 0.0149, similarity loss: 0.2470\n",
      "Epoch 83, loss = 0.3070, time: 16.0880\n",
      "reconstruction loss = 0.0155, similarity loss: 0.2296\n",
      "Epoch 84, loss = 0.3040, time: 16.1608\n",
      "reconstruction loss = 0.0139, similarity loss: 0.2345\n",
      "Epoch 85, loss = 0.3274, time: 16.1179\n",
      "reconstruction loss = 0.0155, similarity loss: 0.2498\n",
      "Epoch 86, loss = 0.3404, time: 16.1497\n",
      "reconstruction loss = 0.0153, similarity loss: 0.2639\n",
      "Epoch 87, loss = 0.3329, time: 16.2843\n",
      "reconstruction loss = 0.0138, similarity loss: 0.2637\n",
      "Epoch 88, loss = 0.3320, time: 16.1058\n",
      "reconstruction loss = 0.0156, similarity loss: 0.2538\n",
      "Epoch 89, loss = 0.3041, time: 16.1235\n",
      "reconstruction loss = 0.0155, similarity loss: 0.2266\n",
      "Epoch 90, loss = 0.3142, time: 16.5067\n",
      "reconstruction loss = 0.0163, similarity loss: 0.2328\n",
      "Epoch 91, loss = 0.3386, time: 16.7438\n",
      "reconstruction loss = 0.0165, similarity loss: 0.2559\n",
      "Epoch 92, loss = 0.2987, time: 16.8571\n",
      "reconstruction loss = 0.0157, similarity loss: 0.2204\n",
      "Epoch 93, loss = 0.3152, time: 16.7933\n",
      "reconstruction loss = 0.0148, similarity loss: 0.2412\n",
      "Epoch 94, loss = 0.3462, time: 16.8492\n",
      "reconstruction loss = 0.0171, similarity loss: 0.2605\n",
      "Epoch 95, loss = 0.2849, time: 16.8789\n",
      "reconstruction loss = 0.0145, similarity loss: 0.2125\n",
      "Epoch 96, loss = 0.3312, time: 16.8005\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2554\n",
      "Epoch 97, loss = 0.2985, time: 16.7538\n",
      "reconstruction loss = 0.0151, similarity loss: 0.2228\n",
      "Epoch 98, loss = 0.3085, time: 16.6652\n",
      "reconstruction loss = 0.0147, similarity loss: 0.2349\n",
      "Epoch 99, loss = 0.3415, time: 16.6679\n",
      "reconstruction loss = 0.0167, similarity loss: 0.2581\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.9983, val.loss = 1.7353, val.acc = 0.4268\n",
      "Epoch 1, loss = 1.6417, val.loss = 1.5639, val.acc = 0.4856\n",
      "Epoch 2, loss = 1.5110, val.loss = 1.4732, val.acc = 0.5140\n",
      "Epoch 3, loss = 1.4314, val.loss = 1.4138, val.acc = 0.5342\n",
      "Epoch 4, loss = 1.3750, val.loss = 1.3708, val.acc = 0.5478\n",
      "Epoch 5, loss = 1.3318, val.loss = 1.3379, val.acc = 0.5570\n",
      "Epoch 6, loss = 1.2970, val.loss = 1.3116, val.acc = 0.5650\n",
      "Epoch 7, loss = 1.2679, val.loss = 1.2901, val.acc = 0.5702\n",
      "Epoch 8, loss = 1.2429, val.loss = 1.2719, val.acc = 0.5790\n",
      "Epoch 9, loss = 1.2210, val.loss = 1.2564, val.acc = 0.5808\n",
      "Epoch 10, loss = 1.2014, val.loss = 1.2429, val.acc = 0.5846\n",
      "Epoch 11, loss = 1.1838, val.loss = 1.2311, val.acc = 0.5868\n",
      "Epoch 12, loss = 1.1677, val.loss = 1.2205, val.acc = 0.5898\n",
      "Epoch 13, loss = 1.1529, val.loss = 1.2111, val.acc = 0.5918\n",
      "Epoch 14, loss = 1.1391, val.loss = 1.2025, val.acc = 0.5952\n",
      "Epoch 15, loss = 1.1262, val.loss = 1.1948, val.acc = 0.5976\n",
      "Epoch 16, loss = 1.1142, val.loss = 1.1877, val.acc = 0.5986\n",
      "Epoch 17, loss = 1.1028, val.loss = 1.1812, val.acc = 0.6006\n",
      "Epoch 18, loss = 1.0920, val.loss = 1.1752, val.acc = 0.6020\n",
      "Epoch 19, loss = 1.0818, val.loss = 1.1696, val.acc = 0.6046\n",
      "Epoch 20, loss = 1.0720, val.loss = 1.1644, val.acc = 0.6068\n",
      "Epoch 21, loss = 1.0627, val.loss = 1.1596, val.acc = 0.6072\n",
      "Epoch 22, loss = 1.0538, val.loss = 1.1552, val.acc = 0.6074\n",
      "Epoch 23, loss = 1.0452, val.loss = 1.1510, val.acc = 0.6096\n",
      "Epoch 24, loss = 1.0370, val.loss = 1.1470, val.acc = 0.6116\n",
      "Epoch 25, loss = 1.0290, val.loss = 1.1434, val.acc = 0.6136\n",
      "Epoch 26, loss = 1.0214, val.loss = 1.1399, val.acc = 0.6144\n",
      "Epoch 27, loss = 1.0140, val.loss = 1.1367, val.acc = 0.6158\n",
      "Epoch 28, loss = 1.0068, val.loss = 1.1336, val.acc = 0.6158\n",
      "Epoch 29, loss = 0.9999, val.loss = 1.1307, val.acc = 0.6180\n",
      "Epoch 30, loss = 0.9932, val.loss = 1.1280, val.acc = 0.6196\n",
      "Epoch 31, loss = 0.9867, val.loss = 1.1254, val.acc = 0.6210\n",
      "Epoch 32, loss = 0.9803, val.loss = 1.1230, val.acc = 0.6224\n",
      "Epoch 33, loss = 0.9742, val.loss = 1.1207, val.acc = 0.6224\n",
      "Epoch 34, loss = 0.9682, val.loss = 1.1185, val.acc = 0.6228\n",
      "Epoch 35, loss = 0.9624, val.loss = 1.1164, val.acc = 0.6222\n",
      "Epoch 36, loss = 0.9567, val.loss = 1.1144, val.acc = 0.6222\n",
      "Epoch 37, loss = 0.9511, val.loss = 1.1126, val.acc = 0.6226\n",
      "Epoch 38, loss = 0.9457, val.loss = 1.1108, val.acc = 0.6238\n",
      "Epoch 39, loss = 0.9404, val.loss = 1.1091, val.acc = 0.6240\n",
      "Epoch 40, loss = 0.9352, val.loss = 1.1076, val.acc = 0.6256\n",
      "Epoch 41, loss = 0.9302, val.loss = 1.1060, val.acc = 0.6256\n",
      "Epoch 42, loss = 0.9252, val.loss = 1.1046, val.acc = 0.6268\n",
      "Epoch 43, loss = 0.9204, val.loss = 1.1032, val.acc = 0.6274\n",
      "Epoch 44, loss = 0.9156, val.loss = 1.1020, val.acc = 0.6278\n",
      "Epoch 45, loss = 0.9110, val.loss = 1.1007, val.acc = 0.6278\n",
      "Epoch 46, loss = 0.9064, val.loss = 1.0996, val.acc = 0.6278\n",
      "Epoch 47, loss = 0.9020, val.loss = 1.0985, val.acc = 0.6296\n",
      "Epoch 48, loss = 0.8976, val.loss = 1.0974, val.acc = 0.6304\n",
      "Epoch 49, loss = 0.8933, val.loss = 1.0964, val.acc = 0.6308\n",
      "Epoch 50, loss = 0.8890, val.loss = 1.0955, val.acc = 0.6306\n",
      "Epoch 51, loss = 0.8849, val.loss = 1.0946, val.acc = 0.6312\n",
      "Epoch 52, loss = 0.8808, val.loss = 1.0938, val.acc = 0.6312\n",
      "Epoch 53, loss = 0.8768, val.loss = 1.0929, val.acc = 0.6320\n",
      "Epoch 54, loss = 0.8729, val.loss = 1.0922, val.acc = 0.6320\n",
      "Epoch 55, loss = 0.8690, val.loss = 1.0915, val.acc = 0.6312\n",
      "Epoch 56, loss = 0.8652, val.loss = 1.0908, val.acc = 0.6314\n",
      "Epoch 57, loss = 0.8614, val.loss = 1.0902, val.acc = 0.6312\n",
      "Epoch 58, loss = 0.8577, val.loss = 1.0896, val.acc = 0.6314\n",
      "Epoch 59, loss = 0.8541, val.loss = 1.0890, val.acc = 0.6316\n",
      "Epoch 60, loss = 0.8505, val.loss = 1.0885, val.acc = 0.6318\n",
      "Epoch 61, loss = 0.8470, val.loss = 1.0880, val.acc = 0.6322\n",
      "Epoch 62, loss = 0.8435, val.loss = 1.0875, val.acc = 0.6324\n",
      "Epoch 63, loss = 0.8401, val.loss = 1.0871, val.acc = 0.6322\n",
      "Epoch 64, loss = 0.8367, val.loss = 1.0867, val.acc = 0.6318\n",
      "Epoch 65, loss = 0.8334, val.loss = 1.0863, val.acc = 0.6324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.8301, val.loss = 1.0860, val.acc = 0.6324\n",
      "Epoch 67, loss = 0.8269, val.loss = 1.0856, val.acc = 0.6322\n",
      "Epoch 68, loss = 0.8237, val.loss = 1.0853, val.acc = 0.6324\n",
      "Epoch 69, loss = 0.8205, val.loss = 1.0850, val.acc = 0.6322\n",
      "Epoch 70, loss = 0.8174, val.loss = 1.0848, val.acc = 0.6322\n",
      "Epoch 71, loss = 0.8144, val.loss = 1.0846, val.acc = 0.6328\n",
      "Epoch 72, loss = 0.8113, val.loss = 1.0843, val.acc = 0.6334\n",
      "Epoch 73, loss = 0.8084, val.loss = 1.0842, val.acc = 0.6338\n",
      "Epoch 74, loss = 0.8054, val.loss = 1.0840, val.acc = 0.6336\n",
      "Epoch 75, loss = 0.8025, val.loss = 1.0839, val.acc = 0.6340\n",
      "Epoch 76, loss = 0.7996, val.loss = 1.0837, val.acc = 0.6344\n",
      "Epoch 77, loss = 0.7968, val.loss = 1.0836, val.acc = 0.6340\n",
      "Epoch 78, loss = 0.7940, val.loss = 1.0835, val.acc = 0.6342\n",
      "Epoch 79, loss = 0.7912, val.loss = 1.0835, val.acc = 0.6346\n",
      "Epoch 80, loss = 0.7884, val.loss = 1.0834, val.acc = 0.6350\n",
      "Epoch 81, loss = 0.7857, val.loss = 1.0834, val.acc = 0.6356\n",
      "Epoch 82, loss = 0.7830, val.loss = 1.0833, val.acc = 0.6354\n",
      "Epoch 83, loss = 0.7804, val.loss = 1.0833, val.acc = 0.6360\n",
      "Epoch 84, loss = 0.7778, val.loss = 1.0834, val.acc = 0.6354\n",
      "Epoch 85, loss = 0.7752, val.loss = 1.0834, val.acc = 0.6362\n",
      "Epoch 86, loss = 0.7726, val.loss = 1.0834, val.acc = 0.6366\n",
      "Epoch 87, loss = 0.7701, val.loss = 1.0835, val.acc = 0.6366\n",
      "Epoch 88, loss = 0.7675, val.loss = 1.0835, val.acc = 0.6362\n",
      "Epoch 89, loss = 0.7651, val.loss = 1.0836, val.acc = 0.6358\n",
      "Epoch 90, loss = 0.7626, val.loss = 1.0837, val.acc = 0.6362\n",
      "Epoch 91, loss = 0.7602, val.loss = 1.0838, val.acc = 0.6360\n",
      "Epoch 92, loss = 0.7578, val.loss = 1.0839, val.acc = 0.6358\n",
      "Epoch 93, loss = 0.7554, val.loss = 1.0840, val.acc = 0.6352\n",
      "Epoch 94, loss = 0.7530, val.loss = 1.0842, val.acc = 0.6350\n",
      "Epoch 95, loss = 0.7507, val.loss = 1.0843, val.acc = 0.6354\n",
      "Epoch 96, loss = 0.7484, val.loss = 1.0845, val.acc = 0.6350\n",
      "Epoch 97, loss = 0.7461, val.loss = 1.0847, val.acc = 0.6348\n",
      "Epoch 98, loss = 0.7438, val.loss = 1.0849, val.acc = 0.6346\n",
      "Epoch 99, loss = 0.7416, val.loss = 1.0850, val.acc = 0.6346\n",
      "Epoch 100, loss = 0.7393, val.loss = 1.0853, val.acc = 0.6348\n",
      "Epoch 101, loss = 0.7371, val.loss = 1.0855, val.acc = 0.6344\n",
      "Epoch 102, loss = 0.7349, val.loss = 1.0857, val.acc = 0.6352\n",
      "Epoch 103, loss = 0.7328, val.loss = 1.0859, val.acc = 0.6346\n",
      "Epoch 104, loss = 0.7306, val.loss = 1.0861, val.acc = 0.6344\n",
      "Epoch 105, loss = 0.7285, val.loss = 1.0864, val.acc = 0.6346\n",
      "Epoch 106, loss = 0.7264, val.loss = 1.0866, val.acc = 0.6346\n",
      "Epoch 107, loss = 0.7243, val.loss = 1.0869, val.acc = 0.6348\n",
      "Epoch 108, loss = 0.7222, val.loss = 1.0872, val.acc = 0.6342\n",
      "Epoch 109, loss = 0.7202, val.loss = 1.0875, val.acc = 0.6344\n",
      "Epoch 110, loss = 0.7181, val.loss = 1.0877, val.acc = 0.6334\n",
      "Epoch 111, loss = 0.7161, val.loss = 1.0880, val.acc = 0.6334\n",
      "Epoch 112, loss = 0.7141, val.loss = 1.0883, val.acc = 0.6338\n",
      "Epoch 113, loss = 0.7121, val.loss = 1.0886, val.acc = 0.6336\n",
      "Epoch 114, loss = 0.7102, val.loss = 1.0890, val.acc = 0.6336\n",
      "Epoch 115, loss = 0.7082, val.loss = 1.0893, val.acc = 0.6344\n",
      "Epoch 116, loss = 0.7063, val.loss = 1.0896, val.acc = 0.6340\n",
      "Epoch 117, loss = 0.7044, val.loss = 1.0899, val.acc = 0.6336\n",
      "Epoch 118, loss = 0.7025, val.loss = 1.0903, val.acc = 0.6334\n",
      "Epoch 119, loss = 0.7006, val.loss = 1.0906, val.acc = 0.6336\n",
      "Epoch 120, loss = 0.6987, val.loss = 1.0910, val.acc = 0.6334\n",
      "Epoch 121, loss = 0.6969, val.loss = 1.0913, val.acc = 0.6334\n",
      "Epoch 122, loss = 0.6950, val.loss = 1.0917, val.acc = 0.6336\n",
      "Epoch 123, loss = 0.6932, val.loss = 1.0921, val.acc = 0.6336\n",
      "Epoch 124, loss = 0.6914, val.loss = 1.0925, val.acc = 0.6336\n",
      "Epoch 125, loss = 0.6896, val.loss = 1.0928, val.acc = 0.6338\n",
      "Epoch 126, loss = 0.6878, val.loss = 1.0932, val.acc = 0.6340\n",
      "Epoch 127, loss = 0.6860, val.loss = 1.0936, val.acc = 0.6340\n",
      "Epoch 128, loss = 0.6843, val.loss = 1.0940, val.acc = 0.6338\n",
      "Epoch 129, loss = 0.6825, val.loss = 1.0944, val.acc = 0.6342\n",
      "Epoch 130, loss = 0.6808, val.loss = 1.0948, val.acc = 0.6348\n",
      "Epoch 131, loss = 0.6791, val.loss = 1.0952, val.acc = 0.6352\n",
      "Epoch 132, loss = 0.6774, val.loss = 1.0957, val.acc = 0.6346\n",
      "Epoch 133, loss = 0.6757, val.loss = 1.0961, val.acc = 0.6348\n",
      "Epoch 134, loss = 0.6740, val.loss = 1.0965, val.acc = 0.6348\n",
      "Epoch 135, loss = 0.6723, val.loss = 1.0969, val.acc = 0.6346\n",
      "Epoch 136, loss = 0.6706, val.loss = 1.0973, val.acc = 0.6346\n",
      "Epoch 137, loss = 0.6690, val.loss = 1.0978, val.acc = 0.6344\n",
      "Epoch 138, loss = 0.6674, val.loss = 1.0982, val.acc = 0.6346\n",
      "Epoch 139, loss = 0.6657, val.loss = 1.0987, val.acc = 0.6348\n",
      "Epoch 140, loss = 0.6641, val.loss = 1.0991, val.acc = 0.6348\n",
      "Epoch 141, loss = 0.6625, val.loss = 1.0996, val.acc = 0.6346\n",
      "Epoch 142, loss = 0.6609, val.loss = 1.1000, val.acc = 0.6348\n",
      "Epoch 143, loss = 0.6593, val.loss = 1.1005, val.acc = 0.6346\n",
      "Epoch 144, loss = 0.6578, val.loss = 1.1010, val.acc = 0.6344\n",
      "Epoch 145, loss = 0.6562, val.loss = 1.1015, val.acc = 0.6344\n",
      "Epoch 146, loss = 0.6547, val.loss = 1.1019, val.acc = 0.6346\n",
      "Epoch 147, loss = 0.6531, val.loss = 1.1024, val.acc = 0.6348\n",
      "Epoch 148, loss = 0.6516, val.loss = 1.1029, val.acc = 0.6344\n",
      "Epoch 149, loss = 0.6501, val.loss = 1.1033, val.acc = 0.6344\n",
      "Rep: 1, te.acc = 0.6171\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6171]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 5\n",
    "vis = visdom.Visdom(port=8097,env='ae'+str(pars.decoder_channel)+'_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T07:12:42.621036Z",
     "start_time": "2022-04-02T06:40:47.634678Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_3/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_10_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(3, 32, 32))\n",
      "    (deconv): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.2851, time: 16.9509\n",
      "reconstruction loss = 0.0595, similarity loss: 0.6897\n",
      "Epoch 1, loss = 1.0052, time: 16.8189\n",
      "reconstruction loss = 0.0406, similarity loss: 0.5994\n",
      "Epoch 2, loss = 0.9385, time: 16.9150\n",
      "reconstruction loss = 0.0364, similarity loss: 0.5746\n",
      "Epoch 3, loss = 0.9584, time: 16.7967\n",
      "reconstruction loss = 0.0299, similarity loss: 0.6593\n",
      "Epoch 4, loss = 0.8362, time: 16.8130\n",
      "reconstruction loss = 0.0278, similarity loss: 0.5577\n",
      "Epoch 5, loss = 0.8048, time: 16.7666\n",
      "reconstruction loss = 0.0260, similarity loss: 0.5448\n",
      "Epoch 6, loss = 0.6390, time: 16.8126\n",
      "reconstruction loss = 0.0238, similarity loss: 0.4007\n",
      "Epoch 7, loss = 0.6672, time: 16.8726\n",
      "reconstruction loss = 0.0238, similarity loss: 0.4293\n",
      "Epoch 8, loss = 0.6793, time: 16.8152\n",
      "reconstruction loss = 0.0233, similarity loss: 0.4460\n",
      "Epoch 9, loss = 0.5558, time: 16.8487\n",
      "reconstruction loss = 0.0208, similarity loss: 0.3481\n",
      "Epoch 10, loss = 0.5951, time: 16.7202\n",
      "reconstruction loss = 0.0221, similarity loss: 0.3739\n",
      "Epoch 11, loss = 0.5787, time: 16.1024\n",
      "reconstruction loss = 0.0214, similarity loss: 0.3648\n",
      "Epoch 12, loss = 0.5256, time: 16.1701\n",
      "reconstruction loss = 0.0178, similarity loss: 0.3477\n",
      "Epoch 13, loss = 0.5977, time: 16.1930\n",
      "reconstruction loss = 0.0226, similarity loss: 0.3720\n",
      "Epoch 14, loss = 0.5313, time: 16.1272\n",
      "reconstruction loss = 0.0187, similarity loss: 0.3438\n",
      "Epoch 15, loss = 0.5451, time: 16.0750\n",
      "reconstruction loss = 0.0212, similarity loss: 0.3330\n",
      "Epoch 16, loss = 0.5255, time: 16.2827\n",
      "reconstruction loss = 0.0201, similarity loss: 0.3246\n",
      "Epoch 17, loss = 0.5405, time: 16.2693\n",
      "reconstruction loss = 0.0210, similarity loss: 0.3304\n",
      "Epoch 18, loss = 0.5213, time: 16.2862\n",
      "reconstruction loss = 0.0192, similarity loss: 0.3291\n",
      "Epoch 19, loss = 0.5261, time: 16.1749\n",
      "reconstruction loss = 0.0207, similarity loss: 0.3190\n",
      "Epoch 20, loss = 0.4287, time: 16.0831\n",
      "reconstruction loss = 0.0175, similarity loss: 0.2541\n",
      "Epoch 21, loss = 0.4727, time: 16.1116\n",
      "reconstruction loss = 0.0182, similarity loss: 0.2912\n",
      "Epoch 22, loss = 0.4957, time: 16.2275\n",
      "reconstruction loss = 0.0184, similarity loss: 0.3113\n",
      "Epoch 23, loss = 0.5164, time: 16.1297\n",
      "reconstruction loss = 0.0181, similarity loss: 0.3352\n",
      "Epoch 24, loss = 0.4836, time: 16.0924\n",
      "reconstruction loss = 0.0194, similarity loss: 0.2900\n",
      "Epoch 25, loss = 0.4469, time: 16.2034\n",
      "reconstruction loss = 0.0169, similarity loss: 0.2775\n",
      "Epoch 26, loss = 0.4767, time: 16.2919\n",
      "reconstruction loss = 0.0170, similarity loss: 0.3066\n",
      "Epoch 27, loss = 0.4564, time: 15.9889\n",
      "reconstruction loss = 0.0172, similarity loss: 0.2844\n",
      "Epoch 28, loss = 0.4564, time: 16.0877\n",
      "reconstruction loss = 0.0182, similarity loss: 0.2741\n",
      "Epoch 29, loss = 0.4452, time: 16.4886\n",
      "reconstruction loss = 0.0167, similarity loss: 0.2778\n",
      "Epoch 30, loss = 0.4269, time: 16.6506\n",
      "reconstruction loss = 0.0171, similarity loss: 0.2562\n",
      "Epoch 31, loss = 0.4460, time: 16.6568\n",
      "reconstruction loss = 0.0148, similarity loss: 0.2977\n",
      "Epoch 32, loss = 0.4802, time: 16.7593\n",
      "reconstruction loss = 0.0186, similarity loss: 0.2941\n",
      "Epoch 33, loss = 0.4847, time: 16.8565\n",
      "reconstruction loss = 0.0180, similarity loss: 0.3052\n",
      "Epoch 34, loss = 0.4491, time: 16.7596\n",
      "reconstruction loss = 0.0174, similarity loss: 0.2751\n",
      "Epoch 35, loss = 0.4233, time: 16.6659\n",
      "reconstruction loss = 0.0168, similarity loss: 0.2551\n",
      "Epoch 36, loss = 0.4579, time: 16.7456\n",
      "reconstruction loss = 0.0164, similarity loss: 0.2943\n",
      "Epoch 37, loss = 0.5121, time: 16.7003\n",
      "reconstruction loss = 0.0174, similarity loss: 0.3382\n",
      "Epoch 38, loss = 0.4333, time: 16.8179\n",
      "reconstruction loss = 0.0183, similarity loss: 0.2505\n",
      "Epoch 39, loss = 0.4454, time: 16.8643\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2935\n",
      "Epoch 40, loss = 0.4323, time: 16.8845\n",
      "reconstruction loss = 0.0156, similarity loss: 0.2759\n",
      "Epoch 41, loss = 0.4189, time: 16.7537\n",
      "reconstruction loss = 0.0151, similarity loss: 0.2682\n",
      "Epoch 42, loss = 0.4313, time: 16.7655\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2798\n",
      "Epoch 43, loss = 0.5032, time: 16.7563\n",
      "reconstruction loss = 0.0173, similarity loss: 0.3303\n",
      "Epoch 44, loss = 0.4311, time: 16.7421\n",
      "reconstruction loss = 0.0164, similarity loss: 0.2673\n",
      "Epoch 45, loss = 0.4198, time: 16.7754\n",
      "reconstruction loss = 0.0151, similarity loss: 0.2684\n",
      "Epoch 46, loss = 0.4022, time: 16.7102\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2498\n",
      "Epoch 47, loss = 0.4203, time: 16.7858\n",
      "reconstruction loss = 0.0163, similarity loss: 0.2578\n",
      "Epoch 48, loss = 0.3993, time: 16.8359\n",
      "reconstruction loss = 0.0144, similarity loss: 0.2553\n",
      "Epoch 49, loss = 0.4104, time: 16.7761\n",
      "reconstruction loss = 0.0145, similarity loss: 0.2654\n",
      "Epoch 50, loss = 0.4650, time: 16.7962\n",
      "reconstruction loss = 0.0171, similarity loss: 0.2939\n",
      "Epoch 51, loss = 0.4444, time: 16.7767\n",
      "reconstruction loss = 0.0176, similarity loss: 0.2685\n",
      "Epoch 52, loss = 0.3919, time: 16.7367\n",
      "reconstruction loss = 0.0145, similarity loss: 0.2467\n",
      "Epoch 53, loss = 0.4072, time: 16.6973\n",
      "reconstruction loss = 0.0150, similarity loss: 0.2568\n",
      "Epoch 54, loss = 0.4149, time: 16.7094\n",
      "reconstruction loss = 0.0147, similarity loss: 0.2677\n",
      "Epoch 55, loss = 0.4261, time: 16.6904\n",
      "reconstruction loss = 0.0158, similarity loss: 0.2686\n",
      "Epoch 56, loss = 0.3963, time: 16.6667\n",
      "reconstruction loss = 0.0141, similarity loss: 0.2552\n",
      "Epoch 57, loss = 0.4052, time: 16.7961\n",
      "reconstruction loss = 0.0147, similarity loss: 0.2582\n",
      "Epoch 58, loss = 0.3724, time: 17.1065\n",
      "reconstruction loss = 0.0146, similarity loss: 0.2267\n",
      "Epoch 59, loss = 0.4065, time: 16.8231\n",
      "reconstruction loss = 0.0140, similarity loss: 0.2660\n",
      "Epoch 60, loss = 0.4131, time: 16.6740\n",
      "reconstruction loss = 0.0136, similarity loss: 0.2775\n",
      "Epoch 61, loss = 0.4067, time: 16.7214\n",
      "reconstruction loss = 0.0151, similarity loss: 0.2559\n",
      "Epoch 62, loss = 0.3831, time: 16.6674\n",
      "reconstruction loss = 0.0134, similarity loss: 0.2491\n",
      "Epoch 63, loss = 0.4233, time: 16.6546\n",
      "reconstruction loss = 0.0143, similarity loss: 0.2802\n",
      "Epoch 64, loss = 0.4289, time: 17.2590\n",
      "reconstruction loss = 0.0142, similarity loss: 0.2873\n",
      "Epoch 65, loss = 0.4064, time: 16.7819\n",
      "reconstruction loss = 0.0158, similarity loss: 0.2481\n",
      "Epoch 66, loss = 0.3966, time: 16.7990\n",
      "reconstruction loss = 0.0144, similarity loss: 0.2526\n",
      "Epoch 67, loss = 0.4016, time: 16.4906\n",
      "reconstruction loss = 0.0131, similarity loss: 0.2703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.3839, time: 16.1613\n",
      "reconstruction loss = 0.0141, similarity loss: 0.2434\n",
      "Epoch 69, loss = 0.3992, time: 16.2017\n",
      "reconstruction loss = 0.0144, similarity loss: 0.2553\n",
      "Epoch 70, loss = 0.3699, time: 16.0370\n",
      "reconstruction loss = 0.0134, similarity loss: 0.2363\n",
      "Epoch 71, loss = 0.3951, time: 16.1445\n",
      "reconstruction loss = 0.0135, similarity loss: 0.2599\n",
      "Epoch 72, loss = 0.4081, time: 16.2980\n",
      "reconstruction loss = 0.0142, similarity loss: 0.2663\n",
      "Epoch 73, loss = 0.3973, time: 16.1157\n",
      "reconstruction loss = 0.0133, similarity loss: 0.2643\n",
      "Epoch 74, loss = 0.4065, time: 16.0675\n",
      "reconstruction loss = 0.0157, similarity loss: 0.2500\n",
      "Epoch 75, loss = 0.3852, time: 16.1705\n",
      "reconstruction loss = 0.0136, similarity loss: 0.2495\n",
      "Epoch 76, loss = 0.4152, time: 16.1131\n",
      "reconstruction loss = 0.0154, similarity loss: 0.2610\n",
      "Epoch 77, loss = 0.3953, time: 16.2677\n",
      "reconstruction loss = 0.0132, similarity loss: 0.2635\n",
      "Epoch 78, loss = 0.4023, time: 16.2866\n",
      "reconstruction loss = 0.0134, similarity loss: 0.2683\n",
      "Epoch 79, loss = 0.4285, time: 16.1394\n",
      "reconstruction loss = 0.0156, similarity loss: 0.2724\n",
      "Epoch 80, loss = 0.3496, time: 16.2604\n",
      "reconstruction loss = 0.0126, similarity loss: 0.2237\n",
      "Epoch 81, loss = 0.3871, time: 16.0717\n",
      "reconstruction loss = 0.0139, similarity loss: 0.2484\n",
      "Epoch 82, loss = 0.3686, time: 16.1139\n",
      "reconstruction loss = 0.0124, similarity loss: 0.2449\n",
      "Epoch 83, loss = 0.3797, time: 16.5250\n",
      "reconstruction loss = 0.0126, similarity loss: 0.2537\n",
      "Epoch 84, loss = 0.3923, time: 16.7964\n",
      "reconstruction loss = 0.0133, similarity loss: 0.2596\n",
      "Epoch 85, loss = 0.3708, time: 16.8418\n",
      "reconstruction loss = 0.0131, similarity loss: 0.2401\n",
      "Epoch 86, loss = 0.3548, time: 16.7267\n",
      "reconstruction loss = 0.0117, similarity loss: 0.2378\n",
      "Epoch 87, loss = 0.3833, time: 16.8481\n",
      "reconstruction loss = 0.0130, similarity loss: 0.2530\n",
      "Epoch 88, loss = 0.3688, time: 16.9004\n",
      "reconstruction loss = 0.0122, similarity loss: 0.2465\n",
      "Epoch 89, loss = 0.3809, time: 16.7912\n",
      "reconstruction loss = 0.0121, similarity loss: 0.2595\n",
      "Epoch 90, loss = 0.3783, time: 16.7678\n",
      "reconstruction loss = 0.0125, similarity loss: 0.2529\n",
      "Epoch 91, loss = 0.3599, time: 16.9043\n",
      "reconstruction loss = 0.0122, similarity loss: 0.2376\n",
      "Epoch 92, loss = 0.3497, time: 16.7362\n",
      "reconstruction loss = 0.0115, similarity loss: 0.2346\n",
      "Epoch 93, loss = 0.3529, time: 16.6796\n",
      "reconstruction loss = 0.0122, similarity loss: 0.2309\n",
      "Epoch 94, loss = 0.3589, time: 16.6683\n",
      "reconstruction loss = 0.0110, similarity loss: 0.2485\n",
      "Epoch 95, loss = 0.3244, time: 16.8104\n",
      "reconstruction loss = 0.0107, similarity loss: 0.2178\n",
      "Epoch 96, loss = 0.3786, time: 16.6296\n",
      "reconstruction loss = 0.0113, similarity loss: 0.2652\n",
      "Epoch 97, loss = 0.3817, time: 16.6757\n",
      "reconstruction loss = 0.0114, similarity loss: 0.2681\n",
      "Epoch 98, loss = 0.3332, time: 16.6220\n",
      "reconstruction loss = 0.0103, similarity loss: 0.2301\n",
      "Epoch 99, loss = 0.3564, time: 16.7413\n",
      "reconstruction loss = 0.0109, similarity loss: 0.2476\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.9365, val.loss = 1.6745, val.acc = 0.4526\n",
      "Epoch 1, loss = 1.5814, val.loss = 1.5100, val.acc = 0.5034\n",
      "Epoch 2, loss = 1.4560, val.loss = 1.4212, val.acc = 0.5342\n",
      "Epoch 3, loss = 1.3779, val.loss = 1.3619, val.acc = 0.5488\n",
      "Epoch 4, loss = 1.3217, val.loss = 1.3187, val.acc = 0.5638\n",
      "Epoch 5, loss = 1.2782, val.loss = 1.2853, val.acc = 0.5740\n",
      "Epoch 6, loss = 1.2431, val.loss = 1.2585, val.acc = 0.5804\n",
      "Epoch 7, loss = 1.2136, val.loss = 1.2364, val.acc = 0.5878\n",
      "Epoch 8, loss = 1.1883, val.loss = 1.2177, val.acc = 0.5922\n",
      "Epoch 9, loss = 1.1662, val.loss = 1.2018, val.acc = 0.5948\n",
      "Epoch 10, loss = 1.1465, val.loss = 1.1879, val.acc = 0.5988\n",
      "Epoch 11, loss = 1.1288, val.loss = 1.1757, val.acc = 0.6050\n",
      "Epoch 12, loss = 1.1127, val.loss = 1.1648, val.acc = 0.6076\n",
      "Epoch 13, loss = 1.0979, val.loss = 1.1551, val.acc = 0.6098\n",
      "Epoch 14, loss = 1.0843, val.loss = 1.1463, val.acc = 0.6134\n",
      "Epoch 15, loss = 1.0716, val.loss = 1.1384, val.acc = 0.6172\n",
      "Epoch 16, loss = 1.0597, val.loss = 1.1311, val.acc = 0.6210\n",
      "Epoch 17, loss = 1.0485, val.loss = 1.1244, val.acc = 0.6234\n",
      "Epoch 18, loss = 1.0379, val.loss = 1.1183, val.acc = 0.6244\n",
      "Epoch 19, loss = 1.0279, val.loss = 1.1126, val.acc = 0.6260\n",
      "Epoch 20, loss = 1.0184, val.loss = 1.1074, val.acc = 0.6284\n",
      "Epoch 21, loss = 1.0093, val.loss = 1.1025, val.acc = 0.6288\n",
      "Epoch 22, loss = 1.0007, val.loss = 1.0979, val.acc = 0.6302\n",
      "Epoch 23, loss = 0.9924, val.loss = 1.0936, val.acc = 0.6316\n",
      "Epoch 24, loss = 0.9844, val.loss = 1.0896, val.acc = 0.6322\n",
      "Epoch 25, loss = 0.9767, val.loss = 1.0858, val.acc = 0.6340\n",
      "Epoch 26, loss = 0.9693, val.loss = 1.0822, val.acc = 0.6352\n",
      "Epoch 27, loss = 0.9622, val.loss = 1.0789, val.acc = 0.6358\n",
      "Epoch 28, loss = 0.9553, val.loss = 1.0757, val.acc = 0.6366\n",
      "Epoch 29, loss = 0.9486, val.loss = 1.0727, val.acc = 0.6366\n",
      "Epoch 30, loss = 0.9422, val.loss = 1.0698, val.acc = 0.6374\n",
      "Epoch 31, loss = 0.9359, val.loss = 1.0671, val.acc = 0.6372\n",
      "Epoch 32, loss = 0.9298, val.loss = 1.0645, val.acc = 0.6388\n",
      "Epoch 33, loss = 0.9239, val.loss = 1.0621, val.acc = 0.6392\n",
      "Epoch 34, loss = 0.9181, val.loss = 1.0598, val.acc = 0.6394\n",
      "Epoch 35, loss = 0.9125, val.loss = 1.0576, val.acc = 0.6404\n",
      "Epoch 36, loss = 0.9070, val.loss = 1.0555, val.acc = 0.6410\n",
      "Epoch 37, loss = 0.9017, val.loss = 1.0535, val.acc = 0.6416\n",
      "Epoch 38, loss = 0.8964, val.loss = 1.0515, val.acc = 0.6426\n",
      "Epoch 39, loss = 0.8913, val.loss = 1.0497, val.acc = 0.6438\n",
      "Epoch 40, loss = 0.8864, val.loss = 1.0480, val.acc = 0.6450\n",
      "Epoch 41, loss = 0.8815, val.loss = 1.0463, val.acc = 0.6452\n",
      "Epoch 42, loss = 0.8767, val.loss = 1.0447, val.acc = 0.6444\n",
      "Epoch 43, loss = 0.8721, val.loss = 1.0431, val.acc = 0.6452\n",
      "Epoch 44, loss = 0.8675, val.loss = 1.0417, val.acc = 0.6460\n",
      "Epoch 45, loss = 0.8630, val.loss = 1.0403, val.acc = 0.6462\n",
      "Epoch 46, loss = 0.8586, val.loss = 1.0389, val.acc = 0.6464\n",
      "Epoch 47, loss = 0.8543, val.loss = 1.0376, val.acc = 0.6462\n",
      "Epoch 48, loss = 0.8501, val.loss = 1.0364, val.acc = 0.6468\n",
      "Epoch 49, loss = 0.8459, val.loss = 1.0352, val.acc = 0.6466\n",
      "Epoch 50, loss = 0.8419, val.loss = 1.0341, val.acc = 0.6472\n",
      "Epoch 51, loss = 0.8379, val.loss = 1.0330, val.acc = 0.6476\n",
      "Epoch 52, loss = 0.8339, val.loss = 1.0320, val.acc = 0.6480\n",
      "Epoch 53, loss = 0.8301, val.loss = 1.0310, val.acc = 0.6480\n",
      "Epoch 54, loss = 0.8263, val.loss = 1.0300, val.acc = 0.6480\n",
      "Epoch 55, loss = 0.8225, val.loss = 1.0291, val.acc = 0.6474\n",
      "Epoch 56, loss = 0.8189, val.loss = 1.0282, val.acc = 0.6480\n",
      "Epoch 57, loss = 0.8152, val.loss = 1.0274, val.acc = 0.6484\n",
      "Epoch 58, loss = 0.8117, val.loss = 1.0266, val.acc = 0.6492\n",
      "Epoch 59, loss = 0.8082, val.loss = 1.0258, val.acc = 0.6496\n",
      "Epoch 60, loss = 0.8047, val.loss = 1.0251, val.acc = 0.6508\n",
      "Epoch 61, loss = 0.8013, val.loss = 1.0244, val.acc = 0.6520\n",
      "Epoch 62, loss = 0.7980, val.loss = 1.0238, val.acc = 0.6526\n",
      "Epoch 63, loss = 0.7947, val.loss = 1.0231, val.acc = 0.6522\n",
      "Epoch 64, loss = 0.7914, val.loss = 1.0225, val.acc = 0.6524\n",
      "Epoch 65, loss = 0.7882, val.loss = 1.0219, val.acc = 0.6528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.7850, val.loss = 1.0214, val.acc = 0.6534\n",
      "Epoch 67, loss = 0.7819, val.loss = 1.0208, val.acc = 0.6538\n",
      "Epoch 68, loss = 0.7788, val.loss = 1.0203, val.acc = 0.6538\n",
      "Epoch 69, loss = 0.7758, val.loss = 1.0199, val.acc = 0.6546\n",
      "Epoch 70, loss = 0.7728, val.loss = 1.0194, val.acc = 0.6554\n",
      "Epoch 71, loss = 0.7698, val.loss = 1.0190, val.acc = 0.6560\n",
      "Epoch 72, loss = 0.7669, val.loss = 1.0186, val.acc = 0.6564\n",
      "Epoch 73, loss = 0.7640, val.loss = 1.0182, val.acc = 0.6562\n",
      "Epoch 74, loss = 0.7611, val.loss = 1.0178, val.acc = 0.6566\n",
      "Epoch 75, loss = 0.7583, val.loss = 1.0175, val.acc = 0.6568\n",
      "Epoch 76, loss = 0.7555, val.loss = 1.0172, val.acc = 0.6576\n",
      "Epoch 77, loss = 0.7528, val.loss = 1.0169, val.acc = 0.6580\n",
      "Epoch 78, loss = 0.7500, val.loss = 1.0166, val.acc = 0.6574\n",
      "Epoch 79, loss = 0.7474, val.loss = 1.0163, val.acc = 0.6574\n",
      "Epoch 80, loss = 0.7447, val.loss = 1.0161, val.acc = 0.6576\n",
      "Epoch 81, loss = 0.7421, val.loss = 1.0159, val.acc = 0.6576\n",
      "Epoch 82, loss = 0.7395, val.loss = 1.0156, val.acc = 0.6582\n",
      "Epoch 83, loss = 0.7369, val.loss = 1.0154, val.acc = 0.6582\n",
      "Epoch 84, loss = 0.7344, val.loss = 1.0153, val.acc = 0.6582\n",
      "Epoch 85, loss = 0.7319, val.loss = 1.0151, val.acc = 0.6586\n",
      "Epoch 86, loss = 0.7294, val.loss = 1.0149, val.acc = 0.6586\n",
      "Epoch 87, loss = 0.7269, val.loss = 1.0148, val.acc = 0.6594\n",
      "Epoch 88, loss = 0.7245, val.loss = 1.0147, val.acc = 0.6598\n",
      "Epoch 89, loss = 0.7221, val.loss = 1.0146, val.acc = 0.6602\n",
      "Epoch 90, loss = 0.7197, val.loss = 1.0145, val.acc = 0.6598\n",
      "Epoch 91, loss = 0.7174, val.loss = 1.0144, val.acc = 0.6602\n",
      "Epoch 92, loss = 0.7150, val.loss = 1.0144, val.acc = 0.6600\n",
      "Epoch 93, loss = 0.7127, val.loss = 1.0143, val.acc = 0.6600\n",
      "Epoch 94, loss = 0.7104, val.loss = 1.0143, val.acc = 0.6602\n",
      "Epoch 95, loss = 0.7082, val.loss = 1.0142, val.acc = 0.6598\n",
      "Epoch 96, loss = 0.7059, val.loss = 1.0142, val.acc = 0.6606\n",
      "Epoch 97, loss = 0.7037, val.loss = 1.0142, val.acc = 0.6600\n",
      "Epoch 98, loss = 0.7015, val.loss = 1.0142, val.acc = 0.6604\n",
      "Epoch 99, loss = 0.6993, val.loss = 1.0143, val.acc = 0.6602\n",
      "Epoch 100, loss = 0.6972, val.loss = 1.0143, val.acc = 0.6598\n",
      "Epoch 101, loss = 0.6951, val.loss = 1.0143, val.acc = 0.6592\n",
      "Epoch 102, loss = 0.6929, val.loss = 1.0144, val.acc = 0.6596\n",
      "Epoch 103, loss = 0.6908, val.loss = 1.0144, val.acc = 0.6598\n",
      "Epoch 104, loss = 0.6888, val.loss = 1.0145, val.acc = 0.6598\n",
      "Epoch 105, loss = 0.6867, val.loss = 1.0146, val.acc = 0.6602\n",
      "Epoch 106, loss = 0.6847, val.loss = 1.0147, val.acc = 0.6602\n",
      "Epoch 107, loss = 0.6826, val.loss = 1.0148, val.acc = 0.6594\n",
      "Epoch 108, loss = 0.6806, val.loss = 1.0149, val.acc = 0.6594\n",
      "Epoch 109, loss = 0.6787, val.loss = 1.0150, val.acc = 0.6592\n",
      "Epoch 110, loss = 0.6767, val.loss = 1.0151, val.acc = 0.6592\n",
      "Epoch 111, loss = 0.6747, val.loss = 1.0153, val.acc = 0.6590\n",
      "Epoch 112, loss = 0.6728, val.loss = 1.0154, val.acc = 0.6588\n",
      "Epoch 113, loss = 0.6709, val.loss = 1.0156, val.acc = 0.6588\n",
      "Epoch 114, loss = 0.6690, val.loss = 1.0158, val.acc = 0.6584\n",
      "Epoch 115, loss = 0.6671, val.loss = 1.0159, val.acc = 0.6582\n",
      "Epoch 116, loss = 0.6652, val.loss = 1.0161, val.acc = 0.6582\n",
      "Epoch 117, loss = 0.6634, val.loss = 1.0163, val.acc = 0.6576\n",
      "Epoch 118, loss = 0.6615, val.loss = 1.0165, val.acc = 0.6576\n",
      "Epoch 119, loss = 0.6597, val.loss = 1.0167, val.acc = 0.6578\n",
      "Epoch 120, loss = 0.6579, val.loss = 1.0169, val.acc = 0.6578\n",
      "Epoch 121, loss = 0.6561, val.loss = 1.0171, val.acc = 0.6574\n",
      "Epoch 122, loss = 0.6543, val.loss = 1.0173, val.acc = 0.6578\n",
      "Epoch 123, loss = 0.6525, val.loss = 1.0176, val.acc = 0.6576\n",
      "Epoch 124, loss = 0.6508, val.loss = 1.0178, val.acc = 0.6576\n",
      "Epoch 125, loss = 0.6490, val.loss = 1.0180, val.acc = 0.6580\n",
      "Epoch 126, loss = 0.6473, val.loss = 1.0183, val.acc = 0.6584\n",
      "Epoch 127, loss = 0.6456, val.loss = 1.0186, val.acc = 0.6576\n",
      "Epoch 128, loss = 0.6439, val.loss = 1.0188, val.acc = 0.6576\n",
      "Epoch 129, loss = 0.6422, val.loss = 1.0191, val.acc = 0.6574\n",
      "Epoch 130, loss = 0.6405, val.loss = 1.0194, val.acc = 0.6574\n",
      "Epoch 131, loss = 0.6389, val.loss = 1.0196, val.acc = 0.6576\n",
      "Epoch 132, loss = 0.6372, val.loss = 1.0199, val.acc = 0.6576\n",
      "Epoch 133, loss = 0.6356, val.loss = 1.0202, val.acc = 0.6576\n",
      "Epoch 134, loss = 0.6339, val.loss = 1.0205, val.acc = 0.6572\n",
      "Epoch 135, loss = 0.6323, val.loss = 1.0208, val.acc = 0.6570\n",
      "Epoch 136, loss = 0.6307, val.loss = 1.0211, val.acc = 0.6568\n",
      "Epoch 137, loss = 0.6291, val.loss = 1.0214, val.acc = 0.6566\n",
      "Epoch 138, loss = 0.6275, val.loss = 1.0217, val.acc = 0.6558\n",
      "Epoch 139, loss = 0.6260, val.loss = 1.0221, val.acc = 0.6554\n",
      "Epoch 140, loss = 0.6244, val.loss = 1.0224, val.acc = 0.6562\n",
      "Epoch 141, loss = 0.6229, val.loss = 1.0227, val.acc = 0.6562\n",
      "Epoch 142, loss = 0.6213, val.loss = 1.0231, val.acc = 0.6562\n",
      "Epoch 143, loss = 0.6198, val.loss = 1.0234, val.acc = 0.6560\n",
      "Epoch 144, loss = 0.6183, val.loss = 1.0237, val.acc = 0.6564\n",
      "Epoch 145, loss = 0.6168, val.loss = 1.0241, val.acc = 0.6560\n",
      "Epoch 146, loss = 0.6153, val.loss = 1.0245, val.acc = 0.6556\n",
      "Epoch 147, loss = 0.6138, val.loss = 1.0248, val.acc = 0.6560\n",
      "Epoch 148, loss = 0.6123, val.loss = 1.0252, val.acc = 0.6560\n",
      "Epoch 149, loss = 0.6109, val.loss = 1.0256, val.acc = 0.6554\n",
      "Rep: 1, te.acc = 0.6420\n",
      "\n",
      "All reps test.acc:\n",
      "[0.642]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 10\n",
    "vis = visdom.Visdom(port=8097,env='ae'+str(pars.decoder_channel)+'_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T07:44:32.311997Z",
     "start_time": "2022-04-02T07:12:42.623036Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_3/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_20_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(3, 32, 32))\n",
      "    (deconv): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.7734, time: 16.7825\n",
      "reconstruction loss = 0.0623, similarity loss: 0.5274\n",
      "Epoch 1, loss = 1.3383, time: 16.6820\n",
      "reconstruction loss = 0.0374, similarity loss: 0.5902\n",
      "Epoch 2, loss = 1.3718, time: 16.7248\n",
      "reconstruction loss = 0.0293, similarity loss: 0.7868\n",
      "Epoch 3, loss = 1.0574, time: 16.6679\n",
      "reconstruction loss = 0.0252, similarity loss: 0.5541\n",
      "Epoch 4, loss = 1.1135, time: 16.1379\n",
      "reconstruction loss = 0.0257, similarity loss: 0.5998\n",
      "Epoch 5, loss = 1.0959, time: 16.1604\n",
      "reconstruction loss = 0.0202, similarity loss: 0.6922\n",
      "Epoch 6, loss = 0.9048, time: 16.0840\n",
      "reconstruction loss = 0.0193, similarity loss: 0.5179\n",
      "Epoch 7, loss = 0.9247, time: 16.1607\n",
      "reconstruction loss = 0.0209, similarity loss: 0.5076\n",
      "Epoch 8, loss = 0.8566, time: 16.1307\n",
      "reconstruction loss = 0.0196, similarity loss: 0.4645\n",
      "Epoch 9, loss = 0.8165, time: 16.0797\n",
      "reconstruction loss = 0.0171, similarity loss: 0.4747\n",
      "Epoch 10, loss = 0.8908, time: 16.0459\n",
      "reconstruction loss = 0.0206, similarity loss: 0.4787\n",
      "Epoch 11, loss = 0.7516, time: 16.3761\n",
      "reconstruction loss = 0.0202, similarity loss: 0.3480\n",
      "Epoch 12, loss = 0.7600, time: 16.1287\n",
      "reconstruction loss = 0.0183, similarity loss: 0.3938\n",
      "Epoch 13, loss = 0.6733, time: 16.1309\n",
      "reconstruction loss = 0.0167, similarity loss: 0.3388\n",
      "Epoch 14, loss = 0.8283, time: 16.0577\n",
      "reconstruction loss = 0.0185, similarity loss: 0.4584\n",
      "Epoch 15, loss = 0.7164, time: 16.2349\n",
      "reconstruction loss = 0.0174, similarity loss: 0.3679\n",
      "Epoch 16, loss = 0.7166, time: 16.2034\n",
      "reconstruction loss = 0.0176, similarity loss: 0.3644\n",
      "Epoch 17, loss = 0.6719, time: 16.1147\n",
      "reconstruction loss = 0.0158, similarity loss: 0.3563\n",
      "Epoch 18, loss = 0.6842, time: 16.0505\n",
      "reconstruction loss = 0.0167, similarity loss: 0.3502\n",
      "Epoch 19, loss = 0.7243, time: 16.2020\n",
      "reconstruction loss = 0.0177, similarity loss: 0.3701\n",
      "Epoch 20, loss = 0.6423, time: 16.0512\n",
      "reconstruction loss = 0.0163, similarity loss: 0.3164\n",
      "Epoch 21, loss = 0.6615, time: 16.0935\n",
      "reconstruction loss = 0.0158, similarity loss: 0.3447\n",
      "Epoch 22, loss = 0.6361, time: 16.3165\n",
      "reconstruction loss = 0.0176, similarity loss: 0.2832\n",
      "Epoch 23, loss = 0.6629, time: 16.6538\n",
      "reconstruction loss = 0.0171, similarity loss: 0.3217\n",
      "Epoch 24, loss = 0.6777, time: 16.6416\n",
      "reconstruction loss = 0.0175, similarity loss: 0.3274\n",
      "Epoch 25, loss = 0.6619, time: 16.7714\n",
      "reconstruction loss = 0.0141, similarity loss: 0.3791\n",
      "Epoch 26, loss = 0.5789, time: 16.7521\n",
      "reconstruction loss = 0.0143, similarity loss: 0.2927\n",
      "Epoch 27, loss = 0.6745, time: 16.8034\n",
      "reconstruction loss = 0.0162, similarity loss: 0.3514\n",
      "Epoch 28, loss = 0.6373, time: 16.7706\n",
      "reconstruction loss = 0.0164, similarity loss: 0.3099\n",
      "Epoch 29, loss = 0.6571, time: 16.6335\n",
      "reconstruction loss = 0.0163, similarity loss: 0.3302\n",
      "Epoch 30, loss = 0.5618, time: 16.6588\n",
      "reconstruction loss = 0.0141, similarity loss: 0.2791\n",
      "Epoch 31, loss = 0.6320, time: 16.6595\n",
      "reconstruction loss = 0.0160, similarity loss: 0.3127\n",
      "Epoch 32, loss = 0.6470, time: 16.7880\n",
      "reconstruction loss = 0.0154, similarity loss: 0.3393\n",
      "Epoch 33, loss = 0.6446, time: 16.7309\n",
      "reconstruction loss = 0.0155, similarity loss: 0.3350\n",
      "Epoch 34, loss = 0.5969, time: 16.7452\n",
      "reconstruction loss = 0.0150, similarity loss: 0.2965\n",
      "Epoch 35, loss = 0.6681, time: 16.7338\n",
      "reconstruction loss = 0.0170, similarity loss: 0.3272\n",
      "Epoch 36, loss = 0.5612, time: 16.8717\n",
      "reconstruction loss = 0.0148, similarity loss: 0.2642\n",
      "Epoch 37, loss = 0.5981, time: 16.7164\n",
      "reconstruction loss = 0.0134, similarity loss: 0.3304\n",
      "Epoch 38, loss = 0.6424, time: 16.7218\n",
      "reconstruction loss = 0.0156, similarity loss: 0.3312\n",
      "Epoch 39, loss = 0.6350, time: 16.7600\n",
      "reconstruction loss = 0.0162, similarity loss: 0.3113\n",
      "Epoch 40, loss = 0.6073, time: 16.6991\n",
      "reconstruction loss = 0.0160, similarity loss: 0.2864\n",
      "Epoch 41, loss = 0.6311, time: 16.7860\n",
      "reconstruction loss = 0.0159, similarity loss: 0.3130\n",
      "Epoch 42, loss = 0.5685, time: 16.8170\n",
      "reconstruction loss = 0.0146, similarity loss: 0.2764\n",
      "Epoch 43, loss = 0.6142, time: 16.8342\n",
      "reconstruction loss = 0.0155, similarity loss: 0.3034\n",
      "Epoch 44, loss = 0.6383, time: 16.6865\n",
      "reconstruction loss = 0.0159, similarity loss: 0.3207\n",
      "Epoch 45, loss = 0.5832, time: 16.7044\n",
      "reconstruction loss = 0.0143, similarity loss: 0.2970\n",
      "Epoch 46, loss = 0.6414, time: 16.6403\n",
      "reconstruction loss = 0.0160, similarity loss: 0.3211\n",
      "Epoch 47, loss = 0.6055, time: 16.7567\n",
      "reconstruction loss = 0.0144, similarity loss: 0.3184\n",
      "Epoch 48, loss = 0.5869, time: 16.7768\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2836\n",
      "Epoch 49, loss = 0.5597, time: 16.7048\n",
      "reconstruction loss = 0.0136, similarity loss: 0.2882\n",
      "Epoch 50, loss = 0.6059, time: 16.8781\n",
      "reconstruction loss = 0.0154, similarity loss: 0.2980\n",
      "Epoch 51, loss = 0.5701, time: 16.8260\n",
      "reconstruction loss = 0.0149, similarity loss: 0.2727\n",
      "Epoch 52, loss = 0.5750, time: 16.8243\n",
      "reconstruction loss = 0.0145, similarity loss: 0.2847\n",
      "Epoch 53, loss = 0.5671, time: 16.7261\n",
      "reconstruction loss = 0.0137, similarity loss: 0.2936\n",
      "Epoch 54, loss = 0.5483, time: 16.7908\n",
      "reconstruction loss = 0.0136, similarity loss: 0.2764\n",
      "Epoch 55, loss = 0.5990, time: 16.7559\n",
      "reconstruction loss = 0.0138, similarity loss: 0.3230\n",
      "Epoch 56, loss = 0.5681, time: 16.7714\n",
      "reconstruction loss = 0.0134, similarity loss: 0.2996\n",
      "Epoch 57, loss = 0.5333, time: 16.8475\n",
      "reconstruction loss = 0.0139, similarity loss: 0.2551\n",
      "Epoch 58, loss = 0.5773, time: 16.2088\n",
      "reconstruction loss = 0.0147, similarity loss: 0.2825\n",
      "Epoch 59, loss = 0.6096, time: 16.1733\n",
      "reconstruction loss = 0.0143, similarity loss: 0.3227\n",
      "Epoch 60, loss = 0.5793, time: 16.0818\n",
      "reconstruction loss = 0.0141, similarity loss: 0.2981\n",
      "Epoch 61, loss = 0.5380, time: 16.1483\n",
      "reconstruction loss = 0.0121, similarity loss: 0.2951\n",
      "Epoch 62, loss = 0.6003, time: 16.2057\n",
      "reconstruction loss = 0.0134, similarity loss: 0.3314\n",
      "Epoch 63, loss = 0.5456, time: 16.2723\n",
      "reconstruction loss = 0.0140, similarity loss: 0.2654\n",
      "Epoch 64, loss = 0.5250, time: 16.0948\n",
      "reconstruction loss = 0.0138, similarity loss: 0.2483\n",
      "Epoch 65, loss = 0.5348, time: 16.1490\n",
      "reconstruction loss = 0.0136, similarity loss: 0.2618\n",
      "Epoch 66, loss = 0.5419, time: 16.2851\n",
      "reconstruction loss = 0.0129, similarity loss: 0.2830\n",
      "Epoch 67, loss = 0.5370, time: 16.1111\n",
      "reconstruction loss = 0.0134, similarity loss: 0.2682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.5706, time: 16.1485\n",
      "reconstruction loss = 0.0140, similarity loss: 0.2897\n",
      "Epoch 69, loss = 0.6140, time: 16.2167\n",
      "reconstruction loss = 0.0141, similarity loss: 0.3317\n",
      "Epoch 70, loss = 0.5539, time: 16.2416\n",
      "reconstruction loss = 0.0130, similarity loss: 0.2930\n",
      "Epoch 71, loss = 0.5268, time: 16.1777\n",
      "reconstruction loss = 0.0143, similarity loss: 0.2404\n",
      "Epoch 72, loss = 0.5135, time: 16.1185\n",
      "reconstruction loss = 0.0114, similarity loss: 0.2857\n",
      "Epoch 73, loss = 0.5586, time: 16.3037\n",
      "reconstruction loss = 0.0129, similarity loss: 0.3007\n",
      "Epoch 74, loss = 0.5375, time: 16.1924\n",
      "reconstruction loss = 0.0128, similarity loss: 0.2823\n",
      "Epoch 75, loss = 0.5153, time: 16.2862\n",
      "reconstruction loss = 0.0126, similarity loss: 0.2638\n",
      "Epoch 76, loss = 0.5251, time: 16.2513\n",
      "reconstruction loss = 0.0119, similarity loss: 0.2877\n",
      "Epoch 77, loss = 0.5116, time: 16.7958\n",
      "reconstruction loss = 0.0113, similarity loss: 0.2853\n",
      "Epoch 78, loss = 0.4912, time: 16.7948\n",
      "reconstruction loss = 0.0109, similarity loss: 0.2729\n",
      "Epoch 79, loss = 0.5136, time: 16.8159\n",
      "reconstruction loss = 0.0115, similarity loss: 0.2827\n",
      "Epoch 80, loss = 0.5121, time: 16.7385\n",
      "reconstruction loss = 0.0108, similarity loss: 0.2961\n",
      "Epoch 81, loss = 0.4750, time: 16.9319\n",
      "reconstruction loss = 0.0106, similarity loss: 0.2622\n",
      "Epoch 82, loss = 0.5334, time: 16.7749\n",
      "reconstruction loss = 0.0111, similarity loss: 0.3108\n",
      "Epoch 83, loss = 0.4659, time: 16.7429\n",
      "reconstruction loss = 0.0104, similarity loss: 0.2578\n",
      "Epoch 84, loss = 0.4885, time: 16.7266\n",
      "reconstruction loss = 0.0111, similarity loss: 0.2659\n",
      "Epoch 85, loss = 0.4487, time: 16.7806\n",
      "reconstruction loss = 0.0095, similarity loss: 0.2582\n",
      "Epoch 86, loss = 0.4882, time: 16.8450\n",
      "reconstruction loss = 0.0103, similarity loss: 0.2821\n",
      "Epoch 87, loss = 0.4985, time: 16.8414\n",
      "reconstruction loss = 0.0104, similarity loss: 0.2898\n",
      "Epoch 88, loss = 0.4705, time: 16.7741\n",
      "reconstruction loss = 0.0107, similarity loss: 0.2565\n",
      "Epoch 89, loss = 0.4618, time: 16.7807\n",
      "reconstruction loss = 0.0101, similarity loss: 0.2595\n",
      "Epoch 90, loss = 0.4069, time: 16.5954\n",
      "reconstruction loss = 0.0093, similarity loss: 0.2201\n",
      "Epoch 91, loss = 0.4665, time: 16.6648\n",
      "reconstruction loss = 0.0094, similarity loss: 0.2790\n",
      "Epoch 92, loss = 0.4701, time: 16.7124\n",
      "reconstruction loss = 0.0100, similarity loss: 0.2705\n",
      "Epoch 93, loss = 0.4217, time: 16.7647\n",
      "reconstruction loss = 0.0091, similarity loss: 0.2398\n",
      "Epoch 94, loss = 0.4560, time: 16.7751\n",
      "reconstruction loss = 0.0092, similarity loss: 0.2724\n",
      "Epoch 95, loss = 0.4196, time: 16.6779\n",
      "reconstruction loss = 0.0091, similarity loss: 0.2372\n",
      "Epoch 96, loss = 0.4749, time: 16.8290\n",
      "reconstruction loss = 0.0099, similarity loss: 0.2762\n",
      "Epoch 97, loss = 0.4160, time: 16.7271\n",
      "reconstruction loss = 0.0088, similarity loss: 0.2393\n",
      "Epoch 98, loss = 0.4914, time: 16.7901\n",
      "reconstruction loss = 0.0103, similarity loss: 0.2844\n",
      "Epoch 99, loss = 0.4036, time: 16.6894\n",
      "reconstruction loss = 0.0086, similarity loss: 0.2313\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.9885, val.loss = 1.7540, val.acc = 0.4214\n",
      "Epoch 1, loss = 1.6660, val.loss = 1.5889, val.acc = 0.4794\n",
      "Epoch 2, loss = 1.5385, val.loss = 1.4954, val.acc = 0.5100\n",
      "Epoch 3, loss = 1.4567, val.loss = 1.4309, val.acc = 0.5292\n",
      "Epoch 4, loss = 1.3969, val.loss = 1.3826, val.acc = 0.5448\n",
      "Epoch 5, loss = 1.3501, val.loss = 1.3445, val.acc = 0.5588\n",
      "Epoch 6, loss = 1.3121, val.loss = 1.3136, val.acc = 0.5696\n",
      "Epoch 7, loss = 1.2802, val.loss = 1.2877, val.acc = 0.5806\n",
      "Epoch 8, loss = 1.2528, val.loss = 1.2658, val.acc = 0.5892\n",
      "Epoch 9, loss = 1.2290, val.loss = 1.2469, val.acc = 0.5944\n",
      "Epoch 10, loss = 1.2078, val.loss = 1.2304, val.acc = 0.5976\n",
      "Epoch 11, loss = 1.1889, val.loss = 1.2157, val.acc = 0.6022\n",
      "Epoch 12, loss = 1.1717, val.loss = 1.2027, val.acc = 0.6068\n",
      "Epoch 13, loss = 1.1560, val.loss = 1.1911, val.acc = 0.6084\n",
      "Epoch 14, loss = 1.1416, val.loss = 1.1805, val.acc = 0.6110\n",
      "Epoch 15, loss = 1.1282, val.loss = 1.1709, val.acc = 0.6136\n",
      "Epoch 16, loss = 1.1158, val.loss = 1.1621, val.acc = 0.6174\n",
      "Epoch 17, loss = 1.1041, val.loss = 1.1540, val.acc = 0.6186\n",
      "Epoch 18, loss = 1.0932, val.loss = 1.1465, val.acc = 0.6196\n",
      "Epoch 19, loss = 1.0828, val.loss = 1.1396, val.acc = 0.6210\n",
      "Epoch 20, loss = 1.0730, val.loss = 1.1332, val.acc = 0.6228\n",
      "Epoch 21, loss = 1.0637, val.loss = 1.1272, val.acc = 0.6246\n",
      "Epoch 22, loss = 1.0548, val.loss = 1.1216, val.acc = 0.6282\n",
      "Epoch 23, loss = 1.0464, val.loss = 1.1163, val.acc = 0.6296\n",
      "Epoch 24, loss = 1.0383, val.loss = 1.1114, val.acc = 0.6300\n",
      "Epoch 25, loss = 1.0305, val.loss = 1.1067, val.acc = 0.6312\n",
      "Epoch 26, loss = 1.0230, val.loss = 1.1024, val.acc = 0.6334\n",
      "Epoch 27, loss = 1.0158, val.loss = 1.0982, val.acc = 0.6348\n",
      "Epoch 28, loss = 1.0089, val.loss = 1.0943, val.acc = 0.6366\n",
      "Epoch 29, loss = 1.0022, val.loss = 1.0906, val.acc = 0.6374\n",
      "Epoch 30, loss = 0.9957, val.loss = 1.0871, val.acc = 0.6400\n",
      "Epoch 31, loss = 0.9894, val.loss = 1.0837, val.acc = 0.6408\n",
      "Epoch 32, loss = 0.9833, val.loss = 1.0805, val.acc = 0.6424\n",
      "Epoch 33, loss = 0.9774, val.loss = 1.0775, val.acc = 0.6432\n",
      "Epoch 34, loss = 0.9717, val.loss = 1.0746, val.acc = 0.6444\n",
      "Epoch 35, loss = 0.9661, val.loss = 1.0718, val.acc = 0.6466\n",
      "Epoch 36, loss = 0.9607, val.loss = 1.0692, val.acc = 0.6482\n",
      "Epoch 37, loss = 0.9554, val.loss = 1.0667, val.acc = 0.6490\n",
      "Epoch 38, loss = 0.9502, val.loss = 1.0642, val.acc = 0.6496\n",
      "Epoch 39, loss = 0.9452, val.loss = 1.0619, val.acc = 0.6510\n",
      "Epoch 40, loss = 0.9403, val.loss = 1.0597, val.acc = 0.6520\n",
      "Epoch 41, loss = 0.9355, val.loss = 1.0576, val.acc = 0.6528\n",
      "Epoch 42, loss = 0.9308, val.loss = 1.0555, val.acc = 0.6540\n",
      "Epoch 43, loss = 0.9263, val.loss = 1.0535, val.acc = 0.6540\n",
      "Epoch 44, loss = 0.9218, val.loss = 1.0516, val.acc = 0.6552\n",
      "Epoch 45, loss = 0.9174, val.loss = 1.0498, val.acc = 0.6552\n",
      "Epoch 46, loss = 0.9131, val.loss = 1.0481, val.acc = 0.6560\n",
      "Epoch 47, loss = 0.9089, val.loss = 1.0464, val.acc = 0.6568\n",
      "Epoch 48, loss = 0.9047, val.loss = 1.0448, val.acc = 0.6566\n",
      "Epoch 49, loss = 0.9007, val.loss = 1.0432, val.acc = 0.6572\n",
      "Epoch 50, loss = 0.8967, val.loss = 1.0417, val.acc = 0.6582\n",
      "Epoch 51, loss = 0.8928, val.loss = 1.0403, val.acc = 0.6588\n",
      "Epoch 52, loss = 0.8890, val.loss = 1.0389, val.acc = 0.6596\n",
      "Epoch 53, loss = 0.8852, val.loss = 1.0375, val.acc = 0.6606\n",
      "Epoch 54, loss = 0.8815, val.loss = 1.0362, val.acc = 0.6620\n",
      "Epoch 55, loss = 0.8779, val.loss = 1.0350, val.acc = 0.6616\n",
      "Epoch 56, loss = 0.8743, val.loss = 1.0338, val.acc = 0.6612\n",
      "Epoch 57, loss = 0.8708, val.loss = 1.0326, val.acc = 0.6620\n",
      "Epoch 58, loss = 0.8673, val.loss = 1.0314, val.acc = 0.6618\n",
      "Epoch 59, loss = 0.8639, val.loss = 1.0304, val.acc = 0.6628\n",
      "Epoch 60, loss = 0.8606, val.loss = 1.0293, val.acc = 0.6630\n",
      "Epoch 61, loss = 0.8573, val.loss = 1.0283, val.acc = 0.6642\n",
      "Epoch 62, loss = 0.8540, val.loss = 1.0273, val.acc = 0.6642\n",
      "Epoch 63, loss = 0.8508, val.loss = 1.0264, val.acc = 0.6646\n",
      "Epoch 64, loss = 0.8476, val.loss = 1.0254, val.acc = 0.6650\n",
      "Epoch 65, loss = 0.8445, val.loss = 1.0245, val.acc = 0.6648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.8414, val.loss = 1.0237, val.acc = 0.6650\n",
      "Epoch 67, loss = 0.8384, val.loss = 1.0229, val.acc = 0.6648\n",
      "Epoch 68, loss = 0.8354, val.loss = 1.0221, val.acc = 0.6658\n",
      "Epoch 69, loss = 0.8325, val.loss = 1.0213, val.acc = 0.6664\n",
      "Epoch 70, loss = 0.8296, val.loss = 1.0205, val.acc = 0.6658\n",
      "Epoch 71, loss = 0.8267, val.loss = 1.0198, val.acc = 0.6674\n",
      "Epoch 72, loss = 0.8238, val.loss = 1.0191, val.acc = 0.6678\n",
      "Epoch 73, loss = 0.8210, val.loss = 1.0185, val.acc = 0.6682\n",
      "Epoch 74, loss = 0.8183, val.loss = 1.0178, val.acc = 0.6684\n",
      "Epoch 75, loss = 0.8155, val.loss = 1.0172, val.acc = 0.6682\n",
      "Epoch 76, loss = 0.8128, val.loss = 1.0166, val.acc = 0.6678\n",
      "Epoch 77, loss = 0.8102, val.loss = 1.0160, val.acc = 0.6676\n",
      "Epoch 78, loss = 0.8076, val.loss = 1.0154, val.acc = 0.6680\n",
      "Epoch 79, loss = 0.8049, val.loss = 1.0149, val.acc = 0.6680\n",
      "Epoch 80, loss = 0.8024, val.loss = 1.0143, val.acc = 0.6690\n",
      "Epoch 81, loss = 0.7998, val.loss = 1.0138, val.acc = 0.6684\n",
      "Epoch 82, loss = 0.7973, val.loss = 1.0133, val.acc = 0.6682\n",
      "Epoch 83, loss = 0.7948, val.loss = 1.0129, val.acc = 0.6686\n",
      "Epoch 84, loss = 0.7924, val.loss = 1.0124, val.acc = 0.6688\n",
      "Epoch 85, loss = 0.7899, val.loss = 1.0120, val.acc = 0.6692\n",
      "Epoch 86, loss = 0.7875, val.loss = 1.0115, val.acc = 0.6690\n",
      "Epoch 87, loss = 0.7851, val.loss = 1.0111, val.acc = 0.6694\n",
      "Epoch 88, loss = 0.7828, val.loss = 1.0107, val.acc = 0.6692\n",
      "Epoch 89, loss = 0.7804, val.loss = 1.0104, val.acc = 0.6694\n",
      "Epoch 90, loss = 0.7781, val.loss = 1.0100, val.acc = 0.6694\n",
      "Epoch 91, loss = 0.7759, val.loss = 1.0097, val.acc = 0.6694\n",
      "Epoch 92, loss = 0.7736, val.loss = 1.0093, val.acc = 0.6694\n",
      "Epoch 93, loss = 0.7713, val.loss = 1.0090, val.acc = 0.6692\n",
      "Epoch 94, loss = 0.7691, val.loss = 1.0087, val.acc = 0.6692\n",
      "Epoch 95, loss = 0.7669, val.loss = 1.0084, val.acc = 0.6690\n",
      "Epoch 96, loss = 0.7648, val.loss = 1.0081, val.acc = 0.6690\n",
      "Epoch 97, loss = 0.7626, val.loss = 1.0078, val.acc = 0.6688\n",
      "Epoch 98, loss = 0.7605, val.loss = 1.0076, val.acc = 0.6688\n",
      "Epoch 99, loss = 0.7584, val.loss = 1.0073, val.acc = 0.6688\n",
      "Epoch 100, loss = 0.7563, val.loss = 1.0071, val.acc = 0.6680\n",
      "Epoch 101, loss = 0.7542, val.loss = 1.0069, val.acc = 0.6676\n",
      "Epoch 102, loss = 0.7521, val.loss = 1.0067, val.acc = 0.6676\n",
      "Epoch 103, loss = 0.7501, val.loss = 1.0064, val.acc = 0.6680\n",
      "Epoch 104, loss = 0.7481, val.loss = 1.0063, val.acc = 0.6682\n",
      "Epoch 105, loss = 0.7461, val.loss = 1.0061, val.acc = 0.6682\n",
      "Epoch 106, loss = 0.7441, val.loss = 1.0059, val.acc = 0.6680\n",
      "Epoch 107, loss = 0.7421, val.loss = 1.0057, val.acc = 0.6678\n",
      "Epoch 108, loss = 0.7402, val.loss = 1.0056, val.acc = 0.6670\n",
      "Epoch 109, loss = 0.7382, val.loss = 1.0054, val.acc = 0.6672\n",
      "Epoch 110, loss = 0.7363, val.loss = 1.0053, val.acc = 0.6678\n",
      "Epoch 111, loss = 0.7344, val.loss = 1.0051, val.acc = 0.6678\n",
      "Epoch 112, loss = 0.7325, val.loss = 1.0050, val.acc = 0.6680\n",
      "Epoch 113, loss = 0.7306, val.loss = 1.0049, val.acc = 0.6678\n",
      "Epoch 114, loss = 0.7288, val.loss = 1.0048, val.acc = 0.6678\n",
      "Epoch 115, loss = 0.7269, val.loss = 1.0047, val.acc = 0.6682\n",
      "Epoch 116, loss = 0.7251, val.loss = 1.0046, val.acc = 0.6682\n",
      "Epoch 117, loss = 0.7233, val.loss = 1.0046, val.acc = 0.6684\n",
      "Epoch 118, loss = 0.7215, val.loss = 1.0045, val.acc = 0.6688\n",
      "Epoch 119, loss = 0.7197, val.loss = 1.0044, val.acc = 0.6692\n",
      "Epoch 120, loss = 0.7180, val.loss = 1.0044, val.acc = 0.6698\n",
      "Epoch 121, loss = 0.7162, val.loss = 1.0043, val.acc = 0.6698\n",
      "Epoch 122, loss = 0.7145, val.loss = 1.0043, val.acc = 0.6698\n",
      "Epoch 123, loss = 0.7127, val.loss = 1.0042, val.acc = 0.6700\n",
      "Epoch 124, loss = 0.7110, val.loss = 1.0042, val.acc = 0.6696\n",
      "Epoch 125, loss = 0.7093, val.loss = 1.0042, val.acc = 0.6696\n",
      "Epoch 126, loss = 0.7076, val.loss = 1.0042, val.acc = 0.6700\n",
      "Epoch 127, loss = 0.7059, val.loss = 1.0042, val.acc = 0.6700\n",
      "Epoch 128, loss = 0.7043, val.loss = 1.0042, val.acc = 0.6694\n",
      "Epoch 129, loss = 0.7026, val.loss = 1.0042, val.acc = 0.6690\n",
      "Epoch 130, loss = 0.7010, val.loss = 1.0042, val.acc = 0.6686\n",
      "Epoch 131, loss = 0.6994, val.loss = 1.0042, val.acc = 0.6686\n",
      "Epoch 132, loss = 0.6977, val.loss = 1.0042, val.acc = 0.6686\n",
      "Epoch 133, loss = 0.6961, val.loss = 1.0042, val.acc = 0.6690\n",
      "Epoch 134, loss = 0.6945, val.loss = 1.0043, val.acc = 0.6688\n",
      "Epoch 135, loss = 0.6929, val.loss = 1.0043, val.acc = 0.6688\n",
      "Epoch 136, loss = 0.6914, val.loss = 1.0044, val.acc = 0.6690\n",
      "Epoch 137, loss = 0.6898, val.loss = 1.0044, val.acc = 0.6686\n",
      "Epoch 138, loss = 0.6883, val.loss = 1.0045, val.acc = 0.6682\n",
      "Epoch 139, loss = 0.6867, val.loss = 1.0045, val.acc = 0.6682\n",
      "Epoch 140, loss = 0.6852, val.loss = 1.0046, val.acc = 0.6678\n",
      "Epoch 141, loss = 0.6837, val.loss = 1.0047, val.acc = 0.6668\n",
      "Epoch 142, loss = 0.6821, val.loss = 1.0047, val.acc = 0.6668\n",
      "Epoch 143, loss = 0.6807, val.loss = 1.0048, val.acc = 0.6670\n",
      "Epoch 144, loss = 0.6792, val.loss = 1.0049, val.acc = 0.6666\n",
      "Epoch 145, loss = 0.6777, val.loss = 1.0050, val.acc = 0.6662\n",
      "Epoch 146, loss = 0.6762, val.loss = 1.0051, val.acc = 0.6662\n",
      "Epoch 147, loss = 0.6747, val.loss = 1.0052, val.acc = 0.6660\n",
      "Epoch 148, loss = 0.6733, val.loss = 1.0053, val.acc = 0.6656\n",
      "Epoch 149, loss = 0.6718, val.loss = 1.0054, val.acc = 0.6654\n",
      "Rep: 1, te.acc = 0.6418\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6418]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 20\n",
    "vis = visdom.Visdom(port=8097,env='ae'+str(pars.decoder_channel)+'_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T08:16:20.372346Z",
     "start_time": "2022-04-02T07:44:32.312997Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_3/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_50_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(3, 32, 32))\n",
      "    (deconv): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 3.2900, time: 16.3727\n",
      "reconstruction loss = 0.0523, similarity loss: 0.6757\n",
      "Epoch 1, loss = 2.8233, time: 16.0326\n",
      "reconstruction loss = 0.0441, similarity loss: 0.6162\n",
      "Epoch 2, loss = 2.6831, time: 16.0326\n",
      "reconstruction loss = 0.0393, similarity loss: 0.7159\n",
      "Epoch 3, loss = 2.3664, time: 16.0858\n",
      "reconstruction loss = 0.0363, similarity loss: 0.5528\n",
      "Epoch 4, loss = 2.4452, time: 16.1287\n",
      "reconstruction loss = 0.0357, similarity loss: 0.6612\n",
      "Epoch 5, loss = 2.2819, time: 16.2778\n",
      "reconstruction loss = 0.0356, similarity loss: 0.4994\n",
      "Epoch 6, loss = 1.7618, time: 16.1140\n",
      "reconstruction loss = 0.0243, similarity loss: 0.5485\n",
      "Epoch 7, loss = 1.3610, time: 16.0930\n",
      "reconstruction loss = 0.0166, similarity loss: 0.5321\n",
      "Epoch 8, loss = 1.4775, time: 16.0525\n",
      "reconstruction loss = 0.0165, similarity loss: 0.6527\n",
      "Epoch 9, loss = 1.2019, time: 16.1469\n",
      "reconstruction loss = 0.0136, similarity loss: 0.5221\n",
      "Epoch 10, loss = 1.3023, time: 16.1232\n",
      "reconstruction loss = 0.0137, similarity loss: 0.6174\n",
      "Epoch 11, loss = 1.2000, time: 16.0230\n",
      "reconstruction loss = 0.0138, similarity loss: 0.5110\n",
      "Epoch 12, loss = 1.0459, time: 16.1386\n",
      "reconstruction loss = 0.0115, similarity loss: 0.4724\n",
      "Epoch 13, loss = 1.2442, time: 16.1291\n",
      "reconstruction loss = 0.0148, similarity loss: 0.5027\n",
      "Epoch 14, loss = 1.0434, time: 16.1424\n",
      "reconstruction loss = 0.0115, similarity loss: 0.4698\n",
      "Epoch 15, loss = 1.0235, time: 16.1459\n",
      "reconstruction loss = 0.0114, similarity loss: 0.4526\n",
      "Epoch 16, loss = 0.9374, time: 16.7258\n",
      "reconstruction loss = 0.0099, similarity loss: 0.4412\n",
      "Epoch 17, loss = 0.9226, time: 16.7443\n",
      "reconstruction loss = 0.0106, similarity loss: 0.3925\n",
      "Epoch 18, loss = 0.8795, time: 16.6668\n",
      "reconstruction loss = 0.0097, similarity loss: 0.3925\n",
      "Epoch 19, loss = 0.9093, time: 16.8448\n",
      "reconstruction loss = 0.0106, similarity loss: 0.3771\n",
      "Epoch 20, loss = 0.9934, time: 16.6142\n",
      "reconstruction loss = 0.0111, similarity loss: 0.4408\n",
      "Epoch 21, loss = 0.8346, time: 16.6774\n",
      "reconstruction loss = 0.0091, similarity loss: 0.3808\n",
      "Epoch 22, loss = 0.9547, time: 16.7159\n",
      "reconstruction loss = 0.0112, similarity loss: 0.3951\n",
      "Epoch 23, loss = 0.8339, time: 16.7547\n",
      "reconstruction loss = 0.0089, similarity loss: 0.3907\n",
      "Epoch 24, loss = 0.8287, time: 16.6672\n",
      "reconstruction loss = 0.0099, similarity loss: 0.3355\n",
      "Epoch 25, loss = 0.7921, time: 16.7931\n",
      "reconstruction loss = 0.0088, similarity loss: 0.3520\n",
      "Epoch 26, loss = 0.8521, time: 16.8139\n",
      "reconstruction loss = 0.0099, similarity loss: 0.3556\n",
      "Epoch 27, loss = 0.8020, time: 16.7840\n",
      "reconstruction loss = 0.0093, similarity loss: 0.3388\n",
      "Epoch 28, loss = 0.8093, time: 16.7067\n",
      "reconstruction loss = 0.0089, similarity loss: 0.3650\n",
      "Epoch 29, loss = 0.7618, time: 16.6637\n",
      "reconstruction loss = 0.0089, similarity loss: 0.3145\n",
      "Epoch 30, loss = 0.8539, time: 16.8605\n",
      "reconstruction loss = 0.0096, similarity loss: 0.3714\n",
      "Epoch 31, loss = 0.7667, time: 16.7458\n",
      "reconstruction loss = 0.0088, similarity loss: 0.3257\n",
      "Epoch 32, loss = 0.8445, time: 16.6735\n",
      "reconstruction loss = 0.0092, similarity loss: 0.3847\n",
      "Epoch 33, loss = 0.7919, time: 16.6880\n",
      "reconstruction loss = 0.0090, similarity loss: 0.3417\n",
      "Epoch 34, loss = 0.7556, time: 16.7360\n",
      "reconstruction loss = 0.0078, similarity loss: 0.3650\n",
      "Epoch 35, loss = 0.7306, time: 16.8117\n",
      "reconstruction loss = 0.0078, similarity loss: 0.3384\n",
      "Epoch 36, loss = 0.7864, time: 16.6795\n",
      "reconstruction loss = 0.0082, similarity loss: 0.3750\n",
      "Epoch 37, loss = 0.7948, time: 16.7406\n",
      "reconstruction loss = 0.0088, similarity loss: 0.3552\n",
      "Epoch 38, loss = 0.7955, time: 16.6169\n",
      "reconstruction loss = 0.0090, similarity loss: 0.3468\n",
      "Epoch 39, loss = 0.7328, time: 16.7513\n",
      "reconstruction loss = 0.0077, similarity loss: 0.3484\n",
      "Epoch 40, loss = 0.7372, time: 16.6564\n",
      "reconstruction loss = 0.0082, similarity loss: 0.3260\n",
      "Epoch 41, loss = 0.8212, time: 16.6610\n",
      "reconstruction loss = 0.0094, similarity loss: 0.3511\n",
      "Epoch 42, loss = 0.7249, time: 16.6811\n",
      "reconstruction loss = 0.0080, similarity loss: 0.3233\n",
      "Epoch 43, loss = 0.7780, time: 16.7659\n",
      "reconstruction loss = 0.0089, similarity loss: 0.3334\n",
      "Epoch 44, loss = 0.7583, time: 16.6299\n",
      "reconstruction loss = 0.0078, similarity loss: 0.3699\n",
      "Epoch 45, loss = 0.7575, time: 17.3019\n",
      "reconstruction loss = 0.0079, similarity loss: 0.3600\n",
      "Epoch 46, loss = 0.7333, time: 16.9277\n",
      "reconstruction loss = 0.0072, similarity loss: 0.3709\n",
      "Epoch 47, loss = 0.7186, time: 16.6795\n",
      "reconstruction loss = 0.0082, similarity loss: 0.3100\n",
      "Epoch 48, loss = 0.6980, time: 16.7249\n",
      "reconstruction loss = 0.0079, similarity loss: 0.3019\n",
      "Epoch 49, loss = 0.8082, time: 16.6592\n",
      "reconstruction loss = 0.0095, similarity loss: 0.3318\n",
      "Epoch 50, loss = 0.7196, time: 16.6126\n",
      "reconstruction loss = 0.0079, similarity loss: 0.3251\n",
      "Epoch 51, loss = 0.6360, time: 16.4924\n",
      "reconstruction loss = 0.0069, similarity loss: 0.2888\n",
      "Epoch 52, loss = 0.6249, time: 16.0363\n",
      "reconstruction loss = 0.0069, similarity loss: 0.2784\n",
      "Epoch 53, loss = 0.7113, time: 16.0778\n",
      "reconstruction loss = 0.0076, similarity loss: 0.3292\n",
      "Epoch 54, loss = 0.7198, time: 16.1064\n",
      "reconstruction loss = 0.0083, similarity loss: 0.3034\n",
      "Epoch 55, loss = 0.7426, time: 16.1640\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3737\n",
      "Epoch 56, loss = 0.6886, time: 16.0716\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3188\n",
      "Epoch 57, loss = 0.6535, time: 16.0480\n",
      "reconstruction loss = 0.0076, similarity loss: 0.2737\n",
      "Epoch 58, loss = 0.7582, time: 16.1718\n",
      "reconstruction loss = 0.0088, similarity loss: 0.3164\n",
      "Epoch 59, loss = 0.6992, time: 16.1461\n",
      "reconstruction loss = 0.0079, similarity loss: 0.3028\n",
      "Epoch 60, loss = 0.6301, time: 16.2311\n",
      "reconstruction loss = 0.0067, similarity loss: 0.2950\n",
      "Epoch 61, loss = 0.6136, time: 16.2191\n",
      "reconstruction loss = 0.0067, similarity loss: 0.2784\n",
      "Epoch 62, loss = 0.7024, time: 16.1769\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3347\n",
      "Epoch 63, loss = 0.6929, time: 16.1317\n",
      "reconstruction loss = 0.0083, similarity loss: 0.2774\n",
      "Epoch 64, loss = 0.7003, time: 16.1442\n",
      "reconstruction loss = 0.0075, similarity loss: 0.3263\n",
      "Epoch 65, loss = 0.6961, time: 16.1008\n",
      "reconstruction loss = 0.0077, similarity loss: 0.3110\n",
      "Epoch 66, loss = 0.6889, time: 16.1879\n",
      "reconstruction loss = 0.0079, similarity loss: 0.2938\n",
      "Epoch 67, loss = 0.6713, time: 16.1315\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.6764, time: 16.0646\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3067\n",
      "Epoch 69, loss = 0.7019, time: 16.0585\n",
      "reconstruction loss = 0.0073, similarity loss: 0.3346\n",
      "Epoch 70, loss = 0.6754, time: 16.5289\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3210\n",
      "Epoch 71, loss = 0.5955, time: 16.6419\n",
      "reconstruction loss = 0.0067, similarity loss: 0.2614\n",
      "Epoch 72, loss = 0.6001, time: 16.7998\n",
      "reconstruction loss = 0.0067, similarity loss: 0.2645\n",
      "Epoch 73, loss = 0.7929, time: 17.0554\n",
      "reconstruction loss = 0.0087, similarity loss: 0.3600\n",
      "Epoch 74, loss = 0.6887, time: 16.8708\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3184\n",
      "Epoch 75, loss = 0.6083, time: 16.7328\n",
      "reconstruction loss = 0.0063, similarity loss: 0.2935\n",
      "Epoch 76, loss = 0.7361, time: 16.6994\n",
      "reconstruction loss = 0.0087, similarity loss: 0.3023\n",
      "Epoch 77, loss = 0.7158, time: 16.8373\n",
      "reconstruction loss = 0.0073, similarity loss: 0.3503\n",
      "Epoch 78, loss = 0.6891, time: 16.7180\n",
      "reconstruction loss = 0.0069, similarity loss: 0.3463\n",
      "Epoch 79, loss = 0.6479, time: 16.7342\n",
      "reconstruction loss = 0.0069, similarity loss: 0.3047\n",
      "Epoch 80, loss = 0.6560, time: 16.8163\n",
      "reconstruction loss = 0.0067, similarity loss: 0.3193\n",
      "Epoch 81, loss = 0.6314, time: 16.8283\n",
      "reconstruction loss = 0.0067, similarity loss: 0.2967\n",
      "Epoch 82, loss = 0.5772, time: 16.7233\n",
      "reconstruction loss = 0.0061, similarity loss: 0.2742\n",
      "Epoch 83, loss = 1.0112, time: 16.7635\n",
      "reconstruction loss = 0.0115, similarity loss: 0.4379\n",
      "Epoch 84, loss = 0.6814, time: 16.7546\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3277\n",
      "Epoch 85, loss = 0.6435, time: 16.7285\n",
      "reconstruction loss = 0.0073, similarity loss: 0.2789\n",
      "Epoch 86, loss = 0.6502, time: 16.6447\n",
      "reconstruction loss = 0.0070, similarity loss: 0.3022\n",
      "Epoch 87, loss = 0.6714, time: 16.6937\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3169\n",
      "Epoch 88, loss = 0.6340, time: 16.7997\n",
      "reconstruction loss = 0.0067, similarity loss: 0.3006\n",
      "Epoch 89, loss = 0.5798, time: 16.9560\n",
      "reconstruction loss = 0.0061, similarity loss: 0.2728\n",
      "Epoch 90, loss = 0.6398, time: 16.6719\n",
      "reconstruction loss = 0.0072, similarity loss: 0.2776\n",
      "Epoch 91, loss = 0.5995, time: 16.7806\n",
      "reconstruction loss = 0.0063, similarity loss: 0.2855\n",
      "Epoch 92, loss = 0.8527, time: 16.8308\n",
      "reconstruction loss = 0.0101, similarity loss: 0.3478\n",
      "Epoch 93, loss = 0.7112, time: 16.8476\n",
      "reconstruction loss = 0.0076, similarity loss: 0.3307\n",
      "Epoch 94, loss = 0.6064, time: 16.6500\n",
      "reconstruction loss = 0.0063, similarity loss: 0.2934\n",
      "Epoch 95, loss = 0.5841, time: 16.7473\n",
      "reconstruction loss = 0.0063, similarity loss: 0.2711\n",
      "Epoch 96, loss = 0.6043, time: 16.8372\n",
      "reconstruction loss = 0.0072, similarity loss: 0.2437\n",
      "Epoch 97, loss = 0.6552, time: 16.8720\n",
      "reconstruction loss = 0.0065, similarity loss: 0.3280\n",
      "Epoch 98, loss = 0.5479, time: 16.6695\n",
      "reconstruction loss = 0.0061, similarity loss: 0.2421\n",
      "Epoch 99, loss = 0.6670, time: 16.8066\n",
      "reconstruction loss = 0.0072, similarity loss: 0.3074\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.9777, val.loss = 1.7447, val.acc = 0.4252\n",
      "Epoch 1, loss = 1.6564, val.loss = 1.5898, val.acc = 0.4780\n",
      "Epoch 2, loss = 1.5388, val.loss = 1.5048, val.acc = 0.5094\n",
      "Epoch 3, loss = 1.4651, val.loss = 1.4465, val.acc = 0.5304\n",
      "Epoch 4, loss = 1.4116, val.loss = 1.4029, val.acc = 0.5430\n",
      "Epoch 5, loss = 1.3699, val.loss = 1.3684, val.acc = 0.5500\n",
      "Epoch 6, loss = 1.3359, val.loss = 1.3402, val.acc = 0.5578\n",
      "Epoch 7, loss = 1.3072, val.loss = 1.3165, val.acc = 0.5628\n",
      "Epoch 8, loss = 1.2825, val.loss = 1.2963, val.acc = 0.5688\n",
      "Epoch 9, loss = 1.2609, val.loss = 1.2786, val.acc = 0.5740\n",
      "Epoch 10, loss = 1.2416, val.loss = 1.2630, val.acc = 0.5780\n",
      "Epoch 11, loss = 1.2243, val.loss = 1.2491, val.acc = 0.5814\n",
      "Epoch 12, loss = 1.2085, val.loss = 1.2366, val.acc = 0.5848\n",
      "Epoch 13, loss = 1.1940, val.loss = 1.2253, val.acc = 0.5892\n",
      "Epoch 14, loss = 1.1806, val.loss = 1.2149, val.acc = 0.5932\n",
      "Epoch 15, loss = 1.1681, val.loss = 1.2054, val.acc = 0.5954\n",
      "Epoch 16, loss = 1.1565, val.loss = 1.1966, val.acc = 0.6006\n",
      "Epoch 17, loss = 1.1456, val.loss = 1.1884, val.acc = 0.6018\n",
      "Epoch 18, loss = 1.1352, val.loss = 1.1808, val.acc = 0.6040\n",
      "Epoch 19, loss = 1.1255, val.loss = 1.1737, val.acc = 0.6070\n",
      "Epoch 20, loss = 1.1162, val.loss = 1.1671, val.acc = 0.6084\n",
      "Epoch 21, loss = 1.1074, val.loss = 1.1608, val.acc = 0.6108\n",
      "Epoch 22, loss = 1.0990, val.loss = 1.1549, val.acc = 0.6126\n",
      "Epoch 23, loss = 1.0910, val.loss = 1.1492, val.acc = 0.6140\n",
      "Epoch 24, loss = 1.0833, val.loss = 1.1439, val.acc = 0.6154\n",
      "Epoch 25, loss = 1.0758, val.loss = 1.1389, val.acc = 0.6190\n",
      "Epoch 26, loss = 1.0687, val.loss = 1.1341, val.acc = 0.6200\n",
      "Epoch 27, loss = 1.0618, val.loss = 1.1295, val.acc = 0.6210\n",
      "Epoch 28, loss = 1.0552, val.loss = 1.1252, val.acc = 0.6236\n",
      "Epoch 29, loss = 1.0488, val.loss = 1.1210, val.acc = 0.6242\n",
      "Epoch 30, loss = 1.0426, val.loss = 1.1170, val.acc = 0.6266\n",
      "Epoch 31, loss = 1.0366, val.loss = 1.1132, val.acc = 0.6284\n",
      "Epoch 32, loss = 1.0308, val.loss = 1.1095, val.acc = 0.6300\n",
      "Epoch 33, loss = 1.0251, val.loss = 1.1060, val.acc = 0.6320\n",
      "Epoch 34, loss = 1.0196, val.loss = 1.1026, val.acc = 0.6338\n",
      "Epoch 35, loss = 1.0142, val.loss = 1.0993, val.acc = 0.6350\n",
      "Epoch 36, loss = 1.0090, val.loss = 1.0962, val.acc = 0.6360\n",
      "Epoch 37, loss = 1.0039, val.loss = 1.0931, val.acc = 0.6372\n",
      "Epoch 38, loss = 0.9990, val.loss = 1.0902, val.acc = 0.6376\n",
      "Epoch 39, loss = 0.9942, val.loss = 1.0874, val.acc = 0.6378\n",
      "Epoch 40, loss = 0.9894, val.loss = 1.0847, val.acc = 0.6384\n",
      "Epoch 41, loss = 0.9848, val.loss = 1.0821, val.acc = 0.6390\n",
      "Epoch 42, loss = 0.9803, val.loss = 1.0795, val.acc = 0.6400\n",
      "Epoch 43, loss = 0.9759, val.loss = 1.0770, val.acc = 0.6398\n",
      "Epoch 44, loss = 0.9716, val.loss = 1.0747, val.acc = 0.6416\n",
      "Epoch 45, loss = 0.9674, val.loss = 1.0724, val.acc = 0.6428\n",
      "Epoch 46, loss = 0.9632, val.loss = 1.0701, val.acc = 0.6424\n",
      "Epoch 47, loss = 0.9592, val.loss = 1.0679, val.acc = 0.6442\n",
      "Epoch 48, loss = 0.9552, val.loss = 1.0658, val.acc = 0.6436\n",
      "Epoch 49, loss = 0.9513, val.loss = 1.0638, val.acc = 0.6436\n",
      "Epoch 50, loss = 0.9475, val.loss = 1.0618, val.acc = 0.6448\n",
      "Epoch 51, loss = 0.9437, val.loss = 1.0599, val.acc = 0.6454\n",
      "Epoch 52, loss = 0.9400, val.loss = 1.0580, val.acc = 0.6472\n",
      "Epoch 53, loss = 0.9364, val.loss = 1.0562, val.acc = 0.6482\n",
      "Epoch 54, loss = 0.9328, val.loss = 1.0545, val.acc = 0.6498\n",
      "Epoch 55, loss = 0.9293, val.loss = 1.0527, val.acc = 0.6506\n",
      "Epoch 56, loss = 0.9259, val.loss = 1.0511, val.acc = 0.6526\n",
      "Epoch 57, loss = 0.9225, val.loss = 1.0495, val.acc = 0.6528\n",
      "Epoch 58, loss = 0.9192, val.loss = 1.0479, val.acc = 0.6532\n",
      "Epoch 59, loss = 0.9159, val.loss = 1.0463, val.acc = 0.6542\n",
      "Epoch 60, loss = 0.9127, val.loss = 1.0448, val.acc = 0.6550\n",
      "Epoch 61, loss = 0.9095, val.loss = 1.0434, val.acc = 0.6554\n",
      "Epoch 62, loss = 0.9063, val.loss = 1.0420, val.acc = 0.6564\n",
      "Epoch 63, loss = 0.9033, val.loss = 1.0406, val.acc = 0.6568\n",
      "Epoch 64, loss = 0.9002, val.loss = 1.0392, val.acc = 0.6568\n",
      "Epoch 65, loss = 0.8972, val.loss = 1.0379, val.acc = 0.6580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.8943, val.loss = 1.0366, val.acc = 0.6580\n",
      "Epoch 67, loss = 0.8914, val.loss = 1.0354, val.acc = 0.6580\n",
      "Epoch 68, loss = 0.8885, val.loss = 1.0342, val.acc = 0.6584\n",
      "Epoch 69, loss = 0.8856, val.loss = 1.0330, val.acc = 0.6592\n",
      "Epoch 70, loss = 0.8829, val.loss = 1.0318, val.acc = 0.6596\n",
      "Epoch 71, loss = 0.8801, val.loss = 1.0307, val.acc = 0.6598\n",
      "Epoch 72, loss = 0.8774, val.loss = 1.0296, val.acc = 0.6604\n",
      "Epoch 73, loss = 0.8747, val.loss = 1.0285, val.acc = 0.6604\n",
      "Epoch 74, loss = 0.8720, val.loss = 1.0275, val.acc = 0.6616\n",
      "Epoch 75, loss = 0.8694, val.loss = 1.0265, val.acc = 0.6616\n",
      "Epoch 76, loss = 0.8668, val.loss = 1.0255, val.acc = 0.6620\n",
      "Epoch 77, loss = 0.8643, val.loss = 1.0245, val.acc = 0.6610\n",
      "Epoch 78, loss = 0.8617, val.loss = 1.0235, val.acc = 0.6606\n",
      "Epoch 79, loss = 0.8592, val.loss = 1.0226, val.acc = 0.6606\n",
      "Epoch 80, loss = 0.8568, val.loss = 1.0217, val.acc = 0.6606\n",
      "Epoch 81, loss = 0.8543, val.loss = 1.0208, val.acc = 0.6604\n",
      "Epoch 82, loss = 0.8519, val.loss = 1.0199, val.acc = 0.6612\n",
      "Epoch 83, loss = 0.8495, val.loss = 1.0191, val.acc = 0.6612\n",
      "Epoch 84, loss = 0.8472, val.loss = 1.0183, val.acc = 0.6614\n",
      "Epoch 85, loss = 0.8448, val.loss = 1.0174, val.acc = 0.6610\n",
      "Epoch 86, loss = 0.8425, val.loss = 1.0167, val.acc = 0.6618\n",
      "Epoch 87, loss = 0.8402, val.loss = 1.0159, val.acc = 0.6626\n",
      "Epoch 88, loss = 0.8380, val.loss = 1.0151, val.acc = 0.6632\n",
      "Epoch 89, loss = 0.8358, val.loss = 1.0144, val.acc = 0.6630\n",
      "Epoch 90, loss = 0.8335, val.loss = 1.0137, val.acc = 0.6632\n",
      "Epoch 91, loss = 0.8314, val.loss = 1.0130, val.acc = 0.6632\n",
      "Epoch 92, loss = 0.8292, val.loss = 1.0123, val.acc = 0.6640\n",
      "Epoch 93, loss = 0.8270, val.loss = 1.0116, val.acc = 0.6642\n",
      "Epoch 94, loss = 0.8249, val.loss = 1.0109, val.acc = 0.6644\n",
      "Epoch 95, loss = 0.8228, val.loss = 1.0103, val.acc = 0.6642\n",
      "Epoch 96, loss = 0.8207, val.loss = 1.0097, val.acc = 0.6640\n",
      "Epoch 97, loss = 0.8187, val.loss = 1.0090, val.acc = 0.6638\n",
      "Epoch 98, loss = 0.8166, val.loss = 1.0084, val.acc = 0.6636\n",
      "Epoch 99, loss = 0.8146, val.loss = 1.0078, val.acc = 0.6636\n",
      "Epoch 100, loss = 0.8126, val.loss = 1.0073, val.acc = 0.6642\n",
      "Epoch 101, loss = 0.8106, val.loss = 1.0067, val.acc = 0.6638\n",
      "Epoch 102, loss = 0.8087, val.loss = 1.0061, val.acc = 0.6640\n",
      "Epoch 103, loss = 0.8067, val.loss = 1.0056, val.acc = 0.6640\n",
      "Epoch 104, loss = 0.8048, val.loss = 1.0051, val.acc = 0.6642\n",
      "Epoch 105, loss = 0.8029, val.loss = 1.0046, val.acc = 0.6646\n",
      "Epoch 106, loss = 0.8010, val.loss = 1.0041, val.acc = 0.6646\n",
      "Epoch 107, loss = 0.7991, val.loss = 1.0036, val.acc = 0.6646\n",
      "Epoch 108, loss = 0.7972, val.loss = 1.0031, val.acc = 0.6652\n",
      "Epoch 109, loss = 0.7954, val.loss = 1.0026, val.acc = 0.6656\n",
      "Epoch 110, loss = 0.7935, val.loss = 1.0021, val.acc = 0.6660\n",
      "Epoch 111, loss = 0.7917, val.loss = 1.0017, val.acc = 0.6660\n",
      "Epoch 112, loss = 0.7899, val.loss = 1.0013, val.acc = 0.6656\n",
      "Epoch 113, loss = 0.7881, val.loss = 1.0008, val.acc = 0.6662\n",
      "Epoch 114, loss = 0.7864, val.loss = 1.0004, val.acc = 0.6662\n",
      "Epoch 115, loss = 0.7846, val.loss = 1.0000, val.acc = 0.6662\n",
      "Epoch 116, loss = 0.7829, val.loss = 0.9996, val.acc = 0.6664\n",
      "Epoch 117, loss = 0.7811, val.loss = 0.9992, val.acc = 0.6666\n",
      "Epoch 118, loss = 0.7794, val.loss = 0.9988, val.acc = 0.6670\n",
      "Epoch 119, loss = 0.7777, val.loss = 0.9984, val.acc = 0.6664\n",
      "Epoch 120, loss = 0.7760, val.loss = 0.9981, val.acc = 0.6664\n",
      "Epoch 121, loss = 0.7744, val.loss = 0.9977, val.acc = 0.6664\n",
      "Epoch 122, loss = 0.7727, val.loss = 0.9973, val.acc = 0.6670\n",
      "Epoch 123, loss = 0.7710, val.loss = 0.9970, val.acc = 0.6668\n",
      "Epoch 124, loss = 0.7694, val.loss = 0.9967, val.acc = 0.6662\n",
      "Epoch 125, loss = 0.7678, val.loss = 0.9963, val.acc = 0.6662\n",
      "Epoch 126, loss = 0.7662, val.loss = 0.9960, val.acc = 0.6666\n",
      "Epoch 127, loss = 0.7646, val.loss = 0.9957, val.acc = 0.6670\n",
      "Epoch 128, loss = 0.7630, val.loss = 0.9954, val.acc = 0.6670\n",
      "Epoch 129, loss = 0.7614, val.loss = 0.9951, val.acc = 0.6664\n",
      "Epoch 130, loss = 0.7598, val.loss = 0.9948, val.acc = 0.6666\n",
      "Epoch 131, loss = 0.7583, val.loss = 0.9945, val.acc = 0.6662\n",
      "Epoch 132, loss = 0.7567, val.loss = 0.9942, val.acc = 0.6660\n",
      "Epoch 133, loss = 0.7552, val.loss = 0.9940, val.acc = 0.6662\n",
      "Epoch 134, loss = 0.7537, val.loss = 0.9937, val.acc = 0.6662\n",
      "Epoch 135, loss = 0.7522, val.loss = 0.9934, val.acc = 0.6660\n",
      "Epoch 136, loss = 0.7507, val.loss = 0.9932, val.acc = 0.6664\n",
      "Epoch 137, loss = 0.7492, val.loss = 0.9929, val.acc = 0.6660\n",
      "Epoch 138, loss = 0.7477, val.loss = 0.9927, val.acc = 0.6662\n",
      "Epoch 139, loss = 0.7462, val.loss = 0.9925, val.acc = 0.6660\n",
      "Epoch 140, loss = 0.7447, val.loss = 0.9922, val.acc = 0.6662\n",
      "Epoch 141, loss = 0.7433, val.loss = 0.9920, val.acc = 0.6664\n",
      "Epoch 142, loss = 0.7419, val.loss = 0.9918, val.acc = 0.6672\n",
      "Epoch 143, loss = 0.7404, val.loss = 0.9916, val.acc = 0.6674\n",
      "Epoch 144, loss = 0.7390, val.loss = 0.9914, val.acc = 0.6678\n",
      "Epoch 145, loss = 0.7376, val.loss = 0.9912, val.acc = 0.6676\n",
      "Epoch 146, loss = 0.7362, val.loss = 0.9910, val.acc = 0.6678\n",
      "Epoch 147, loss = 0.7348, val.loss = 0.9908, val.acc = 0.6674\n",
      "Epoch 148, loss = 0.7334, val.loss = 0.9906, val.acc = 0.6672\n",
      "Epoch 149, loss = 0.7320, val.loss = 0.9904, val.acc = 0.6676\n",
      "Rep: 1, te.acc = 0.6555\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6555]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 50\n",
    "vis = visdom.Visdom(port=8097,env='ae'+str(pars.decoder_channel)+'_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T08:48:09.365031Z",
     "start_time": "2022-04-02T08:16:20.373346Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_3/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_100_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(3, 32, 32))\n",
      "    (deconv): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 5.9762, time: 16.2447\n",
      "reconstruction loss = 0.0534, similarity loss: 0.6359\n",
      "Epoch 1, loss = 4.0300, time: 16.1329\n",
      "reconstruction loss = 0.0320, similarity loss: 0.8309\n",
      "Epoch 2, loss = 2.7281, time: 16.0106\n",
      "reconstruction loss = 0.0203, similarity loss: 0.6936\n",
      "Epoch 3, loss = 2.3199, time: 16.1637\n",
      "reconstruction loss = 0.0174, similarity loss: 0.5755\n",
      "Epoch 4, loss = 2.2182, time: 16.1561\n",
      "reconstruction loss = 0.0141, similarity loss: 0.8097\n",
      "Epoch 5, loss = 2.0868, time: 16.2397\n",
      "reconstruction loss = 0.0131, similarity loss: 0.7752\n",
      "Epoch 6, loss = 2.0567, time: 16.1888\n",
      "reconstruction loss = 0.0133, similarity loss: 0.7273\n",
      "Epoch 7, loss = 1.9396, time: 16.2165\n",
      "reconstruction loss = 0.0125, similarity loss: 0.6862\n",
      "Epoch 8, loss = 1.7463, time: 16.1717\n",
      "reconstruction loss = 0.0120, similarity loss: 0.5438\n",
      "Epoch 9, loss = 1.8136, time: 16.5660\n",
      "reconstruction loss = 0.0111, similarity loss: 0.7053\n",
      "Epoch 10, loss = 1.6730, time: 16.7286\n",
      "reconstruction loss = 0.0105, similarity loss: 0.6232\n",
      "Epoch 11, loss = 1.6651, time: 16.8048\n",
      "reconstruction loss = 0.0108, similarity loss: 0.5806\n",
      "Epoch 12, loss = 1.5134, time: 16.7298\n",
      "reconstruction loss = 0.0098, similarity loss: 0.5324\n",
      "Epoch 13, loss = 1.5484, time: 16.7809\n",
      "reconstruction loss = 0.0092, similarity loss: 0.6263\n",
      "Epoch 14, loss = 1.5629, time: 16.8193\n",
      "reconstruction loss = 0.0098, similarity loss: 0.5802\n",
      "Epoch 15, loss = 1.3589, time: 16.7471\n",
      "reconstruction loss = 0.0085, similarity loss: 0.5058\n",
      "Epoch 16, loss = 1.4944, time: 16.6542\n",
      "reconstruction loss = 0.0092, similarity loss: 0.5704\n",
      "Epoch 17, loss = 1.3606, time: 16.6757\n",
      "reconstruction loss = 0.0080, similarity loss: 0.5593\n",
      "Epoch 18, loss = 1.3534, time: 16.6789\n",
      "reconstruction loss = 0.0087, similarity loss: 0.4855\n",
      "Epoch 19, loss = 1.3930, time: 16.5985\n",
      "reconstruction loss = 0.0090, similarity loss: 0.4934\n",
      "Epoch 20, loss = 1.3388, time: 16.7671\n",
      "reconstruction loss = 0.0082, similarity loss: 0.5173\n",
      "Epoch 21, loss = 1.3484, time: 16.7998\n",
      "reconstruction loss = 0.0083, similarity loss: 0.5214\n",
      "Epoch 22, loss = 1.3523, time: 16.6296\n",
      "reconstruction loss = 0.0083, similarity loss: 0.5266\n",
      "Epoch 23, loss = 1.2994, time: 16.6290\n",
      "reconstruction loss = 0.0083, similarity loss: 0.4732\n",
      "Epoch 24, loss = 1.2369, time: 16.8041\n",
      "reconstruction loss = 0.0077, similarity loss: 0.4676\n",
      "Epoch 25, loss = 1.3498, time: 16.6948\n",
      "reconstruction loss = 0.0082, similarity loss: 0.5278\n",
      "Epoch 26, loss = 1.2308, time: 16.7608\n",
      "reconstruction loss = 0.0081, similarity loss: 0.4195\n",
      "Epoch 27, loss = 1.2459, time: 16.6856\n",
      "reconstruction loss = 0.0082, similarity loss: 0.4227\n",
      "Epoch 28, loss = 1.2555, time: 16.7137\n",
      "reconstruction loss = 0.0083, similarity loss: 0.4297\n",
      "Epoch 29, loss = 1.2105, time: 16.7708\n",
      "reconstruction loss = 0.0075, similarity loss: 0.4577\n",
      "Epoch 30, loss = 1.1499, time: 16.6136\n",
      "reconstruction loss = 0.0074, similarity loss: 0.4084\n",
      "Epoch 31, loss = 1.2561, time: 16.6618\n",
      "reconstruction loss = 0.0084, similarity loss: 0.4163\n",
      "Epoch 32, loss = 1.3797, time: 16.7238\n",
      "reconstruction loss = 0.0086, similarity loss: 0.5202\n",
      "Epoch 33, loss = 1.2139, time: 16.7972\n",
      "reconstruction loss = 0.0077, similarity loss: 0.4455\n",
      "Epoch 34, loss = 1.2425, time: 16.6341\n",
      "reconstruction loss = 0.0079, similarity loss: 0.4557\n",
      "Epoch 35, loss = 1.0541, time: 16.7597\n",
      "reconstruction loss = 0.0070, similarity loss: 0.3514\n",
      "Epoch 36, loss = 1.2825, time: 16.6908\n",
      "reconstruction loss = 0.0086, similarity loss: 0.4214\n",
      "Epoch 37, loss = 1.2080, time: 16.7008\n",
      "reconstruction loss = 0.0075, similarity loss: 0.4535\n",
      "Epoch 38, loss = 1.1646, time: 16.6748\n",
      "reconstruction loss = 0.0072, similarity loss: 0.4412\n",
      "Epoch 39, loss = 1.0664, time: 16.7701\n",
      "reconstruction loss = 0.0070, similarity loss: 0.3707\n",
      "Epoch 40, loss = 1.1668, time: 16.6889\n",
      "reconstruction loss = 0.0080, similarity loss: 0.3670\n",
      "Epoch 41, loss = 1.0757, time: 16.6967\n",
      "reconstruction loss = 0.0073, similarity loss: 0.3483\n",
      "Epoch 42, loss = 1.1499, time: 16.6980\n",
      "reconstruction loss = 0.0076, similarity loss: 0.3882\n",
      "Epoch 43, loss = 1.0755, time: 16.6398\n",
      "reconstruction loss = 0.0072, similarity loss: 0.3557\n",
      "Epoch 44, loss = 1.0981, time: 16.7350\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3912\n",
      "Epoch 45, loss = 1.1376, time: 16.1228\n",
      "reconstruction loss = 0.0075, similarity loss: 0.3908\n",
      "Epoch 46, loss = 1.1629, time: 16.2060\n",
      "reconstruction loss = 0.0078, similarity loss: 0.3870\n",
      "Epoch 47, loss = 1.1745, time: 16.0486\n",
      "reconstruction loss = 0.0076, similarity loss: 0.4193\n",
      "Epoch 48, loss = 1.0811, time: 16.1310\n",
      "reconstruction loss = 0.0068, similarity loss: 0.4000\n",
      "Epoch 49, loss = 1.0797, time: 16.1453\n",
      "reconstruction loss = 0.0067, similarity loss: 0.4053\n",
      "Epoch 50, loss = 1.1821, time: 16.1173\n",
      "reconstruction loss = 0.0076, similarity loss: 0.4182\n",
      "Epoch 51, loss = 1.1211, time: 16.0428\n",
      "reconstruction loss = 0.0075, similarity loss: 0.3720\n",
      "Epoch 52, loss = 1.1257, time: 16.2018\n",
      "reconstruction loss = 0.0073, similarity loss: 0.3952\n",
      "Epoch 53, loss = 1.0698, time: 16.1729\n",
      "reconstruction loss = 0.0068, similarity loss: 0.3929\n",
      "Epoch 54, loss = 1.0519, time: 16.1384\n",
      "reconstruction loss = 0.0068, similarity loss: 0.3694\n",
      "Epoch 55, loss = 1.0996, time: 16.1067\n",
      "reconstruction loss = 0.0072, similarity loss: 0.3783\n",
      "Epoch 56, loss = 1.0837, time: 16.2090\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3476\n",
      "Epoch 57, loss = 0.9897, time: 16.1761\n",
      "reconstruction loss = 0.0065, similarity loss: 0.3372\n",
      "Epoch 58, loss = 1.1516, time: 16.0704\n",
      "reconstruction loss = 0.0074, similarity loss: 0.4128\n",
      "Epoch 59, loss = 0.9676, time: 16.0538\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3299\n",
      "Epoch 60, loss = 1.0260, time: 16.2060\n",
      "reconstruction loss = 0.0067, similarity loss: 0.3570\n",
      "Epoch 61, loss = 1.0014, time: 16.1544\n",
      "reconstruction loss = 0.0066, similarity loss: 0.3410\n",
      "Epoch 62, loss = 1.0341, time: 16.1332\n",
      "reconstruction loss = 0.0068, similarity loss: 0.3503\n",
      "Epoch 63, loss = 1.0160, time: 16.2655\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3785\n",
      "Epoch 64, loss = 1.1426, time: 16.7558\n",
      "reconstruction loss = 0.0079, similarity loss: 0.3537\n",
      "Epoch 65, loss = 1.1052, time: 16.6849\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3904\n",
      "Epoch 66, loss = 0.9885, time: 16.5794\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3442\n",
      "Epoch 67, loss = 1.0552, time: 16.8063\n",
      "reconstruction loss = 0.0069, similarity loss: 0.3645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 1.1802, time: 16.8945\n",
      "reconstruction loss = 0.0077, similarity loss: 0.4120\n",
      "Epoch 69, loss = 1.0338, time: 16.6420\n",
      "reconstruction loss = 0.0068, similarity loss: 0.3539\n",
      "Epoch 70, loss = 0.9970, time: 16.7258\n",
      "reconstruction loss = 0.0066, similarity loss: 0.3331\n",
      "Epoch 71, loss = 1.2304, time: 16.6273\n",
      "reconstruction loss = 0.0077, similarity loss: 0.4588\n",
      "Epoch 72, loss = 1.0437, time: 16.6713\n",
      "reconstruction loss = 0.0068, similarity loss: 0.3613\n",
      "Epoch 73, loss = 0.9357, time: 16.5396\n",
      "reconstruction loss = 0.0065, similarity loss: 0.2820\n",
      "Epoch 74, loss = 1.0259, time: 16.7328\n",
      "reconstruction loss = 0.0063, similarity loss: 0.3953\n",
      "Epoch 75, loss = 0.9448, time: 16.7868\n",
      "reconstruction loss = 0.0068, similarity loss: 0.2653\n",
      "Epoch 76, loss = 0.9420, time: 16.7043\n",
      "reconstruction loss = 0.0063, similarity loss: 0.3110\n",
      "Epoch 77, loss = 0.9565, time: 16.7678\n",
      "reconstruction loss = 0.0062, similarity loss: 0.3343\n",
      "Epoch 78, loss = 0.9670, time: 16.6238\n",
      "reconstruction loss = 0.0065, similarity loss: 0.3174\n",
      "Epoch 79, loss = 1.4068, time: 16.7838\n",
      "reconstruction loss = 0.0089, similarity loss: 0.5180\n",
      "Epoch 80, loss = 1.1209, time: 16.7501\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3772\n",
      "Epoch 81, loss = 1.0251, time: 16.7170\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3871\n",
      "Epoch 82, loss = 0.9869, time: 16.7256\n",
      "reconstruction loss = 0.0061, similarity loss: 0.3725\n",
      "Epoch 83, loss = 0.9190, time: 16.7619\n",
      "reconstruction loss = 0.0061, similarity loss: 0.3096\n",
      "Epoch 84, loss = 1.0050, time: 16.7686\n",
      "reconstruction loss = 0.0067, similarity loss: 0.3356\n",
      "Epoch 85, loss = 0.9753, time: 16.6995\n",
      "reconstruction loss = 0.0068, similarity loss: 0.2973\n",
      "Epoch 86, loss = 0.9558, time: 16.7542\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3131\n",
      "Epoch 87, loss = 0.9183, time: 16.7415\n",
      "reconstruction loss = 0.0061, similarity loss: 0.3038\n",
      "Epoch 88, loss = 0.8661, time: 16.7008\n",
      "reconstruction loss = 0.0056, similarity loss: 0.3034\n",
      "Epoch 89, loss = 1.0194, time: 16.7627\n",
      "reconstruction loss = 0.0063, similarity loss: 0.3906\n",
      "Epoch 90, loss = 0.8725, time: 16.7978\n",
      "reconstruction loss = 0.0057, similarity loss: 0.3051\n",
      "Epoch 91, loss = 0.8494, time: 16.8094\n",
      "reconstruction loss = 0.0054, similarity loss: 0.3125\n",
      "Epoch 92, loss = 0.9473, time: 16.8636\n",
      "reconstruction loss = 0.0062, similarity loss: 0.3279\n",
      "Epoch 93, loss = 0.9094, time: 16.6840\n",
      "reconstruction loss = 0.0058, similarity loss: 0.3307\n",
      "Epoch 94, loss = 0.8868, time: 16.7797\n",
      "reconstruction loss = 0.0060, similarity loss: 0.2908\n",
      "Epoch 95, loss = 1.0499, time: 16.6512\n",
      "reconstruction loss = 0.0067, similarity loss: 0.3789\n",
      "Epoch 96, loss = 0.9857, time: 16.6920\n",
      "reconstruction loss = 0.0066, similarity loss: 0.3225\n",
      "Epoch 97, loss = 0.9053, time: 16.6311\n",
      "reconstruction loss = 0.0056, similarity loss: 0.3449\n",
      "Epoch 98, loss = 0.8776, time: 16.7120\n",
      "reconstruction loss = 0.0058, similarity loss: 0.2948\n",
      "Epoch 99, loss = 0.9874, time: 16.5713\n",
      "reconstruction loss = 0.0063, similarity loss: 0.3588\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.9754, val.loss = 1.7637, val.acc = 0.4156\n",
      "Epoch 1, loss = 1.6839, val.loss = 1.6216, val.acc = 0.4560\n",
      "Epoch 2, loss = 1.5741, val.loss = 1.5419, val.acc = 0.4842\n",
      "Epoch 3, loss = 1.5037, val.loss = 1.4858, val.acc = 0.5088\n",
      "Epoch 4, loss = 1.4515, val.loss = 1.4430, val.acc = 0.5230\n",
      "Epoch 5, loss = 1.4103, val.loss = 1.4086, val.acc = 0.5344\n",
      "Epoch 6, loss = 1.3763, val.loss = 1.3800, val.acc = 0.5452\n",
      "Epoch 7, loss = 1.3476, val.loss = 1.3558, val.acc = 0.5538\n",
      "Epoch 8, loss = 1.3227, val.loss = 1.3349, val.acc = 0.5608\n",
      "Epoch 9, loss = 1.3008, val.loss = 1.3165, val.acc = 0.5660\n",
      "Epoch 10, loss = 1.2812, val.loss = 1.3002, val.acc = 0.5714\n",
      "Epoch 11, loss = 1.2636, val.loss = 1.2855, val.acc = 0.5760\n",
      "Epoch 12, loss = 1.2476, val.loss = 1.2723, val.acc = 0.5794\n",
      "Epoch 13, loss = 1.2330, val.loss = 1.2603, val.acc = 0.5844\n",
      "Epoch 14, loss = 1.2195, val.loss = 1.2493, val.acc = 0.5894\n",
      "Epoch 15, loss = 1.2069, val.loss = 1.2391, val.acc = 0.5880\n",
      "Epoch 16, loss = 1.1952, val.loss = 1.2298, val.acc = 0.5896\n",
      "Epoch 17, loss = 1.1843, val.loss = 1.2210, val.acc = 0.5916\n",
      "Epoch 18, loss = 1.1740, val.loss = 1.2129, val.acc = 0.5948\n",
      "Epoch 19, loss = 1.1642, val.loss = 1.2053, val.acc = 0.5972\n",
      "Epoch 20, loss = 1.1550, val.loss = 1.1982, val.acc = 0.5982\n",
      "Epoch 21, loss = 1.1463, val.loss = 1.1914, val.acc = 0.5994\n",
      "Epoch 22, loss = 1.1380, val.loss = 1.1851, val.acc = 0.6010\n",
      "Epoch 23, loss = 1.1300, val.loss = 1.1791, val.acc = 0.6020\n",
      "Epoch 24, loss = 1.1224, val.loss = 1.1734, val.acc = 0.6040\n",
      "Epoch 25, loss = 1.1152, val.loss = 1.1680, val.acc = 0.6052\n",
      "Epoch 26, loss = 1.1082, val.loss = 1.1629, val.acc = 0.6068\n",
      "Epoch 27, loss = 1.1015, val.loss = 1.1580, val.acc = 0.6080\n",
      "Epoch 28, loss = 1.0950, val.loss = 1.1533, val.acc = 0.6102\n",
      "Epoch 29, loss = 1.0887, val.loss = 1.1488, val.acc = 0.6112\n",
      "Epoch 30, loss = 1.0827, val.loss = 1.1445, val.acc = 0.6122\n",
      "Epoch 31, loss = 1.0768, val.loss = 1.1404, val.acc = 0.6144\n",
      "Epoch 32, loss = 1.0712, val.loss = 1.1365, val.acc = 0.6154\n",
      "Epoch 33, loss = 1.0657, val.loss = 1.1327, val.acc = 0.6162\n",
      "Epoch 34, loss = 1.0604, val.loss = 1.1291, val.acc = 0.6182\n",
      "Epoch 35, loss = 1.0552, val.loss = 1.1256, val.acc = 0.6182\n",
      "Epoch 36, loss = 1.0502, val.loss = 1.1222, val.acc = 0.6200\n",
      "Epoch 37, loss = 1.0453, val.loss = 1.1189, val.acc = 0.6218\n",
      "Epoch 38, loss = 1.0405, val.loss = 1.1158, val.acc = 0.6234\n",
      "Epoch 39, loss = 1.0359, val.loss = 1.1128, val.acc = 0.6250\n",
      "Epoch 40, loss = 1.0314, val.loss = 1.1098, val.acc = 0.6260\n",
      "Epoch 41, loss = 1.0270, val.loss = 1.1070, val.acc = 0.6278\n",
      "Epoch 42, loss = 1.0227, val.loss = 1.1043, val.acc = 0.6288\n",
      "Epoch 43, loss = 1.0184, val.loss = 1.1016, val.acc = 0.6302\n",
      "Epoch 44, loss = 1.0143, val.loss = 1.0990, val.acc = 0.6304\n",
      "Epoch 45, loss = 1.0103, val.loss = 1.0965, val.acc = 0.6320\n",
      "Epoch 46, loss = 1.0063, val.loss = 1.0941, val.acc = 0.6332\n",
      "Epoch 47, loss = 1.0025, val.loss = 1.0918, val.acc = 0.6336\n",
      "Epoch 48, loss = 0.9987, val.loss = 1.0895, val.acc = 0.6336\n",
      "Epoch 49, loss = 0.9950, val.loss = 1.0873, val.acc = 0.6350\n",
      "Epoch 50, loss = 0.9914, val.loss = 1.0851, val.acc = 0.6354\n",
      "Epoch 51, loss = 0.9878, val.loss = 1.0830, val.acc = 0.6366\n",
      "Epoch 52, loss = 0.9843, val.loss = 1.0810, val.acc = 0.6378\n",
      "Epoch 53, loss = 0.9809, val.loss = 1.0790, val.acc = 0.6380\n",
      "Epoch 54, loss = 0.9775, val.loss = 1.0771, val.acc = 0.6388\n",
      "Epoch 55, loss = 0.9742, val.loss = 1.0752, val.acc = 0.6396\n",
      "Epoch 56, loss = 0.9709, val.loss = 1.0733, val.acc = 0.6402\n",
      "Epoch 57, loss = 0.9677, val.loss = 1.0716, val.acc = 0.6418\n",
      "Epoch 58, loss = 0.9645, val.loss = 1.0698, val.acc = 0.6420\n",
      "Epoch 59, loss = 0.9614, val.loss = 1.0681, val.acc = 0.6430\n",
      "Epoch 60, loss = 0.9584, val.loss = 1.0665, val.acc = 0.6430\n",
      "Epoch 61, loss = 0.9554, val.loss = 1.0648, val.acc = 0.6436\n",
      "Epoch 62, loss = 0.9524, val.loss = 1.0633, val.acc = 0.6448\n",
      "Epoch 63, loss = 0.9495, val.loss = 1.0617, val.acc = 0.6462\n",
      "Epoch 64, loss = 0.9467, val.loss = 1.0602, val.acc = 0.6466\n",
      "Epoch 65, loss = 0.9438, val.loss = 1.0588, val.acc = 0.6474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.9411, val.loss = 1.0573, val.acc = 0.6474\n",
      "Epoch 67, loss = 0.9383, val.loss = 1.0559, val.acc = 0.6480\n",
      "Epoch 68, loss = 0.9356, val.loss = 1.0546, val.acc = 0.6482\n",
      "Epoch 69, loss = 0.9329, val.loss = 1.0532, val.acc = 0.6494\n",
      "Epoch 70, loss = 0.9303, val.loss = 1.0519, val.acc = 0.6498\n",
      "Epoch 71, loss = 0.9277, val.loss = 1.0506, val.acc = 0.6498\n",
      "Epoch 72, loss = 0.9252, val.loss = 1.0494, val.acc = 0.6500\n",
      "Epoch 73, loss = 0.9226, val.loss = 1.0481, val.acc = 0.6506\n",
      "Epoch 74, loss = 0.9201, val.loss = 1.0469, val.acc = 0.6510\n",
      "Epoch 75, loss = 0.9177, val.loss = 1.0458, val.acc = 0.6522\n",
      "Epoch 76, loss = 0.9152, val.loss = 1.0446, val.acc = 0.6528\n",
      "Epoch 77, loss = 0.9128, val.loss = 1.0435, val.acc = 0.6538\n",
      "Epoch 78, loss = 0.9105, val.loss = 1.0424, val.acc = 0.6540\n",
      "Epoch 79, loss = 0.9081, val.loss = 1.0413, val.acc = 0.6538\n",
      "Epoch 80, loss = 0.9058, val.loss = 1.0402, val.acc = 0.6534\n",
      "Epoch 81, loss = 0.9035, val.loss = 1.0392, val.acc = 0.6538\n",
      "Epoch 82, loss = 0.9012, val.loss = 1.0382, val.acc = 0.6546\n",
      "Epoch 83, loss = 0.8990, val.loss = 1.0372, val.acc = 0.6550\n",
      "Epoch 84, loss = 0.8968, val.loss = 1.0362, val.acc = 0.6552\n",
      "Epoch 85, loss = 0.8946, val.loss = 1.0353, val.acc = 0.6556\n",
      "Epoch 86, loss = 0.8924, val.loss = 1.0343, val.acc = 0.6560\n",
      "Epoch 87, loss = 0.8903, val.loss = 1.0334, val.acc = 0.6552\n",
      "Epoch 88, loss = 0.8882, val.loss = 1.0325, val.acc = 0.6552\n",
      "Epoch 89, loss = 0.8861, val.loss = 1.0316, val.acc = 0.6556\n",
      "Epoch 90, loss = 0.8840, val.loss = 1.0307, val.acc = 0.6564\n",
      "Epoch 91, loss = 0.8819, val.loss = 1.0299, val.acc = 0.6568\n",
      "Epoch 92, loss = 0.8799, val.loss = 1.0290, val.acc = 0.6570\n",
      "Epoch 93, loss = 0.8779, val.loss = 1.0282, val.acc = 0.6572\n",
      "Epoch 94, loss = 0.8759, val.loss = 1.0274, val.acc = 0.6572\n",
      "Epoch 95, loss = 0.8739, val.loss = 1.0266, val.acc = 0.6572\n",
      "Epoch 96, loss = 0.8720, val.loss = 1.0258, val.acc = 0.6578\n",
      "Epoch 97, loss = 0.8700, val.loss = 1.0251, val.acc = 0.6582\n",
      "Epoch 98, loss = 0.8681, val.loss = 1.0243, val.acc = 0.6580\n",
      "Epoch 99, loss = 0.8662, val.loss = 1.0236, val.acc = 0.6582\n",
      "Epoch 100, loss = 0.8643, val.loss = 1.0229, val.acc = 0.6580\n",
      "Epoch 101, loss = 0.8625, val.loss = 1.0222, val.acc = 0.6582\n",
      "Epoch 102, loss = 0.8606, val.loss = 1.0215, val.acc = 0.6586\n",
      "Epoch 103, loss = 0.8588, val.loss = 1.0208, val.acc = 0.6592\n",
      "Epoch 104, loss = 0.8570, val.loss = 1.0201, val.acc = 0.6596\n",
      "Epoch 105, loss = 0.8552, val.loss = 1.0195, val.acc = 0.6606\n",
      "Epoch 106, loss = 0.8534, val.loss = 1.0188, val.acc = 0.6618\n",
      "Epoch 107, loss = 0.8516, val.loss = 1.0182, val.acc = 0.6624\n",
      "Epoch 108, loss = 0.8499, val.loss = 1.0176, val.acc = 0.6626\n",
      "Epoch 109, loss = 0.8482, val.loss = 1.0170, val.acc = 0.6622\n",
      "Epoch 110, loss = 0.8464, val.loss = 1.0164, val.acc = 0.6624\n",
      "Epoch 111, loss = 0.8447, val.loss = 1.0158, val.acc = 0.6624\n",
      "Epoch 112, loss = 0.8430, val.loss = 1.0152, val.acc = 0.6626\n",
      "Epoch 113, loss = 0.8414, val.loss = 1.0146, val.acc = 0.6630\n",
      "Epoch 114, loss = 0.8397, val.loss = 1.0140, val.acc = 0.6628\n",
      "Epoch 115, loss = 0.8380, val.loss = 1.0135, val.acc = 0.6632\n",
      "Epoch 116, loss = 0.8364, val.loss = 1.0130, val.acc = 0.6632\n",
      "Epoch 117, loss = 0.8348, val.loss = 1.0124, val.acc = 0.6632\n",
      "Epoch 118, loss = 0.8332, val.loss = 1.0119, val.acc = 0.6634\n",
      "Epoch 119, loss = 0.8316, val.loss = 1.0114, val.acc = 0.6640\n",
      "Epoch 120, loss = 0.8300, val.loss = 1.0109, val.acc = 0.6644\n",
      "Epoch 121, loss = 0.8284, val.loss = 1.0104, val.acc = 0.6648\n",
      "Epoch 122, loss = 0.8268, val.loss = 1.0099, val.acc = 0.6652\n",
      "Epoch 123, loss = 0.8253, val.loss = 1.0094, val.acc = 0.6654\n",
      "Epoch 124, loss = 0.8237, val.loss = 1.0089, val.acc = 0.6656\n",
      "Epoch 125, loss = 0.8222, val.loss = 1.0085, val.acc = 0.6654\n",
      "Epoch 126, loss = 0.8207, val.loss = 1.0080, val.acc = 0.6652\n",
      "Epoch 127, loss = 0.8192, val.loss = 1.0076, val.acc = 0.6652\n",
      "Epoch 128, loss = 0.8177, val.loss = 1.0071, val.acc = 0.6656\n",
      "Epoch 129, loss = 0.8162, val.loss = 1.0067, val.acc = 0.6656\n",
      "Epoch 130, loss = 0.8147, val.loss = 1.0063, val.acc = 0.6662\n",
      "Epoch 131, loss = 0.8133, val.loss = 1.0058, val.acc = 0.6664\n",
      "Epoch 132, loss = 0.8118, val.loss = 1.0054, val.acc = 0.6670\n",
      "Epoch 133, loss = 0.8104, val.loss = 1.0050, val.acc = 0.6674\n",
      "Epoch 134, loss = 0.8089, val.loss = 1.0046, val.acc = 0.6678\n",
      "Epoch 135, loss = 0.8075, val.loss = 1.0042, val.acc = 0.6680\n",
      "Epoch 136, loss = 0.8061, val.loss = 1.0038, val.acc = 0.6676\n",
      "Epoch 137, loss = 0.8047, val.loss = 1.0035, val.acc = 0.6680\n",
      "Epoch 138, loss = 0.8033, val.loss = 1.0031, val.acc = 0.6682\n",
      "Epoch 139, loss = 0.8019, val.loss = 1.0027, val.acc = 0.6680\n",
      "Epoch 140, loss = 0.8005, val.loss = 1.0023, val.acc = 0.6684\n",
      "Epoch 141, loss = 0.7992, val.loss = 1.0020, val.acc = 0.6688\n",
      "Epoch 142, loss = 0.7978, val.loss = 1.0016, val.acc = 0.6692\n",
      "Epoch 143, loss = 0.7964, val.loss = 1.0013, val.acc = 0.6688\n",
      "Epoch 144, loss = 0.7951, val.loss = 1.0010, val.acc = 0.6684\n",
      "Epoch 145, loss = 0.7938, val.loss = 1.0006, val.acc = 0.6686\n",
      "Epoch 146, loss = 0.7924, val.loss = 1.0003, val.acc = 0.6694\n",
      "Epoch 147, loss = 0.7911, val.loss = 1.0000, val.acc = 0.6690\n",
      "Epoch 148, loss = 0.7898, val.loss = 0.9997, val.acc = 0.6696\n",
      "Epoch 149, loss = 0.7885, val.loss = 0.9994, val.acc = 0.6698\n",
      "Rep: 1, te.acc = 0.6485\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6485]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 100\n",
    "vis = visdom.Visdom(port=8097,env='ae_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T08:48:09.381034Z",
     "start_time": "2022-04-02T08:48:09.366031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture: CONV6\n",
      "nonlinear: hardtanh\n",
      "batch_size: 500\n",
      "headsize: 64\n",
      "dataset: Cifar100\n",
      "loss: SimCLR\n",
      "OPT: Adam\n",
      "LR: 0.0005\n",
      "epochs: 100\n",
      "clf_dataset: Cifar10\n",
      "clf_loss: CE\n",
      "clf_opt: Adam\n",
      "clf_lr: 5e-05\n",
      "clf_epochs: 150\n",
      "repeat: 1\n",
      "device: cuda:0\n",
      "datapath: data/\n",
      "savepath: save/\n",
      "loadnet: False\n",
      "loadclf: False\n",
      "lam: 1\n",
      "decoder_channel: 16\n",
      "clfnonlinear: None\n",
      "headnonlinear: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pars = PARS(device, datapath, savepath)\n",
    "pars.architecture = 'CONV6'\n",
    "pars.LR = 5e-4\n",
    "pars.clf_lr = 5e-5\n",
    "pars.epochs = 100\n",
    "pars.clf_epochs = 150\n",
    "pars.nonlinear = 'hardtanh'\n",
    "pars.repeat = 1\n",
    "pars.loadnet = False\n",
    "pars.decoder_channel = 16\n",
    "print(pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T15:26:21.113379Z",
     "start_time": "2022-04-02T08:48:09.382035Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_16/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_1_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=16384, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(16, 32, 32))\n",
      "    (deconv): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 0.7397, time: 16.7430\n",
      "reconstruction loss = 0.0790, similarity loss: 0.6607\n",
      "Epoch 1, loss = 0.5773, time: 16.5036\n",
      "reconstruction loss = 0.0480, similarity loss: 0.5293\n",
      "Epoch 2, loss = 0.7650, time: 16.7663\n",
      "reconstruction loss = 0.0614, similarity loss: 0.7036\n",
      "Epoch 3, loss = 0.6851, time: 17.0526\n",
      "reconstruction loss = 0.0717, similarity loss: 0.6134\n",
      "Epoch 4, loss = 0.6261, time: 17.1258\n",
      "reconstruction loss = 0.0473, similarity loss: 0.5788\n",
      "Epoch 5, loss = 0.7439, time: 17.1010\n",
      "reconstruction loss = 0.0569, similarity loss: 0.6870\n",
      "Epoch 6, loss = 0.6629, time: 17.1272\n",
      "reconstruction loss = 0.0584, similarity loss: 0.6044\n",
      "Epoch 7, loss = 0.5315, time: 17.0315\n",
      "reconstruction loss = 0.0560, similarity loss: 0.4755\n",
      "Epoch 8, loss = 0.5895, time: 17.1524\n",
      "reconstruction loss = 0.0611, similarity loss: 0.5285\n",
      "Epoch 9, loss = 0.5763, time: 17.1392\n",
      "reconstruction loss = 0.0532, similarity loss: 0.5231\n",
      "Epoch 10, loss = 0.5355, time: 17.1219\n",
      "reconstruction loss = 0.0675, similarity loss: 0.4679\n",
      "Epoch 11, loss = 0.4511, time: 17.1614\n",
      "reconstruction loss = 0.0542, similarity loss: 0.3969\n",
      "Epoch 12, loss = 0.4537, time: 17.1283\n",
      "reconstruction loss = 0.0488, similarity loss: 0.4048\n",
      "Epoch 13, loss = 0.3656, time: 17.1218\n",
      "reconstruction loss = 0.0432, similarity loss: 0.3224\n",
      "Epoch 14, loss = 0.4180, time: 21950.4784\n",
      "reconstruction loss = 0.0444, similarity loss: 0.3736\n",
      "Epoch 15, loss = 0.3461, time: 19.3522\n",
      "reconstruction loss = 0.0402, similarity loss: 0.3059\n",
      "Epoch 16, loss = 0.3587, time: 17.6008\n",
      "reconstruction loss = 0.0411, similarity loss: 0.3176\n",
      "Epoch 17, loss = 0.3050, time: 17.2300\n",
      "reconstruction loss = 0.0423, similarity loss: 0.2627\n",
      "Epoch 18, loss = 0.3487, time: 16.8994\n",
      "reconstruction loss = 0.0385, similarity loss: 0.3103\n",
      "Epoch 19, loss = 0.3352, time: 17.0446\n",
      "reconstruction loss = 0.0501, similarity loss: 0.2851\n",
      "Epoch 20, loss = 0.3195, time: 17.2059\n",
      "reconstruction loss = 0.0389, similarity loss: 0.2807\n",
      "Epoch 21, loss = 0.3657, time: 17.2125\n",
      "reconstruction loss = 0.0376, similarity loss: 0.3281\n",
      "Epoch 22, loss = 0.3340, time: 17.1610\n",
      "reconstruction loss = 0.0460, similarity loss: 0.2880\n",
      "Epoch 23, loss = 0.3498, time: 16.9870\n",
      "reconstruction loss = 0.0355, similarity loss: 0.3142\n",
      "Epoch 24, loss = 0.3485, time: 17.2314\n",
      "reconstruction loss = 0.0382, similarity loss: 0.3104\n",
      "Epoch 25, loss = 0.3126, time: 16.8778\n",
      "reconstruction loss = 0.0375, similarity loss: 0.2751\n",
      "Epoch 26, loss = 0.3298, time: 17.0081\n",
      "reconstruction loss = 0.0409, similarity loss: 0.2889\n",
      "Epoch 27, loss = 0.3044, time: 17.4337\n",
      "reconstruction loss = 0.0405, similarity loss: 0.2640\n",
      "Epoch 28, loss = 0.3204, time: 17.4199\n",
      "reconstruction loss = 0.0349, similarity loss: 0.2855\n",
      "Epoch 29, loss = 0.2794, time: 17.3905\n",
      "reconstruction loss = 0.0392, similarity loss: 0.2402\n",
      "Epoch 30, loss = 0.3371, time: 16.6761\n",
      "reconstruction loss = 0.0360, similarity loss: 0.3011\n",
      "Epoch 31, loss = 0.3215, time: 17.3762\n",
      "reconstruction loss = 0.0343, similarity loss: 0.2872\n",
      "Epoch 32, loss = 0.2954, time: 17.2319\n",
      "reconstruction loss = 0.0381, similarity loss: 0.2573\n",
      "Epoch 33, loss = 0.3018, time: 16.8625\n",
      "reconstruction loss = 0.0328, similarity loss: 0.2690\n",
      "Epoch 34, loss = 0.2810, time: 17.1025\n",
      "reconstruction loss = 0.0344, similarity loss: 0.2466\n",
      "Epoch 35, loss = 0.2973, time: 16.6607\n",
      "reconstruction loss = 0.0358, similarity loss: 0.2615\n",
      "Epoch 36, loss = 0.3265, time: 16.5771\n",
      "reconstruction loss = 0.0390, similarity loss: 0.2875\n",
      "Epoch 37, loss = 0.3136, time: 16.4879\n",
      "reconstruction loss = 0.0326, similarity loss: 0.2811\n",
      "Epoch 38, loss = 0.3148, time: 16.6037\n",
      "reconstruction loss = 0.0354, similarity loss: 0.2794\n",
      "Epoch 39, loss = 0.2853, time: 16.4222\n",
      "reconstruction loss = 0.0300, similarity loss: 0.2553\n",
      "Epoch 40, loss = 0.2810, time: 16.4778\n",
      "reconstruction loss = 0.0361, similarity loss: 0.2450\n",
      "Epoch 41, loss = 0.2959, time: 16.3832\n",
      "reconstruction loss = 0.0411, similarity loss: 0.2548\n",
      "Epoch 42, loss = 0.3066, time: 16.4239\n",
      "reconstruction loss = 0.0354, similarity loss: 0.2712\n",
      "Epoch 43, loss = 0.2815, time: 16.3830\n",
      "reconstruction loss = 0.0334, similarity loss: 0.2481\n",
      "Epoch 44, loss = 0.3041, time: 16.4510\n",
      "reconstruction loss = 0.0333, similarity loss: 0.2708\n",
      "Epoch 45, loss = 0.2833, time: 16.3887\n",
      "reconstruction loss = 0.0297, similarity loss: 0.2536\n",
      "Epoch 46, loss = 0.2868, time: 16.4774\n",
      "reconstruction loss = 0.0269, similarity loss: 0.2599\n",
      "Epoch 47, loss = 0.3022, time: 16.5283\n",
      "reconstruction loss = 0.0308, similarity loss: 0.2714\n",
      "Epoch 48, loss = 0.2792, time: 16.6223\n",
      "reconstruction loss = 0.0301, similarity loss: 0.2491\n",
      "Epoch 49, loss = 0.2747, time: 16.8357\n",
      "reconstruction loss = 0.0309, similarity loss: 0.2438\n",
      "Epoch 50, loss = 0.3136, time: 16.9795\n",
      "reconstruction loss = 0.0301, similarity loss: 0.2836\n",
      "Epoch 51, loss = 0.2721, time: 17.0835\n",
      "reconstruction loss = 0.0305, similarity loss: 0.2416\n",
      "Epoch 52, loss = 0.2880, time: 17.2256\n",
      "reconstruction loss = 0.0284, similarity loss: 0.2596\n",
      "Epoch 53, loss = 0.2709, time: 17.0289\n",
      "reconstruction loss = 0.0316, similarity loss: 0.2393\n",
      "Epoch 54, loss = 0.2657, time: 17.0119\n",
      "reconstruction loss = 0.0281, similarity loss: 0.2376\n",
      "Epoch 55, loss = 0.2660, time: 16.9521\n",
      "reconstruction loss = 0.0280, similarity loss: 0.2380\n",
      "Epoch 56, loss = 0.2884, time: 17.0203\n",
      "reconstruction loss = 0.0317, similarity loss: 0.2567\n",
      "Epoch 57, loss = 0.2539, time: 17.4486\n",
      "reconstruction loss = 0.0264, similarity loss: 0.2275\n",
      "Epoch 58, loss = 0.2693, time: 17.0573\n",
      "reconstruction loss = 0.0279, similarity loss: 0.2414\n",
      "Epoch 59, loss = 0.3081, time: 17.0224\n",
      "reconstruction loss = 0.0428, similarity loss: 0.2653\n",
      "Epoch 60, loss = 0.2899, time: 16.9800\n",
      "reconstruction loss = 0.0419, similarity loss: 0.2479\n",
      "Epoch 61, loss = 0.2941, time: 16.9737\n",
      "reconstruction loss = 0.0285, similarity loss: 0.2656\n",
      "Epoch 62, loss = 0.3107, time: 17.1218\n",
      "reconstruction loss = 0.0289, similarity loss: 0.2818\n",
      "Epoch 63, loss = 0.2568, time: 16.9385\n",
      "reconstruction loss = 0.0238, similarity loss: 0.2330\n",
      "Epoch 64, loss = 0.2873, time: 16.9487\n",
      "reconstruction loss = 0.0287, similarity loss: 0.2587\n",
      "Epoch 65, loss = 0.2535, time: 17.0465\n",
      "reconstruction loss = 0.0252, similarity loss: 0.2283\n",
      "Epoch 66, loss = 0.2333, time: 16.8992\n",
      "reconstruction loss = 0.0260, similarity loss: 0.2073\n",
      "Epoch 67, loss = 0.2478, time: 16.9963\n",
      "reconstruction loss = 0.0276, similarity loss: 0.2201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.2486, time: 17.0477\n",
      "reconstruction loss = 0.0244, similarity loss: 0.2243\n",
      "Epoch 69, loss = 0.2558, time: 17.1379\n",
      "reconstruction loss = 0.0251, similarity loss: 0.2307\n",
      "Epoch 70, loss = 0.2670, time: 17.1391\n",
      "reconstruction loss = 0.0247, similarity loss: 0.2423\n",
      "Epoch 71, loss = 0.3008, time: 17.0282\n",
      "reconstruction loss = 0.0286, similarity loss: 0.2722\n",
      "Epoch 72, loss = 0.2535, time: 16.9159\n",
      "reconstruction loss = 0.0249, similarity loss: 0.2286\n",
      "Epoch 73, loss = 0.2689, time: 17.0139\n",
      "reconstruction loss = 0.0284, similarity loss: 0.2405\n",
      "Epoch 74, loss = 0.2547, time: 17.1598\n",
      "reconstruction loss = 0.0250, similarity loss: 0.2297\n",
      "Epoch 75, loss = 0.2722, time: 17.0598\n",
      "reconstruction loss = 0.0269, similarity loss: 0.2453\n",
      "Epoch 76, loss = 0.2489, time: 16.9188\n",
      "reconstruction loss = 0.0262, similarity loss: 0.2226\n",
      "Epoch 77, loss = 0.2406, time: 17.1507\n",
      "reconstruction loss = 0.0232, similarity loss: 0.2174\n",
      "Epoch 78, loss = 0.2771, time: 17.0474\n",
      "reconstruction loss = 0.0237, similarity loss: 0.2534\n",
      "Epoch 79, loss = 0.2560, time: 17.0019\n",
      "reconstruction loss = 0.0246, similarity loss: 0.2314\n",
      "Epoch 80, loss = 0.2738, time: 17.1219\n",
      "reconstruction loss = 0.0271, similarity loss: 0.2467\n",
      "Epoch 81, loss = 0.2478, time: 17.0759\n",
      "reconstruction loss = 0.0246, similarity loss: 0.2233\n",
      "Epoch 82, loss = 0.2432, time: 17.1494\n",
      "reconstruction loss = 0.0258, similarity loss: 0.2175\n",
      "Epoch 83, loss = 0.2398, time: 17.1914\n",
      "reconstruction loss = 0.0215, similarity loss: 0.2183\n",
      "Epoch 84, loss = 0.2714, time: 16.6680\n",
      "reconstruction loss = 0.0270, similarity loss: 0.2444\n",
      "Epoch 85, loss = 0.2628, time: 16.8354\n",
      "reconstruction loss = 0.0253, similarity loss: 0.2375\n",
      "Epoch 86, loss = 0.2790, time: 16.9944\n",
      "reconstruction loss = 0.0238, similarity loss: 0.2552\n",
      "Epoch 87, loss = 0.2440, time: 16.9671\n",
      "reconstruction loss = 0.0235, similarity loss: 0.2205\n",
      "Epoch 88, loss = 0.2734, time: 17.0011\n",
      "reconstruction loss = 0.0280, similarity loss: 0.2454\n",
      "Epoch 89, loss = 0.2589, time: 16.8693\n",
      "reconstruction loss = 0.0227, similarity loss: 0.2363\n",
      "Epoch 90, loss = 0.2744, time: 17.0032\n",
      "reconstruction loss = 0.0225, similarity loss: 0.2520\n",
      "Epoch 91, loss = 0.2698, time: 17.0132\n",
      "reconstruction loss = 0.0220, similarity loss: 0.2478\n",
      "Epoch 92, loss = 0.2566, time: 17.0172\n",
      "reconstruction loss = 0.0237, similarity loss: 0.2329\n",
      "Epoch 93, loss = 0.2421, time: 17.0209\n",
      "reconstruction loss = 0.0232, similarity loss: 0.2189\n",
      "Epoch 94, loss = 0.2389, time: 17.0151\n",
      "reconstruction loss = 0.0221, similarity loss: 0.2167\n",
      "Epoch 95, loss = 0.2419, time: 17.0481\n",
      "reconstruction loss = 0.0262, similarity loss: 0.2158\n",
      "Epoch 96, loss = 0.2676, time: 16.8966\n",
      "reconstruction loss = 0.0221, similarity loss: 0.2455\n",
      "Epoch 97, loss = 0.2254, time: 16.9319\n",
      "reconstruction loss = 0.0243, similarity loss: 0.2011\n",
      "Epoch 98, loss = 0.2783, time: 17.1092\n",
      "reconstruction loss = 0.0270, similarity loss: 0.2513\n",
      "Epoch 99, loss = 0.2318, time: 16.9348\n",
      "reconstruction loss = 0.0236, similarity loss: 0.2082\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 2.0406, val.loss = 1.7588, val.acc = 0.4446\n",
      "Epoch 1, loss = 1.6445, val.loss = 1.5487, val.acc = 0.5042\n",
      "Epoch 2, loss = 1.4892, val.loss = 1.4424, val.acc = 0.5340\n",
      "Epoch 3, loss = 1.3978, val.loss = 1.3752, val.acc = 0.5522\n",
      "Epoch 4, loss = 1.3345, val.loss = 1.3277, val.acc = 0.5666\n",
      "Epoch 5, loss = 1.2868, val.loss = 1.2917, val.acc = 0.5762\n",
      "Epoch 6, loss = 1.2486, val.loss = 1.2632, val.acc = 0.5828\n",
      "Epoch 7, loss = 1.2170, val.loss = 1.2399, val.acc = 0.5900\n",
      "Epoch 8, loss = 1.1900, val.loss = 1.2204, val.acc = 0.5956\n",
      "Epoch 9, loss = 1.1665, val.loss = 1.2037, val.acc = 0.6004\n",
      "Epoch 10, loss = 1.1457, val.loss = 1.1892, val.acc = 0.6030\n",
      "Epoch 11, loss = 1.1270, val.loss = 1.1765, val.acc = 0.6076\n",
      "Epoch 12, loss = 1.1100, val.loss = 1.1652, val.acc = 0.6116\n",
      "Epoch 13, loss = 1.0944, val.loss = 1.1551, val.acc = 0.6134\n",
      "Epoch 14, loss = 1.0800, val.loss = 1.1459, val.acc = 0.6174\n",
      "Epoch 15, loss = 1.0666, val.loss = 1.1376, val.acc = 0.6194\n",
      "Epoch 16, loss = 1.0541, val.loss = 1.1300, val.acc = 0.6214\n",
      "Epoch 17, loss = 1.0423, val.loss = 1.1230, val.acc = 0.6228\n",
      "Epoch 18, loss = 1.0312, val.loss = 1.1166, val.acc = 0.6234\n",
      "Epoch 19, loss = 1.0207, val.loss = 1.1107, val.acc = 0.6272\n",
      "Epoch 20, loss = 1.0107, val.loss = 1.1052, val.acc = 0.6306\n",
      "Epoch 21, loss = 1.0011, val.loss = 1.1000, val.acc = 0.6322\n",
      "Epoch 22, loss = 0.9920, val.loss = 1.0952, val.acc = 0.6334\n",
      "Epoch 23, loss = 0.9833, val.loss = 1.0908, val.acc = 0.6354\n",
      "Epoch 24, loss = 0.9749, val.loss = 1.0865, val.acc = 0.6374\n",
      "Epoch 25, loss = 0.9668, val.loss = 1.0826, val.acc = 0.6390\n",
      "Epoch 26, loss = 0.9591, val.loss = 1.0788, val.acc = 0.6398\n",
      "Epoch 27, loss = 0.9516, val.loss = 1.0753, val.acc = 0.6408\n",
      "Epoch 28, loss = 0.9443, val.loss = 1.0721, val.acc = 0.6418\n",
      "Epoch 29, loss = 0.9373, val.loss = 1.0689, val.acc = 0.6420\n",
      "Epoch 30, loss = 0.9305, val.loss = 1.0660, val.acc = 0.6442\n",
      "Epoch 31, loss = 0.9239, val.loss = 1.0632, val.acc = 0.6458\n",
      "Epoch 32, loss = 0.9175, val.loss = 1.0605, val.acc = 0.6468\n",
      "Epoch 33, loss = 0.9113, val.loss = 1.0580, val.acc = 0.6470\n",
      "Epoch 34, loss = 0.9052, val.loss = 1.0557, val.acc = 0.6486\n",
      "Epoch 35, loss = 0.8993, val.loss = 1.0534, val.acc = 0.6484\n",
      "Epoch 36, loss = 0.8936, val.loss = 1.0512, val.acc = 0.6496\n",
      "Epoch 37, loss = 0.8880, val.loss = 1.0492, val.acc = 0.6510\n",
      "Epoch 38, loss = 0.8825, val.loss = 1.0473, val.acc = 0.6512\n",
      "Epoch 39, loss = 0.8772, val.loss = 1.0454, val.acc = 0.6532\n",
      "Epoch 40, loss = 0.8719, val.loss = 1.0436, val.acc = 0.6542\n",
      "Epoch 41, loss = 0.8668, val.loss = 1.0420, val.acc = 0.6546\n",
      "Epoch 42, loss = 0.8618, val.loss = 1.0404, val.acc = 0.6554\n",
      "Epoch 43, loss = 0.8569, val.loss = 1.0389, val.acc = 0.6548\n",
      "Epoch 44, loss = 0.8522, val.loss = 1.0374, val.acc = 0.6550\n",
      "Epoch 45, loss = 0.8475, val.loss = 1.0360, val.acc = 0.6560\n",
      "Epoch 46, loss = 0.8429, val.loss = 1.0347, val.acc = 0.6574\n",
      "Epoch 47, loss = 0.8384, val.loss = 1.0335, val.acc = 0.6568\n",
      "Epoch 48, loss = 0.8339, val.loss = 1.0323, val.acc = 0.6574\n",
      "Epoch 49, loss = 0.8296, val.loss = 1.0311, val.acc = 0.6578\n",
      "Epoch 50, loss = 0.8253, val.loss = 1.0300, val.acc = 0.6582\n",
      "Epoch 51, loss = 0.8211, val.loss = 1.0290, val.acc = 0.6584\n",
      "Epoch 52, loss = 0.8170, val.loss = 1.0280, val.acc = 0.6582\n",
      "Epoch 53, loss = 0.8130, val.loss = 1.0271, val.acc = 0.6586\n",
      "Epoch 54, loss = 0.8090, val.loss = 1.0262, val.acc = 0.6586\n",
      "Epoch 55, loss = 0.8051, val.loss = 1.0253, val.acc = 0.6592\n",
      "Epoch 56, loss = 0.8012, val.loss = 1.0246, val.acc = 0.6588\n",
      "Epoch 57, loss = 0.7974, val.loss = 1.0238, val.acc = 0.6582\n",
      "Epoch 58, loss = 0.7937, val.loss = 1.0231, val.acc = 0.6592\n",
      "Epoch 59, loss = 0.7900, val.loss = 1.0224, val.acc = 0.6594\n",
      "Epoch 60, loss = 0.7864, val.loss = 1.0217, val.acc = 0.6594\n",
      "Epoch 61, loss = 0.7829, val.loss = 1.0211, val.acc = 0.6594\n",
      "Epoch 62, loss = 0.7793, val.loss = 1.0205, val.acc = 0.6592\n",
      "Epoch 63, loss = 0.7759, val.loss = 1.0199, val.acc = 0.6596\n",
      "Epoch 64, loss = 0.7725, val.loss = 1.0194, val.acc = 0.6594\n",
      "Epoch 65, loss = 0.7691, val.loss = 1.0189, val.acc = 0.6594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.7658, val.loss = 1.0184, val.acc = 0.6594\n",
      "Epoch 67, loss = 0.7625, val.loss = 1.0180, val.acc = 0.6594\n",
      "Epoch 68, loss = 0.7593, val.loss = 1.0176, val.acc = 0.6592\n",
      "Epoch 69, loss = 0.7561, val.loss = 1.0172, val.acc = 0.6596\n",
      "Epoch 70, loss = 0.7530, val.loss = 1.0168, val.acc = 0.6596\n",
      "Epoch 71, loss = 0.7499, val.loss = 1.0165, val.acc = 0.6598\n",
      "Epoch 72, loss = 0.7468, val.loss = 1.0162, val.acc = 0.6602\n",
      "Epoch 73, loss = 0.7438, val.loss = 1.0159, val.acc = 0.6604\n",
      "Epoch 74, loss = 0.7408, val.loss = 1.0156, val.acc = 0.6608\n",
      "Epoch 75, loss = 0.7379, val.loss = 1.0153, val.acc = 0.6618\n",
      "Epoch 76, loss = 0.7350, val.loss = 1.0151, val.acc = 0.6612\n",
      "Epoch 77, loss = 0.7321, val.loss = 1.0149, val.acc = 0.6616\n",
      "Epoch 78, loss = 0.7292, val.loss = 1.0147, val.acc = 0.6622\n",
      "Epoch 79, loss = 0.7264, val.loss = 1.0146, val.acc = 0.6624\n",
      "Epoch 80, loss = 0.7236, val.loss = 1.0144, val.acc = 0.6624\n",
      "Epoch 81, loss = 0.7209, val.loss = 1.0142, val.acc = 0.6628\n",
      "Epoch 82, loss = 0.7182, val.loss = 1.0141, val.acc = 0.6628\n",
      "Epoch 83, loss = 0.7155, val.loss = 1.0140, val.acc = 0.6630\n",
      "Epoch 84, loss = 0.7128, val.loss = 1.0139, val.acc = 0.6636\n",
      "Epoch 85, loss = 0.7102, val.loss = 1.0139, val.acc = 0.6640\n",
      "Epoch 86, loss = 0.7076, val.loss = 1.0138, val.acc = 0.6636\n",
      "Epoch 87, loss = 0.7050, val.loss = 1.0138, val.acc = 0.6630\n",
      "Epoch 88, loss = 0.7025, val.loss = 1.0137, val.acc = 0.6632\n",
      "Epoch 89, loss = 0.7000, val.loss = 1.0137, val.acc = 0.6630\n",
      "Epoch 90, loss = 0.6975, val.loss = 1.0137, val.acc = 0.6630\n",
      "Epoch 91, loss = 0.6950, val.loss = 1.0137, val.acc = 0.6638\n",
      "Epoch 92, loss = 0.6926, val.loss = 1.0137, val.acc = 0.6638\n",
      "Epoch 93, loss = 0.6902, val.loss = 1.0138, val.acc = 0.6642\n",
      "Epoch 94, loss = 0.6878, val.loss = 1.0138, val.acc = 0.6636\n",
      "Epoch 95, loss = 0.6854, val.loss = 1.0139, val.acc = 0.6636\n",
      "Epoch 96, loss = 0.6831, val.loss = 1.0139, val.acc = 0.6636\n",
      "Epoch 97, loss = 0.6808, val.loss = 1.0140, val.acc = 0.6634\n",
      "Epoch 98, loss = 0.6785, val.loss = 1.0141, val.acc = 0.6628\n",
      "Epoch 99, loss = 0.6762, val.loss = 1.0142, val.acc = 0.6628\n",
      "Epoch 100, loss = 0.6739, val.loss = 1.0143, val.acc = 0.6620\n",
      "Epoch 101, loss = 0.6717, val.loss = 1.0144, val.acc = 0.6614\n",
      "Epoch 102, loss = 0.6695, val.loss = 1.0146, val.acc = 0.6614\n",
      "Epoch 103, loss = 0.6673, val.loss = 1.0147, val.acc = 0.6614\n",
      "Epoch 104, loss = 0.6651, val.loss = 1.0149, val.acc = 0.6612\n",
      "Epoch 105, loss = 0.6630, val.loss = 1.0150, val.acc = 0.6608\n",
      "Epoch 106, loss = 0.6608, val.loss = 1.0152, val.acc = 0.6604\n",
      "Epoch 107, loss = 0.6587, val.loss = 1.0154, val.acc = 0.6604\n",
      "Epoch 108, loss = 0.6566, val.loss = 1.0156, val.acc = 0.6602\n",
      "Epoch 109, loss = 0.6546, val.loss = 1.0157, val.acc = 0.6606\n",
      "Epoch 110, loss = 0.6525, val.loss = 1.0159, val.acc = 0.6606\n",
      "Epoch 111, loss = 0.6505, val.loss = 1.0161, val.acc = 0.6610\n",
      "Epoch 112, loss = 0.6484, val.loss = 1.0164, val.acc = 0.6610\n",
      "Epoch 113, loss = 0.6464, val.loss = 1.0166, val.acc = 0.6610\n",
      "Epoch 114, loss = 0.6444, val.loss = 1.0168, val.acc = 0.6608\n",
      "Epoch 115, loss = 0.6425, val.loss = 1.0171, val.acc = 0.6610\n",
      "Epoch 116, loss = 0.6405, val.loss = 1.0173, val.acc = 0.6612\n",
      "Epoch 117, loss = 0.6386, val.loss = 1.0175, val.acc = 0.6608\n",
      "Epoch 118, loss = 0.6366, val.loss = 1.0178, val.acc = 0.6606\n",
      "Epoch 119, loss = 0.6347, val.loss = 1.0181, val.acc = 0.6604\n",
      "Epoch 120, loss = 0.6328, val.loss = 1.0183, val.acc = 0.6602\n",
      "Epoch 121, loss = 0.6309, val.loss = 1.0186, val.acc = 0.6606\n",
      "Epoch 122, loss = 0.6291, val.loss = 1.0189, val.acc = 0.6596\n",
      "Epoch 123, loss = 0.6272, val.loss = 1.0192, val.acc = 0.6598\n",
      "Epoch 124, loss = 0.6254, val.loss = 1.0195, val.acc = 0.6604\n",
      "Epoch 125, loss = 0.6236, val.loss = 1.0198, val.acc = 0.6602\n",
      "Epoch 126, loss = 0.6218, val.loss = 1.0201, val.acc = 0.6598\n",
      "Epoch 127, loss = 0.6200, val.loss = 1.0204, val.acc = 0.6592\n",
      "Epoch 128, loss = 0.6182, val.loss = 1.0207, val.acc = 0.6582\n",
      "Epoch 129, loss = 0.6164, val.loss = 1.0211, val.acc = 0.6576\n",
      "Epoch 130, loss = 0.6147, val.loss = 1.0213, val.acc = 0.6572\n",
      "Epoch 131, loss = 0.6129, val.loss = 1.0217, val.acc = 0.6570\n",
      "Epoch 132, loss = 0.6112, val.loss = 1.0220, val.acc = 0.6572\n",
      "Epoch 133, loss = 0.6095, val.loss = 1.0224, val.acc = 0.6574\n",
      "Epoch 134, loss = 0.6078, val.loss = 1.0227, val.acc = 0.6572\n",
      "Epoch 135, loss = 0.6061, val.loss = 1.0231, val.acc = 0.6568\n",
      "Epoch 136, loss = 0.6044, val.loss = 1.0234, val.acc = 0.6570\n",
      "Epoch 137, loss = 0.6028, val.loss = 1.0238, val.acc = 0.6568\n",
      "Epoch 138, loss = 0.6011, val.loss = 1.0241, val.acc = 0.6572\n",
      "Epoch 139, loss = 0.5995, val.loss = 1.0245, val.acc = 0.6568\n",
      "Epoch 140, loss = 0.5978, val.loss = 1.0249, val.acc = 0.6566\n",
      "Epoch 141, loss = 0.5962, val.loss = 1.0252, val.acc = 0.6562\n",
      "Epoch 142, loss = 0.5946, val.loss = 1.0256, val.acc = 0.6562\n",
      "Epoch 143, loss = 0.5930, val.loss = 1.0260, val.acc = 0.6560\n",
      "Epoch 144, loss = 0.5914, val.loss = 1.0264, val.acc = 0.6554\n",
      "Epoch 145, loss = 0.5898, val.loss = 1.0268, val.acc = 0.6554\n",
      "Epoch 146, loss = 0.5883, val.loss = 1.0272, val.acc = 0.6554\n",
      "Epoch 147, loss = 0.5867, val.loss = 1.0276, val.acc = 0.6554\n",
      "Epoch 148, loss = 0.5852, val.loss = 1.0280, val.acc = 0.6556\n",
      "Epoch 149, loss = 0.5836, val.loss = 1.0284, val.acc = 0.6554\n",
      "Rep: 1, te.acc = 0.6434\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6434]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 1\n",
    "vis = visdom.Visdom(port=8097,env='ae'+str(pars.decoder_channel)+'_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T15:58:30.086151Z",
     "start_time": "2022-04-02T15:26:21.114379Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_16/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_5_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=16384, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(16, 32, 32))\n",
      "    (deconv): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 0.9360, time: 17.3031\n",
      "reconstruction loss = 0.0561, similarity loss: 0.6554\n",
      "Epoch 1, loss = 0.7849, time: 17.0988\n",
      "reconstruction loss = 0.0425, similarity loss: 0.5722\n",
      "Epoch 2, loss = 0.7705, time: 17.0101\n",
      "reconstruction loss = 0.0401, similarity loss: 0.5698\n",
      "Epoch 3, loss = 0.6570, time: 17.0691\n",
      "reconstruction loss = 0.0352, similarity loss: 0.4811\n",
      "Epoch 4, loss = 0.6090, time: 17.1018\n",
      "reconstruction loss = 0.0377, similarity loss: 0.4205\n",
      "Epoch 5, loss = 0.5051, time: 16.7164\n",
      "reconstruction loss = 0.0310, similarity loss: 0.3500\n",
      "Epoch 6, loss = 0.4609, time: 16.4680\n",
      "reconstruction loss = 0.0294, similarity loss: 0.3141\n",
      "Epoch 7, loss = 0.5217, time: 16.4030\n",
      "reconstruction loss = 0.0334, similarity loss: 0.3546\n",
      "Epoch 8, loss = 0.5337, time: 16.4391\n",
      "reconstruction loss = 0.0299, similarity loss: 0.3840\n",
      "Epoch 9, loss = 0.5085, time: 16.5924\n",
      "reconstruction loss = 0.0306, similarity loss: 0.3555\n",
      "Epoch 10, loss = 0.4345, time: 16.3902\n",
      "reconstruction loss = 0.0281, similarity loss: 0.2940\n",
      "Epoch 11, loss = 0.4567, time: 16.4520\n",
      "reconstruction loss = 0.0303, similarity loss: 0.3054\n",
      "Epoch 12, loss = 0.4168, time: 16.3403\n",
      "reconstruction loss = 0.0255, similarity loss: 0.2895\n",
      "Epoch 13, loss = 0.4398, time: 16.4684\n",
      "reconstruction loss = 0.0278, similarity loss: 0.3010\n",
      "Epoch 14, loss = 0.4207, time: 16.4073\n",
      "reconstruction loss = 0.0259, similarity loss: 0.2913\n",
      "Epoch 15, loss = 0.4612, time: 16.4019\n",
      "reconstruction loss = 0.0270, similarity loss: 0.3262\n",
      "Epoch 16, loss = 0.4170, time: 16.4311\n",
      "reconstruction loss = 0.0249, similarity loss: 0.2925\n",
      "Epoch 17, loss = 0.3932, time: 16.4382\n",
      "reconstruction loss = 0.0238, similarity loss: 0.2744\n",
      "Epoch 18, loss = 0.4079, time: 16.3735\n",
      "reconstruction loss = 0.0258, similarity loss: 0.2791\n",
      "Epoch 19, loss = 0.4136, time: 16.3914\n",
      "reconstruction loss = 0.0264, similarity loss: 0.2818\n",
      "Epoch 20, loss = 0.4134, time: 16.3835\n",
      "reconstruction loss = 0.0246, similarity loss: 0.2903\n",
      "Epoch 21, loss = 0.3840, time: 16.3883\n",
      "reconstruction loss = 0.0222, similarity loss: 0.2732\n",
      "Epoch 22, loss = 0.3963, time: 16.4230\n",
      "reconstruction loss = 0.0247, similarity loss: 0.2726\n",
      "Epoch 23, loss = 0.4209, time: 16.4474\n",
      "reconstruction loss = 0.0270, similarity loss: 0.2859\n",
      "Epoch 24, loss = 0.3972, time: 16.3970\n",
      "reconstruction loss = 0.0220, similarity loss: 0.2871\n",
      "Epoch 25, loss = 0.4325, time: 16.4561\n",
      "reconstruction loss = 0.0254, similarity loss: 0.3057\n",
      "Epoch 26, loss = 0.4032, time: 16.3720\n",
      "reconstruction loss = 0.0231, similarity loss: 0.2876\n",
      "Epoch 27, loss = 0.3575, time: 16.3851\n",
      "reconstruction loss = 0.0244, similarity loss: 0.2357\n",
      "Epoch 28, loss = 0.4083, time: 16.4150\n",
      "reconstruction loss = 0.0251, similarity loss: 0.2827\n",
      "Epoch 29, loss = 0.3721, time: 16.3189\n",
      "reconstruction loss = 0.0262, similarity loss: 0.2412\n",
      "Epoch 30, loss = 0.3776, time: 16.4296\n",
      "reconstruction loss = 0.0227, similarity loss: 0.2642\n",
      "Epoch 31, loss = 0.4648, time: 16.4256\n",
      "reconstruction loss = 0.0257, similarity loss: 0.3365\n",
      "Epoch 32, loss = 0.3520, time: 16.3996\n",
      "reconstruction loss = 0.0210, similarity loss: 0.2472\n",
      "Epoch 33, loss = 0.3865, time: 16.3504\n",
      "reconstruction loss = 0.0206, similarity loss: 0.2833\n",
      "Epoch 34, loss = 0.3955, time: 16.4883\n",
      "reconstruction loss = 0.0205, similarity loss: 0.2930\n",
      "Epoch 35, loss = 0.3749, time: 16.3719\n",
      "reconstruction loss = 0.0191, similarity loss: 0.2795\n",
      "Epoch 36, loss = 0.3568, time: 16.3589\n",
      "reconstruction loss = 0.0216, similarity loss: 0.2487\n",
      "Epoch 37, loss = 0.3463, time: 16.3834\n",
      "reconstruction loss = 0.0185, similarity loss: 0.2536\n",
      "Epoch 38, loss = 0.4044, time: 16.4601\n",
      "reconstruction loss = 0.0188, similarity loss: 0.3104\n",
      "Epoch 39, loss = 0.3554, time: 16.3703\n",
      "reconstruction loss = 0.0182, similarity loss: 0.2642\n",
      "Epoch 40, loss = 0.3758, time: 16.5473\n",
      "reconstruction loss = 0.0202, similarity loss: 0.2750\n",
      "Epoch 41, loss = 0.3467, time: 16.3780\n",
      "reconstruction loss = 0.0197, similarity loss: 0.2482\n",
      "Epoch 42, loss = 0.3862, time: 16.5050\n",
      "reconstruction loss = 0.0170, similarity loss: 0.3009\n",
      "Epoch 43, loss = 0.3320, time: 16.4194\n",
      "reconstruction loss = 0.0190, similarity loss: 0.2372\n",
      "Epoch 44, loss = 0.3212, time: 16.4516\n",
      "reconstruction loss = 0.0179, similarity loss: 0.2315\n",
      "Epoch 45, loss = 0.3423, time: 16.5492\n",
      "reconstruction loss = 0.0163, similarity loss: 0.2606\n",
      "Epoch 46, loss = 0.3868, time: 16.7488\n",
      "reconstruction loss = 0.0234, similarity loss: 0.2697\n",
      "Epoch 47, loss = 0.3312, time: 16.9455\n",
      "reconstruction loss = 0.0169, similarity loss: 0.2469\n",
      "Epoch 48, loss = 0.3291, time: 17.0044\n",
      "reconstruction loss = 0.0165, similarity loss: 0.2464\n",
      "Epoch 49, loss = 0.3095, time: 16.9339\n",
      "reconstruction loss = 0.0163, similarity loss: 0.2280\n",
      "Epoch 50, loss = 0.3386, time: 17.0022\n",
      "reconstruction loss = 0.0164, similarity loss: 0.2566\n",
      "Epoch 51, loss = 0.3088, time: 16.9786\n",
      "reconstruction loss = 0.0175, similarity loss: 0.2214\n",
      "Epoch 52, loss = 0.3345, time: 17.0487\n",
      "reconstruction loss = 0.0148, similarity loss: 0.2603\n",
      "Epoch 53, loss = 0.3199, time: 16.9937\n",
      "reconstruction loss = 0.0154, similarity loss: 0.2430\n",
      "Epoch 54, loss = 0.3447, time: 16.9474\n",
      "reconstruction loss = 0.0175, similarity loss: 0.2570\n",
      "Epoch 55, loss = 0.3654, time: 16.9047\n",
      "reconstruction loss = 0.0163, similarity loss: 0.2839\n",
      "Epoch 56, loss = 0.3342, time: 17.1727\n",
      "reconstruction loss = 0.0164, similarity loss: 0.2524\n",
      "Epoch 57, loss = 0.3282, time: 16.9413\n",
      "reconstruction loss = 0.0143, similarity loss: 0.2566\n",
      "Epoch 58, loss = 0.3636, time: 16.9267\n",
      "reconstruction loss = 0.0166, similarity loss: 0.2809\n",
      "Epoch 59, loss = 0.2956, time: 16.9999\n",
      "reconstruction loss = 0.0162, similarity loss: 0.2144\n",
      "Epoch 60, loss = 0.3169, time: 17.0403\n",
      "reconstruction loss = 0.0164, similarity loss: 0.2346\n",
      "Epoch 61, loss = 0.3404, time: 16.9974\n",
      "reconstruction loss = 0.0150, similarity loss: 0.2655\n",
      "Epoch 62, loss = 0.3445, time: 16.9443\n",
      "reconstruction loss = 0.0144, similarity loss: 0.2723\n",
      "Epoch 63, loss = 0.3344, time: 16.9758\n",
      "reconstruction loss = 0.0143, similarity loss: 0.2629\n",
      "Epoch 64, loss = 0.3548, time: 17.0535\n",
      "reconstruction loss = 0.0158, similarity loss: 0.2757\n",
      "Epoch 65, loss = 0.3755, time: 17.1468\n",
      "reconstruction loss = 0.0178, similarity loss: 0.2865\n",
      "Epoch 66, loss = 0.3549, time: 17.1205\n",
      "reconstruction loss = 0.0141, similarity loss: 0.2843\n",
      "Epoch 67, loss = 0.3170, time: 17.0418\n",
      "reconstruction loss = 0.0144, similarity loss: 0.2452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.3237, time: 17.0152\n",
      "reconstruction loss = 0.0159, similarity loss: 0.2441\n",
      "Epoch 69, loss = 0.3203, time: 17.0952\n",
      "reconstruction loss = 0.0146, similarity loss: 0.2470\n",
      "Epoch 70, loss = 0.3293, time: 17.1303\n",
      "reconstruction loss = 0.0160, similarity loss: 0.2493\n",
      "Epoch 71, loss = 0.3246, time: 17.0545\n",
      "reconstruction loss = 0.0143, similarity loss: 0.2531\n",
      "Epoch 72, loss = 0.3418, time: 17.1449\n",
      "reconstruction loss = 0.0163, similarity loss: 0.2601\n",
      "Epoch 73, loss = 0.3228, time: 17.0339\n",
      "reconstruction loss = 0.0151, similarity loss: 0.2474\n",
      "Epoch 74, loss = 0.3217, time: 17.0271\n",
      "reconstruction loss = 0.0146, similarity loss: 0.2489\n",
      "Epoch 75, loss = 0.3014, time: 17.0665\n",
      "reconstruction loss = 0.0128, similarity loss: 0.2375\n",
      "Epoch 76, loss = 0.3084, time: 17.0090\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2324\n",
      "Epoch 77, loss = 0.3318, time: 17.0702\n",
      "reconstruction loss = 0.0159, similarity loss: 0.2523\n",
      "Epoch 78, loss = 0.3340, time: 17.0563\n",
      "reconstruction loss = 0.0148, similarity loss: 0.2600\n",
      "Epoch 79, loss = 0.3141, time: 17.0195\n",
      "reconstruction loss = 0.0120, similarity loss: 0.2542\n",
      "Epoch 80, loss = 0.3171, time: 17.0305\n",
      "reconstruction loss = 0.0146, similarity loss: 0.2438\n",
      "Epoch 81, loss = 0.3219, time: 16.8364\n",
      "reconstruction loss = 0.0142, similarity loss: 0.2510\n",
      "Epoch 82, loss = 0.2869, time: 16.5017\n",
      "reconstruction loss = 0.0127, similarity loss: 0.2233\n",
      "Epoch 83, loss = 0.3508, time: 16.3522\n",
      "reconstruction loss = 0.0135, similarity loss: 0.2835\n",
      "Epoch 84, loss = 0.3464, time: 16.4968\n",
      "reconstruction loss = 0.0147, similarity loss: 0.2731\n",
      "Epoch 85, loss = 0.3248, time: 16.4169\n",
      "reconstruction loss = 0.0139, similarity loss: 0.2554\n",
      "Epoch 86, loss = 0.2742, time: 16.3555\n",
      "reconstruction loss = 0.0151, similarity loss: 0.1987\n",
      "Epoch 87, loss = 0.3065, time: 16.4755\n",
      "reconstruction loss = 0.0157, similarity loss: 0.2278\n",
      "Epoch 88, loss = 0.3220, time: 16.5621\n",
      "reconstruction loss = 0.0121, similarity loss: 0.2617\n",
      "Epoch 89, loss = 0.3777, time: 16.5319\n",
      "reconstruction loss = 0.0158, similarity loss: 0.2986\n",
      "Epoch 90, loss = 0.3071, time: 16.5042\n",
      "reconstruction loss = 0.0128, similarity loss: 0.2428\n",
      "Epoch 91, loss = 0.3162, time: 16.5425\n",
      "reconstruction loss = 0.0135, similarity loss: 0.2486\n",
      "Epoch 92, loss = 0.3045, time: 16.5521\n",
      "reconstruction loss = 0.0158, similarity loss: 0.2255\n",
      "Epoch 93, loss = 0.3271, time: 16.4192\n",
      "reconstruction loss = 0.0123, similarity loss: 0.2655\n",
      "Epoch 94, loss = 0.3067, time: 16.5864\n",
      "reconstruction loss = 0.0130, similarity loss: 0.2417\n",
      "Epoch 95, loss = 0.2924, time: 16.4831\n",
      "reconstruction loss = 0.0122, similarity loss: 0.2316\n",
      "Epoch 96, loss = 0.3007, time: 16.7318\n",
      "reconstruction loss = 0.0113, similarity loss: 0.2442\n",
      "Epoch 97, loss = 0.3486, time: 17.0769\n",
      "reconstruction loss = 0.0166, similarity loss: 0.2655\n",
      "Epoch 98, loss = 0.2983, time: 17.2167\n",
      "reconstruction loss = 0.0124, similarity loss: 0.2362\n",
      "Epoch 99, loss = 0.3026, time: 17.0087\n",
      "reconstruction loss = 0.0125, similarity loss: 0.2399\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 2.0846, val.loss = 1.9078, val.acc = 0.4090\n",
      "Epoch 1, loss = 1.8211, val.loss = 1.7434, val.acc = 0.4588\n",
      "Epoch 2, loss = 1.6927, val.loss = 1.6479, val.acc = 0.4800\n",
      "Epoch 3, loss = 1.6099, val.loss = 1.5823, val.acc = 0.4976\n",
      "Epoch 4, loss = 1.5495, val.loss = 1.5330, val.acc = 0.5100\n",
      "Epoch 5, loss = 1.5022, val.loss = 1.4939, val.acc = 0.5206\n",
      "Epoch 6, loss = 1.4635, val.loss = 1.4617, val.acc = 0.5296\n",
      "Epoch 7, loss = 1.4309, val.loss = 1.4346, val.acc = 0.5396\n",
      "Epoch 8, loss = 1.4027, val.loss = 1.4112, val.acc = 0.5470\n",
      "Epoch 9, loss = 1.3780, val.loss = 1.3907, val.acc = 0.5502\n",
      "Epoch 10, loss = 1.3559, val.loss = 1.3726, val.acc = 0.5560\n",
      "Epoch 11, loss = 1.3361, val.loss = 1.3565, val.acc = 0.5600\n",
      "Epoch 12, loss = 1.3181, val.loss = 1.3419, val.acc = 0.5652\n",
      "Epoch 13, loss = 1.3015, val.loss = 1.3286, val.acc = 0.5692\n",
      "Epoch 14, loss = 1.2863, val.loss = 1.3165, val.acc = 0.5754\n",
      "Epoch 15, loss = 1.2722, val.loss = 1.3053, val.acc = 0.5776\n",
      "Epoch 16, loss = 1.2591, val.loss = 1.2951, val.acc = 0.5816\n",
      "Epoch 17, loss = 1.2467, val.loss = 1.2855, val.acc = 0.5838\n",
      "Epoch 18, loss = 1.2352, val.loss = 1.2766, val.acc = 0.5864\n",
      "Epoch 19, loss = 1.2243, val.loss = 1.2684, val.acc = 0.5890\n",
      "Epoch 20, loss = 1.2139, val.loss = 1.2606, val.acc = 0.5908\n",
      "Epoch 21, loss = 1.2042, val.loss = 1.2533, val.acc = 0.5944\n",
      "Epoch 22, loss = 1.1948, val.loss = 1.2464, val.acc = 0.5962\n",
      "Epoch 23, loss = 1.1860, val.loss = 1.2400, val.acc = 0.5978\n",
      "Epoch 24, loss = 1.1775, val.loss = 1.2338, val.acc = 0.6000\n",
      "Epoch 25, loss = 1.1694, val.loss = 1.2280, val.acc = 0.6012\n",
      "Epoch 26, loss = 1.1616, val.loss = 1.2225, val.acc = 0.6038\n",
      "Epoch 27, loss = 1.1541, val.loss = 1.2173, val.acc = 0.6042\n",
      "Epoch 28, loss = 1.1469, val.loss = 1.2123, val.acc = 0.6054\n",
      "Epoch 29, loss = 1.1399, val.loss = 1.2075, val.acc = 0.6058\n",
      "Epoch 30, loss = 1.1332, val.loss = 1.2029, val.acc = 0.6066\n",
      "Epoch 31, loss = 1.1267, val.loss = 1.1986, val.acc = 0.6074\n",
      "Epoch 32, loss = 1.1204, val.loss = 1.1944, val.acc = 0.6090\n",
      "Epoch 33, loss = 1.1144, val.loss = 1.1904, val.acc = 0.6112\n",
      "Epoch 34, loss = 1.1085, val.loss = 1.1866, val.acc = 0.6126\n",
      "Epoch 35, loss = 1.1028, val.loss = 1.1829, val.acc = 0.6146\n",
      "Epoch 36, loss = 1.0972, val.loss = 1.1794, val.acc = 0.6146\n",
      "Epoch 37, loss = 1.0918, val.loss = 1.1759, val.acc = 0.6162\n",
      "Epoch 38, loss = 1.0865, val.loss = 1.1727, val.acc = 0.6184\n",
      "Epoch 39, loss = 1.0814, val.loss = 1.1695, val.acc = 0.6190\n",
      "Epoch 40, loss = 1.0764, val.loss = 1.1664, val.acc = 0.6186\n",
      "Epoch 41, loss = 1.0715, val.loss = 1.1635, val.acc = 0.6194\n",
      "Epoch 42, loss = 1.0667, val.loss = 1.1606, val.acc = 0.6210\n",
      "Epoch 43, loss = 1.0621, val.loss = 1.1579, val.acc = 0.6212\n",
      "Epoch 44, loss = 1.0575, val.loss = 1.1552, val.acc = 0.6222\n",
      "Epoch 45, loss = 1.0531, val.loss = 1.1526, val.acc = 0.6224\n",
      "Epoch 46, loss = 1.0487, val.loss = 1.1501, val.acc = 0.6220\n",
      "Epoch 47, loss = 1.0445, val.loss = 1.1477, val.acc = 0.6226\n",
      "Epoch 48, loss = 1.0403, val.loss = 1.1454, val.acc = 0.6240\n",
      "Epoch 49, loss = 1.0362, val.loss = 1.1431, val.acc = 0.6240\n",
      "Epoch 50, loss = 1.0322, val.loss = 1.1409, val.acc = 0.6250\n",
      "Epoch 51, loss = 1.0282, val.loss = 1.1387, val.acc = 0.6258\n",
      "Epoch 52, loss = 1.0244, val.loss = 1.1366, val.acc = 0.6274\n",
      "Epoch 53, loss = 1.0206, val.loss = 1.1346, val.acc = 0.6276\n",
      "Epoch 54, loss = 1.0169, val.loss = 1.1326, val.acc = 0.6282\n",
      "Epoch 55, loss = 1.0132, val.loss = 1.1307, val.acc = 0.6286\n",
      "Epoch 56, loss = 1.0096, val.loss = 1.1289, val.acc = 0.6288\n",
      "Epoch 57, loss = 1.0061, val.loss = 1.1270, val.acc = 0.6300\n",
      "Epoch 58, loss = 1.0026, val.loss = 1.1253, val.acc = 0.6308\n",
      "Epoch 59, loss = 0.9991, val.loss = 1.1236, val.acc = 0.6312\n",
      "Epoch 60, loss = 0.9958, val.loss = 1.1219, val.acc = 0.6318\n",
      "Epoch 61, loss = 0.9925, val.loss = 1.1202, val.acc = 0.6322\n",
      "Epoch 62, loss = 0.9892, val.loss = 1.1187, val.acc = 0.6328\n",
      "Epoch 63, loss = 0.9860, val.loss = 1.1171, val.acc = 0.6332\n",
      "Epoch 64, loss = 0.9828, val.loss = 1.1156, val.acc = 0.6338\n",
      "Epoch 65, loss = 0.9797, val.loss = 1.1141, val.acc = 0.6338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.9766, val.loss = 1.1127, val.acc = 0.6336\n",
      "Epoch 67, loss = 0.9735, val.loss = 1.1113, val.acc = 0.6332\n",
      "Epoch 68, loss = 0.9705, val.loss = 1.1099, val.acc = 0.6330\n",
      "Epoch 69, loss = 0.9676, val.loss = 1.1085, val.acc = 0.6326\n",
      "Epoch 70, loss = 0.9647, val.loss = 1.1072, val.acc = 0.6334\n",
      "Epoch 71, loss = 0.9618, val.loss = 1.1060, val.acc = 0.6340\n",
      "Epoch 72, loss = 0.9589, val.loss = 1.1047, val.acc = 0.6350\n",
      "Epoch 73, loss = 0.9561, val.loss = 1.1035, val.acc = 0.6354\n",
      "Epoch 74, loss = 0.9534, val.loss = 1.1023, val.acc = 0.6362\n",
      "Epoch 75, loss = 0.9506, val.loss = 1.1011, val.acc = 0.6360\n",
      "Epoch 76, loss = 0.9479, val.loss = 1.1000, val.acc = 0.6366\n",
      "Epoch 77, loss = 0.9452, val.loss = 1.0989, val.acc = 0.6378\n",
      "Epoch 78, loss = 0.9426, val.loss = 1.0978, val.acc = 0.6382\n",
      "Epoch 79, loss = 0.9400, val.loss = 1.0967, val.acc = 0.6388\n",
      "Epoch 80, loss = 0.9374, val.loss = 1.0956, val.acc = 0.6390\n",
      "Epoch 81, loss = 0.9349, val.loss = 1.0946, val.acc = 0.6396\n",
      "Epoch 82, loss = 0.9323, val.loss = 1.0936, val.acc = 0.6396\n",
      "Epoch 83, loss = 0.9298, val.loss = 1.0926, val.acc = 0.6398\n",
      "Epoch 84, loss = 0.9274, val.loss = 1.0917, val.acc = 0.6396\n",
      "Epoch 85, loss = 0.9249, val.loss = 1.0907, val.acc = 0.6406\n",
      "Epoch 86, loss = 0.9225, val.loss = 1.0898, val.acc = 0.6410\n",
      "Epoch 87, loss = 0.9201, val.loss = 1.0889, val.acc = 0.6408\n",
      "Epoch 88, loss = 0.9178, val.loss = 1.0880, val.acc = 0.6412\n",
      "Epoch 89, loss = 0.9154, val.loss = 1.0872, val.acc = 0.6414\n",
      "Epoch 90, loss = 0.9131, val.loss = 1.0863, val.acc = 0.6414\n",
      "Epoch 91, loss = 0.9108, val.loss = 1.0855, val.acc = 0.6422\n",
      "Epoch 92, loss = 0.9085, val.loss = 1.0847, val.acc = 0.6422\n",
      "Epoch 93, loss = 0.9063, val.loss = 1.0839, val.acc = 0.6422\n",
      "Epoch 94, loss = 0.9041, val.loss = 1.0831, val.acc = 0.6424\n",
      "Epoch 95, loss = 0.9018, val.loss = 1.0823, val.acc = 0.6432\n",
      "Epoch 96, loss = 0.8997, val.loss = 1.0816, val.acc = 0.6432\n",
      "Epoch 97, loss = 0.8975, val.loss = 1.0808, val.acc = 0.6442\n",
      "Epoch 98, loss = 0.8954, val.loss = 1.0801, val.acc = 0.6444\n",
      "Epoch 99, loss = 0.8932, val.loss = 1.0794, val.acc = 0.6452\n",
      "Epoch 100, loss = 0.8911, val.loss = 1.0787, val.acc = 0.6450\n",
      "Epoch 101, loss = 0.8890, val.loss = 1.0780, val.acc = 0.6464\n",
      "Epoch 102, loss = 0.8870, val.loss = 1.0774, val.acc = 0.6466\n",
      "Epoch 103, loss = 0.8849, val.loss = 1.0767, val.acc = 0.6466\n",
      "Epoch 104, loss = 0.8829, val.loss = 1.0761, val.acc = 0.6468\n",
      "Epoch 105, loss = 0.8809, val.loss = 1.0754, val.acc = 0.6472\n",
      "Epoch 106, loss = 0.8789, val.loss = 1.0748, val.acc = 0.6476\n",
      "Epoch 107, loss = 0.8769, val.loss = 1.0742, val.acc = 0.6484\n",
      "Epoch 108, loss = 0.8749, val.loss = 1.0736, val.acc = 0.6482\n",
      "Epoch 109, loss = 0.8730, val.loss = 1.0730, val.acc = 0.6480\n",
      "Epoch 110, loss = 0.8710, val.loss = 1.0725, val.acc = 0.6488\n",
      "Epoch 111, loss = 0.8691, val.loss = 1.0719, val.acc = 0.6490\n",
      "Epoch 112, loss = 0.8672, val.loss = 1.0714, val.acc = 0.6494\n",
      "Epoch 113, loss = 0.8653, val.loss = 1.0708, val.acc = 0.6494\n",
      "Epoch 114, loss = 0.8635, val.loss = 1.0703, val.acc = 0.6498\n",
      "Epoch 115, loss = 0.8616, val.loss = 1.0698, val.acc = 0.6494\n",
      "Epoch 116, loss = 0.8598, val.loss = 1.0693, val.acc = 0.6490\n",
      "Epoch 117, loss = 0.8579, val.loss = 1.0688, val.acc = 0.6492\n",
      "Epoch 118, loss = 0.8561, val.loss = 1.0683, val.acc = 0.6488\n",
      "Epoch 119, loss = 0.8543, val.loss = 1.0678, val.acc = 0.6484\n",
      "Epoch 120, loss = 0.8525, val.loss = 1.0673, val.acc = 0.6480\n",
      "Epoch 121, loss = 0.8508, val.loss = 1.0669, val.acc = 0.6480\n",
      "Epoch 122, loss = 0.8490, val.loss = 1.0664, val.acc = 0.6478\n",
      "Epoch 123, loss = 0.8473, val.loss = 1.0660, val.acc = 0.6480\n",
      "Epoch 124, loss = 0.8455, val.loss = 1.0655, val.acc = 0.6482\n",
      "Epoch 125, loss = 0.8438, val.loss = 1.0651, val.acc = 0.6486\n",
      "Epoch 126, loss = 0.8421, val.loss = 1.0647, val.acc = 0.6496\n",
      "Epoch 127, loss = 0.8404, val.loss = 1.0643, val.acc = 0.6498\n",
      "Epoch 128, loss = 0.8387, val.loss = 1.0639, val.acc = 0.6496\n",
      "Epoch 129, loss = 0.8370, val.loss = 1.0635, val.acc = 0.6494\n",
      "Epoch 130, loss = 0.8354, val.loss = 1.0631, val.acc = 0.6496\n",
      "Epoch 131, loss = 0.8337, val.loss = 1.0627, val.acc = 0.6492\n",
      "Epoch 132, loss = 0.8321, val.loss = 1.0624, val.acc = 0.6496\n",
      "Epoch 133, loss = 0.8305, val.loss = 1.0620, val.acc = 0.6494\n",
      "Epoch 134, loss = 0.8288, val.loss = 1.0616, val.acc = 0.6502\n",
      "Epoch 135, loss = 0.8272, val.loss = 1.0613, val.acc = 0.6502\n",
      "Epoch 136, loss = 0.8256, val.loss = 1.0609, val.acc = 0.6512\n",
      "Epoch 137, loss = 0.8241, val.loss = 1.0606, val.acc = 0.6512\n",
      "Epoch 138, loss = 0.8225, val.loss = 1.0603, val.acc = 0.6512\n",
      "Epoch 139, loss = 0.8209, val.loss = 1.0600, val.acc = 0.6512\n",
      "Epoch 140, loss = 0.8194, val.loss = 1.0596, val.acc = 0.6516\n",
      "Epoch 141, loss = 0.8178, val.loss = 1.0593, val.acc = 0.6516\n",
      "Epoch 142, loss = 0.8163, val.loss = 1.0590, val.acc = 0.6514\n",
      "Epoch 143, loss = 0.8148, val.loss = 1.0587, val.acc = 0.6514\n",
      "Epoch 144, loss = 0.8133, val.loss = 1.0584, val.acc = 0.6518\n",
      "Epoch 145, loss = 0.8117, val.loss = 1.0582, val.acc = 0.6518\n",
      "Epoch 146, loss = 0.8103, val.loss = 1.0579, val.acc = 0.6516\n",
      "Epoch 147, loss = 0.8088, val.loss = 1.0576, val.acc = 0.6516\n",
      "Epoch 148, loss = 0.8073, val.loss = 1.0573, val.acc = 0.6514\n",
      "Epoch 149, loss = 0.8058, val.loss = 1.0571, val.acc = 0.6516\n",
      "Rep: 1, te.acc = 0.6361\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6361]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 5\n",
    "vis = visdom.Visdom(port=8097,env='ae'+str(pars.decoder_channel)+'_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T16:30:50.175650Z",
     "start_time": "2022-04-02T15:58:30.089153Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_16/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_10_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=16384, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(16, 32, 32))\n",
      "    (deconv): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.2991, time: 17.5019\n",
      "reconstruction loss = 0.0641, similarity loss: 0.6583\n",
      "Epoch 1, loss = 0.9844, time: 16.9374\n",
      "reconstruction loss = 0.0412, similarity loss: 0.5727\n",
      "Epoch 2, loss = 0.9523, time: 16.9269\n",
      "reconstruction loss = 0.0364, similarity loss: 0.5878\n",
      "Epoch 3, loss = 0.9403, time: 17.0643\n",
      "reconstruction loss = 0.0300, similarity loss: 0.6404\n",
      "Epoch 4, loss = 0.8308, time: 16.9976\n",
      "reconstruction loss = 0.0324, similarity loss: 0.5071\n",
      "Epoch 5, loss = 0.6544, time: 16.9721\n",
      "reconstruction loss = 0.0255, similarity loss: 0.3997\n",
      "Epoch 6, loss = 0.6458, time: 17.0364\n",
      "reconstruction loss = 0.0235, similarity loss: 0.4105\n",
      "Epoch 7, loss = 0.7028, time: 17.0574\n",
      "reconstruction loss = 0.0216, similarity loss: 0.4864\n",
      "Epoch 8, loss = 0.5886, time: 16.9556\n",
      "reconstruction loss = 0.0208, similarity loss: 0.3805\n",
      "Epoch 9, loss = 0.6339, time: 17.0269\n",
      "reconstruction loss = 0.0235, similarity loss: 0.3991\n",
      "Epoch 10, loss = 0.5350, time: 16.9005\n",
      "reconstruction loss = 0.0194, similarity loss: 0.3407\n",
      "Epoch 11, loss = 0.5629, time: 17.0559\n",
      "reconstruction loss = 0.0202, similarity loss: 0.3610\n",
      "Epoch 12, loss = 0.5522, time: 16.8868\n",
      "reconstruction loss = 0.0197, similarity loss: 0.3549\n",
      "Epoch 13, loss = 0.5344, time: 17.0748\n",
      "reconstruction loss = 0.0188, similarity loss: 0.3464\n",
      "Epoch 14, loss = 0.5382, time: 17.0143\n",
      "reconstruction loss = 0.0199, similarity loss: 0.3389\n",
      "Epoch 15, loss = 0.5487, time: 17.0296\n",
      "reconstruction loss = 0.0186, similarity loss: 0.3628\n",
      "Epoch 16, loss = 0.4546, time: 16.8736\n",
      "reconstruction loss = 0.0169, similarity loss: 0.2859\n",
      "Epoch 17, loss = 0.5016, time: 16.4522\n",
      "reconstruction loss = 0.0185, similarity loss: 0.3167\n",
      "Epoch 18, loss = 0.4175, time: 16.4458\n",
      "reconstruction loss = 0.0162, similarity loss: 0.2554\n",
      "Epoch 19, loss = 0.5308, time: 16.4906\n",
      "reconstruction loss = 0.0210, similarity loss: 0.3205\n",
      "Epoch 20, loss = 0.5212, time: 16.4961\n",
      "reconstruction loss = 0.0176, similarity loss: 0.3455\n",
      "Epoch 21, loss = 0.4638, time: 16.5613\n",
      "reconstruction loss = 0.0172, similarity loss: 0.2920\n",
      "Epoch 22, loss = 0.4560, time: 16.4008\n",
      "reconstruction loss = 0.0160, similarity loss: 0.2963\n",
      "Epoch 23, loss = 0.5047, time: 16.4441\n",
      "reconstruction loss = 0.0168, similarity loss: 0.3363\n",
      "Epoch 24, loss = 0.4949, time: 16.4396\n",
      "reconstruction loss = 0.0162, similarity loss: 0.3334\n",
      "Epoch 25, loss = 0.5083, time: 16.4278\n",
      "reconstruction loss = 0.0165, similarity loss: 0.3436\n",
      "Epoch 26, loss = 0.5126, time: 16.5249\n",
      "reconstruction loss = 0.0175, similarity loss: 0.3374\n",
      "Epoch 27, loss = 0.4395, time: 16.5251\n",
      "reconstruction loss = 0.0167, similarity loss: 0.2723\n",
      "Epoch 28, loss = 0.4242, time: 16.3869\n",
      "reconstruction loss = 0.0145, similarity loss: 0.2790\n",
      "Epoch 29, loss = 0.4436, time: 16.4263\n",
      "reconstruction loss = 0.0154, similarity loss: 0.2895\n",
      "Epoch 30, loss = 0.4342, time: 16.4138\n",
      "reconstruction loss = 0.0138, similarity loss: 0.2965\n",
      "Epoch 31, loss = 0.4163, time: 16.4168\n",
      "reconstruction loss = 0.0150, similarity loss: 0.2666\n",
      "Epoch 32, loss = 0.4240, time: 16.5283\n",
      "reconstruction loss = 0.0136, similarity loss: 0.2877\n",
      "Epoch 33, loss = 0.4494, time: 16.4979\n",
      "reconstruction loss = 0.0143, similarity loss: 0.3069\n",
      "Epoch 34, loss = 0.4237, time: 16.4947\n",
      "reconstruction loss = 0.0139, similarity loss: 0.2851\n",
      "Epoch 35, loss = 0.4118, time: 16.7976\n",
      "reconstruction loss = 0.0139, similarity loss: 0.2731\n",
      "Epoch 36, loss = 0.4491, time: 16.8988\n",
      "reconstruction loss = 0.0154, similarity loss: 0.2950\n",
      "Epoch 37, loss = 0.4136, time: 17.0877\n",
      "reconstruction loss = 0.0144, similarity loss: 0.2699\n",
      "Epoch 38, loss = 0.4142, time: 17.1378\n",
      "reconstruction loss = 0.0142, similarity loss: 0.2726\n",
      "Epoch 39, loss = 0.4423, time: 17.0402\n",
      "reconstruction loss = 0.0140, similarity loss: 0.3025\n",
      "Epoch 40, loss = 0.4040, time: 17.1116\n",
      "reconstruction loss = 0.0144, similarity loss: 0.2601\n",
      "Epoch 41, loss = 0.4356, time: 17.3149\n",
      "reconstruction loss = 0.0142, similarity loss: 0.2931\n",
      "Epoch 42, loss = 0.4178, time: 17.0940\n",
      "reconstruction loss = 0.0138, similarity loss: 0.2796\n",
      "Epoch 43, loss = 0.4535, time: 17.0899\n",
      "reconstruction loss = 0.0152, similarity loss: 0.3018\n",
      "Epoch 44, loss = 0.4167, time: 16.9764\n",
      "reconstruction loss = 0.0142, similarity loss: 0.2746\n",
      "Epoch 45, loss = 0.4187, time: 17.0304\n",
      "reconstruction loss = 0.0146, similarity loss: 0.2731\n",
      "Epoch 46, loss = 0.4442, time: 17.0660\n",
      "reconstruction loss = 0.0128, similarity loss: 0.3162\n",
      "Epoch 47, loss = 0.4288, time: 16.9811\n",
      "reconstruction loss = 0.0133, similarity loss: 0.2956\n",
      "Epoch 48, loss = 0.4304, time: 17.1117\n",
      "reconstruction loss = 0.0149, similarity loss: 0.2817\n",
      "Epoch 49, loss = 0.4175, time: 16.9716\n",
      "reconstruction loss = 0.0144, similarity loss: 0.2736\n",
      "Epoch 50, loss = 0.3846, time: 17.0570\n",
      "reconstruction loss = 0.0124, similarity loss: 0.2603\n",
      "Epoch 51, loss = 0.3735, time: 17.1235\n",
      "reconstruction loss = 0.0126, similarity loss: 0.2478\n",
      "Epoch 52, loss = 0.4008, time: 17.0251\n",
      "reconstruction loss = 0.0130, similarity loss: 0.2705\n",
      "Epoch 53, loss = 0.4077, time: 16.9169\n",
      "reconstruction loss = 0.0137, similarity loss: 0.2709\n",
      "Epoch 54, loss = 0.4315, time: 17.0186\n",
      "reconstruction loss = 0.0124, similarity loss: 0.3072\n",
      "Epoch 55, loss = 0.4138, time: 17.1087\n",
      "reconstruction loss = 0.0124, similarity loss: 0.2893\n",
      "Epoch 56, loss = 0.3872, time: 16.9988\n",
      "reconstruction loss = 0.0119, similarity loss: 0.2686\n",
      "Epoch 57, loss = 0.3631, time: 17.0336\n",
      "reconstruction loss = 0.0106, similarity loss: 0.2573\n",
      "Epoch 58, loss = 0.3778, time: 17.1619\n",
      "reconstruction loss = 0.0125, similarity loss: 0.2528\n",
      "Epoch 59, loss = 0.3968, time: 17.0579\n",
      "reconstruction loss = 0.0128, similarity loss: 0.2691\n",
      "Epoch 60, loss = 0.3868, time: 17.0254\n",
      "reconstruction loss = 0.0118, similarity loss: 0.2684\n",
      "Epoch 61, loss = 0.4069, time: 17.0219\n",
      "reconstruction loss = 0.0137, similarity loss: 0.2701\n",
      "Epoch 62, loss = 0.3414, time: 16.9771\n",
      "reconstruction loss = 0.0107, similarity loss: 0.2347\n",
      "Epoch 63, loss = 0.3859, time: 17.0679\n",
      "reconstruction loss = 0.0123, similarity loss: 0.2629\n",
      "Epoch 64, loss = 0.4038, time: 17.1117\n",
      "reconstruction loss = 0.0129, similarity loss: 0.2751\n",
      "Epoch 65, loss = 0.3970, time: 17.0790\n",
      "reconstruction loss = 0.0117, similarity loss: 0.2799\n",
      "Epoch 66, loss = 0.4375, time: 16.9878\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2858\n",
      "Epoch 67, loss = 0.4165, time: 17.1825\n",
      "reconstruction loss = 0.0120, similarity loss: 0.2965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.3919, time: 17.4419\n",
      "reconstruction loss = 0.0109, similarity loss: 0.2825\n",
      "Epoch 69, loss = 0.4079, time: 17.3276\n",
      "reconstruction loss = 0.0119, similarity loss: 0.2893\n",
      "Epoch 70, loss = 0.4037, time: 16.4519\n",
      "reconstruction loss = 0.0115, similarity loss: 0.2883\n",
      "Epoch 71, loss = 0.3822, time: 16.5090\n",
      "reconstruction loss = 0.0127, similarity loss: 0.2548\n",
      "Epoch 72, loss = 0.3726, time: 16.5258\n",
      "reconstruction loss = 0.0113, similarity loss: 0.2600\n",
      "Epoch 73, loss = 0.3664, time: 16.3891\n",
      "reconstruction loss = 0.0113, similarity loss: 0.2536\n",
      "Epoch 74, loss = 0.3589, time: 16.4898\n",
      "reconstruction loss = 0.0113, similarity loss: 0.2464\n",
      "Epoch 75, loss = 0.3822, time: 16.4708\n",
      "reconstruction loss = 0.0130, similarity loss: 0.2525\n",
      "Epoch 76, loss = 0.3728, time: 16.5058\n",
      "reconstruction loss = 0.0123, similarity loss: 0.2494\n",
      "Epoch 77, loss = 0.4406, time: 16.4697\n",
      "reconstruction loss = 0.0141, similarity loss: 0.2996\n",
      "Epoch 78, loss = 0.3795, time: 16.5141\n",
      "reconstruction loss = 0.0126, similarity loss: 0.2532\n",
      "Epoch 79, loss = 0.3963, time: 16.5862\n",
      "reconstruction loss = 0.0101, similarity loss: 0.2954\n",
      "Epoch 80, loss = 0.3595, time: 16.5549\n",
      "reconstruction loss = 0.0111, similarity loss: 0.2487\n",
      "Epoch 81, loss = 0.3495, time: 16.4833\n",
      "reconstruction loss = 0.0109, similarity loss: 0.2405\n",
      "Epoch 82, loss = 0.3981, time: 16.4716\n",
      "reconstruction loss = 0.0112, similarity loss: 0.2863\n",
      "Epoch 83, loss = 0.3659, time: 16.5759\n",
      "reconstruction loss = 0.0097, similarity loss: 0.2694\n",
      "Epoch 84, loss = 0.3800, time: 16.5425\n",
      "reconstruction loss = 0.0122, similarity loss: 0.2577\n",
      "Epoch 85, loss = 0.4182, time: 16.5509\n",
      "reconstruction loss = 0.0137, similarity loss: 0.2814\n",
      "Epoch 86, loss = 0.3896, time: 16.5233\n",
      "reconstruction loss = 0.0114, similarity loss: 0.2758\n",
      "Epoch 87, loss = 0.3666, time: 16.5052\n",
      "reconstruction loss = 0.0094, similarity loss: 0.2725\n",
      "Epoch 88, loss = 0.3646, time: 16.3757\n",
      "reconstruction loss = 0.0104, similarity loss: 0.2602\n",
      "Epoch 89, loss = 0.3813, time: 16.5058\n",
      "reconstruction loss = 0.0110, similarity loss: 0.2712\n",
      "Epoch 90, loss = 0.3663, time: 16.6484\n",
      "reconstruction loss = 0.0096, similarity loss: 0.2703\n",
      "Epoch 91, loss = 0.3623, time: 16.6581\n",
      "reconstruction loss = 0.0113, similarity loss: 0.2498\n",
      "Epoch 92, loss = 0.3497, time: 16.9553\n",
      "reconstruction loss = 0.0100, similarity loss: 0.2496\n",
      "Epoch 93, loss = 0.3311, time: 16.9425\n",
      "reconstruction loss = 0.0090, similarity loss: 0.2413\n",
      "Epoch 94, loss = 0.3435, time: 16.9316\n",
      "reconstruction loss = 0.0097, similarity loss: 0.2461\n",
      "Epoch 95, loss = 0.3366, time: 17.0730\n",
      "reconstruction loss = 0.0102, similarity loss: 0.2345\n",
      "Epoch 96, loss = 0.3904, time: 16.8468\n",
      "reconstruction loss = 0.0115, similarity loss: 0.2749\n",
      "Epoch 97, loss = 0.3847, time: 17.0236\n",
      "reconstruction loss = 0.0112, similarity loss: 0.2732\n",
      "Epoch 98, loss = 0.3621, time: 17.1278\n",
      "reconstruction loss = 0.0101, similarity loss: 0.2608\n",
      "Epoch 99, loss = 0.3624, time: 17.0274\n",
      "reconstruction loss = 0.0103, similarity loss: 0.2595\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 2.1036, val.loss = 1.9377, val.acc = 0.4146\n",
      "Epoch 1, loss = 1.8447, val.loss = 1.7651, val.acc = 0.4628\n",
      "Epoch 2, loss = 1.7102, val.loss = 1.6651, val.acc = 0.4856\n",
      "Epoch 3, loss = 1.6247, val.loss = 1.5971, val.acc = 0.5000\n",
      "Epoch 4, loss = 1.5630, val.loss = 1.5462, val.acc = 0.5126\n",
      "Epoch 5, loss = 1.5149, val.loss = 1.5057, val.acc = 0.5214\n",
      "Epoch 6, loss = 1.4754, val.loss = 1.4722, val.acc = 0.5310\n",
      "Epoch 7, loss = 1.4419, val.loss = 1.4437, val.acc = 0.5368\n",
      "Epoch 8, loss = 1.4128, val.loss = 1.4190, val.acc = 0.5418\n",
      "Epoch 9, loss = 1.3872, val.loss = 1.3972, val.acc = 0.5476\n",
      "Epoch 10, loss = 1.3642, val.loss = 1.3778, val.acc = 0.5536\n",
      "Epoch 11, loss = 1.3435, val.loss = 1.3604, val.acc = 0.5572\n",
      "Epoch 12, loss = 1.3246, val.loss = 1.3445, val.acc = 0.5618\n",
      "Epoch 13, loss = 1.3072, val.loss = 1.3301, val.acc = 0.5678\n",
      "Epoch 14, loss = 1.2911, val.loss = 1.3168, val.acc = 0.5712\n",
      "Epoch 15, loss = 1.2762, val.loss = 1.3045, val.acc = 0.5736\n",
      "Epoch 16, loss = 1.2623, val.loss = 1.2932, val.acc = 0.5762\n",
      "Epoch 17, loss = 1.2492, val.loss = 1.2826, val.acc = 0.5800\n",
      "Epoch 18, loss = 1.2370, val.loss = 1.2728, val.acc = 0.5836\n",
      "Epoch 19, loss = 1.2254, val.loss = 1.2635, val.acc = 0.5848\n",
      "Epoch 20, loss = 1.2145, val.loss = 1.2549, val.acc = 0.5872\n",
      "Epoch 21, loss = 1.2041, val.loss = 1.2468, val.acc = 0.5900\n",
      "Epoch 22, loss = 1.1942, val.loss = 1.2391, val.acc = 0.5940\n",
      "Epoch 23, loss = 1.1848, val.loss = 1.2318, val.acc = 0.5972\n",
      "Epoch 24, loss = 1.1759, val.loss = 1.2250, val.acc = 0.6008\n",
      "Epoch 25, loss = 1.1673, val.loss = 1.2185, val.acc = 0.6046\n",
      "Epoch 26, loss = 1.1591, val.loss = 1.2123, val.acc = 0.6058\n",
      "Epoch 27, loss = 1.1512, val.loss = 1.2064, val.acc = 0.6068\n",
      "Epoch 28, loss = 1.1436, val.loss = 1.2008, val.acc = 0.6080\n",
      "Epoch 29, loss = 1.1363, val.loss = 1.1955, val.acc = 0.6082\n",
      "Epoch 30, loss = 1.1293, val.loss = 1.1904, val.acc = 0.6102\n",
      "Epoch 31, loss = 1.1225, val.loss = 1.1855, val.acc = 0.6104\n",
      "Epoch 32, loss = 1.1160, val.loss = 1.1808, val.acc = 0.6122\n",
      "Epoch 33, loss = 1.1097, val.loss = 1.1763, val.acc = 0.6124\n",
      "Epoch 34, loss = 1.1035, val.loss = 1.1720, val.acc = 0.6128\n",
      "Epoch 35, loss = 1.0976, val.loss = 1.1679, val.acc = 0.6144\n",
      "Epoch 36, loss = 1.0918, val.loss = 1.1639, val.acc = 0.6160\n",
      "Epoch 37, loss = 1.0862, val.loss = 1.1601, val.acc = 0.6156\n",
      "Epoch 38, loss = 1.0808, val.loss = 1.1564, val.acc = 0.6168\n",
      "Epoch 39, loss = 1.0755, val.loss = 1.1529, val.acc = 0.6176\n",
      "Epoch 40, loss = 1.0703, val.loss = 1.1494, val.acc = 0.6194\n",
      "Epoch 41, loss = 1.0653, val.loss = 1.1461, val.acc = 0.6202\n",
      "Epoch 42, loss = 1.0604, val.loss = 1.1429, val.acc = 0.6200\n",
      "Epoch 43, loss = 1.0556, val.loss = 1.1399, val.acc = 0.6210\n",
      "Epoch 44, loss = 1.0510, val.loss = 1.1369, val.acc = 0.6222\n",
      "Epoch 45, loss = 1.0464, val.loss = 1.1340, val.acc = 0.6234\n",
      "Epoch 46, loss = 1.0420, val.loss = 1.1312, val.acc = 0.6244\n",
      "Epoch 47, loss = 1.0376, val.loss = 1.1284, val.acc = 0.6256\n",
      "Epoch 48, loss = 1.0334, val.loss = 1.1258, val.acc = 0.6256\n",
      "Epoch 49, loss = 1.0292, val.loss = 1.1233, val.acc = 0.6254\n",
      "Epoch 50, loss = 1.0251, val.loss = 1.1208, val.acc = 0.6256\n",
      "Epoch 51, loss = 1.0211, val.loss = 1.1184, val.acc = 0.6264\n",
      "Epoch 52, loss = 1.0172, val.loss = 1.1160, val.acc = 0.6282\n",
      "Epoch 53, loss = 1.0134, val.loss = 1.1137, val.acc = 0.6288\n",
      "Epoch 54, loss = 1.0096, val.loss = 1.1115, val.acc = 0.6296\n",
      "Epoch 55, loss = 1.0059, val.loss = 1.1094, val.acc = 0.6300\n",
      "Epoch 56, loss = 1.0023, val.loss = 1.1073, val.acc = 0.6306\n",
      "Epoch 57, loss = 0.9987, val.loss = 1.1052, val.acc = 0.6314\n",
      "Epoch 58, loss = 0.9952, val.loss = 1.1033, val.acc = 0.6318\n",
      "Epoch 59, loss = 0.9917, val.loss = 1.1013, val.acc = 0.6326\n",
      "Epoch 60, loss = 0.9884, val.loss = 1.0994, val.acc = 0.6330\n",
      "Epoch 61, loss = 0.9850, val.loss = 1.0976, val.acc = 0.6330\n",
      "Epoch 62, loss = 0.9817, val.loss = 1.0958, val.acc = 0.6334\n",
      "Epoch 63, loss = 0.9785, val.loss = 1.0940, val.acc = 0.6336\n",
      "Epoch 64, loss = 0.9753, val.loss = 1.0923, val.acc = 0.6340\n",
      "Epoch 65, loss = 0.9722, val.loss = 1.0907, val.acc = 0.6346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.9691, val.loss = 1.0890, val.acc = 0.6344\n",
      "Epoch 67, loss = 0.9661, val.loss = 1.0874, val.acc = 0.6352\n",
      "Epoch 68, loss = 0.9631, val.loss = 1.0859, val.acc = 0.6360\n",
      "Epoch 69, loss = 0.9602, val.loss = 1.0844, val.acc = 0.6370\n",
      "Epoch 70, loss = 0.9572, val.loss = 1.0829, val.acc = 0.6374\n",
      "Epoch 71, loss = 0.9544, val.loss = 1.0814, val.acc = 0.6378\n",
      "Epoch 72, loss = 0.9515, val.loss = 1.0800, val.acc = 0.6378\n",
      "Epoch 73, loss = 0.9488, val.loss = 1.0786, val.acc = 0.6380\n",
      "Epoch 74, loss = 0.9460, val.loss = 1.0773, val.acc = 0.6376\n",
      "Epoch 75, loss = 0.9433, val.loss = 1.0759, val.acc = 0.6378\n",
      "Epoch 76, loss = 0.9406, val.loss = 1.0747, val.acc = 0.6380\n",
      "Epoch 77, loss = 0.9379, val.loss = 1.0734, val.acc = 0.6388\n",
      "Epoch 78, loss = 0.9353, val.loss = 1.0721, val.acc = 0.6382\n",
      "Epoch 79, loss = 0.9327, val.loss = 1.0709, val.acc = 0.6384\n",
      "Epoch 80, loss = 0.9302, val.loss = 1.0697, val.acc = 0.6392\n",
      "Epoch 81, loss = 0.9277, val.loss = 1.0686, val.acc = 0.6400\n",
      "Epoch 82, loss = 0.9252, val.loss = 1.0674, val.acc = 0.6404\n",
      "Epoch 83, loss = 0.9227, val.loss = 1.0663, val.acc = 0.6416\n",
      "Epoch 84, loss = 0.9203, val.loss = 1.0652, val.acc = 0.6420\n",
      "Epoch 85, loss = 0.9179, val.loss = 1.0641, val.acc = 0.6424\n",
      "Epoch 86, loss = 0.9155, val.loss = 1.0630, val.acc = 0.6426\n",
      "Epoch 87, loss = 0.9131, val.loss = 1.0620, val.acc = 0.6432\n",
      "Epoch 88, loss = 0.9108, val.loss = 1.0610, val.acc = 0.6426\n",
      "Epoch 89, loss = 0.9085, val.loss = 1.0600, val.acc = 0.6430\n",
      "Epoch 90, loss = 0.9062, val.loss = 1.0590, val.acc = 0.6432\n",
      "Epoch 91, loss = 0.9039, val.loss = 1.0581, val.acc = 0.6430\n",
      "Epoch 92, loss = 0.9017, val.loss = 1.0571, val.acc = 0.6430\n",
      "Epoch 93, loss = 0.8995, val.loss = 1.0562, val.acc = 0.6430\n",
      "Epoch 94, loss = 0.8973, val.loss = 1.0553, val.acc = 0.6428\n",
      "Epoch 95, loss = 0.8951, val.loss = 1.0544, val.acc = 0.6422\n",
      "Epoch 96, loss = 0.8930, val.loss = 1.0536, val.acc = 0.6428\n",
      "Epoch 97, loss = 0.8909, val.loss = 1.0527, val.acc = 0.6434\n",
      "Epoch 98, loss = 0.8888, val.loss = 1.0519, val.acc = 0.6442\n",
      "Epoch 99, loss = 0.8867, val.loss = 1.0511, val.acc = 0.6438\n",
      "Epoch 100, loss = 0.8846, val.loss = 1.0502, val.acc = 0.6442\n",
      "Epoch 101, loss = 0.8826, val.loss = 1.0494, val.acc = 0.6446\n",
      "Epoch 102, loss = 0.8805, val.loss = 1.0487, val.acc = 0.6452\n",
      "Epoch 103, loss = 0.8785, val.loss = 1.0479, val.acc = 0.6452\n",
      "Epoch 104, loss = 0.8765, val.loss = 1.0472, val.acc = 0.6454\n",
      "Epoch 105, loss = 0.8746, val.loss = 1.0464, val.acc = 0.6452\n",
      "Epoch 106, loss = 0.8726, val.loss = 1.0457, val.acc = 0.6456\n",
      "Epoch 107, loss = 0.8707, val.loss = 1.0450, val.acc = 0.6462\n",
      "Epoch 108, loss = 0.8687, val.loss = 1.0443, val.acc = 0.6458\n",
      "Epoch 109, loss = 0.8668, val.loss = 1.0436, val.acc = 0.6464\n",
      "Epoch 110, loss = 0.8649, val.loss = 1.0430, val.acc = 0.6468\n",
      "Epoch 111, loss = 0.8631, val.loss = 1.0423, val.acc = 0.6476\n",
      "Epoch 112, loss = 0.8612, val.loss = 1.0416, val.acc = 0.6482\n",
      "Epoch 113, loss = 0.8594, val.loss = 1.0410, val.acc = 0.6482\n",
      "Epoch 114, loss = 0.8575, val.loss = 1.0404, val.acc = 0.6478\n",
      "Epoch 115, loss = 0.8557, val.loss = 1.0398, val.acc = 0.6474\n",
      "Epoch 116, loss = 0.8539, val.loss = 1.0392, val.acc = 0.6476\n",
      "Epoch 117, loss = 0.8521, val.loss = 1.0386, val.acc = 0.6478\n",
      "Epoch 118, loss = 0.8504, val.loss = 1.0380, val.acc = 0.6480\n",
      "Epoch 119, loss = 0.8486, val.loss = 1.0374, val.acc = 0.6488\n",
      "Epoch 120, loss = 0.8469, val.loss = 1.0369, val.acc = 0.6492\n",
      "Epoch 121, loss = 0.8451, val.loss = 1.0363, val.acc = 0.6492\n",
      "Epoch 122, loss = 0.8434, val.loss = 1.0358, val.acc = 0.6490\n",
      "Epoch 123, loss = 0.8417, val.loss = 1.0352, val.acc = 0.6496\n",
      "Epoch 124, loss = 0.8400, val.loss = 1.0347, val.acc = 0.6500\n",
      "Epoch 125, loss = 0.8384, val.loss = 1.0342, val.acc = 0.6500\n",
      "Epoch 126, loss = 0.8367, val.loss = 1.0337, val.acc = 0.6502\n",
      "Epoch 127, loss = 0.8350, val.loss = 1.0332, val.acc = 0.6506\n",
      "Epoch 128, loss = 0.8334, val.loss = 1.0327, val.acc = 0.6510\n",
      "Epoch 129, loss = 0.8318, val.loss = 1.0323, val.acc = 0.6514\n",
      "Epoch 130, loss = 0.8302, val.loss = 1.0318, val.acc = 0.6518\n",
      "Epoch 131, loss = 0.8286, val.loss = 1.0313, val.acc = 0.6526\n",
      "Epoch 132, loss = 0.8270, val.loss = 1.0309, val.acc = 0.6526\n",
      "Epoch 133, loss = 0.8254, val.loss = 1.0304, val.acc = 0.6522\n",
      "Epoch 134, loss = 0.8238, val.loss = 1.0300, val.acc = 0.6524\n",
      "Epoch 135, loss = 0.8222, val.loss = 1.0296, val.acc = 0.6522\n",
      "Epoch 136, loss = 0.8207, val.loss = 1.0291, val.acc = 0.6528\n",
      "Epoch 137, loss = 0.8191, val.loss = 1.0287, val.acc = 0.6530\n",
      "Epoch 138, loss = 0.8176, val.loss = 1.0283, val.acc = 0.6528\n",
      "Epoch 139, loss = 0.8161, val.loss = 1.0279, val.acc = 0.6528\n",
      "Epoch 140, loss = 0.8146, val.loss = 1.0275, val.acc = 0.6524\n",
      "Epoch 141, loss = 0.8131, val.loss = 1.0271, val.acc = 0.6522\n",
      "Epoch 142, loss = 0.8116, val.loss = 1.0268, val.acc = 0.6524\n",
      "Epoch 143, loss = 0.8101, val.loss = 1.0264, val.acc = 0.6526\n",
      "Epoch 144, loss = 0.8086, val.loss = 1.0260, val.acc = 0.6528\n",
      "Epoch 145, loss = 0.8072, val.loss = 1.0257, val.acc = 0.6528\n",
      "Epoch 146, loss = 0.8057, val.loss = 1.0253, val.acc = 0.6528\n",
      "Epoch 147, loss = 0.8043, val.loss = 1.0250, val.acc = 0.6530\n",
      "Epoch 148, loss = 0.8028, val.loss = 1.0246, val.acc = 0.6530\n",
      "Epoch 149, loss = 0.8014, val.loss = 1.0243, val.acc = 0.6534\n",
      "Rep: 1, te.acc = 0.6482\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6482]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 10\n",
    "vis = visdom.Visdom(port=8097,env='ae'+str(pars.decoder_channel)+'_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T17:03:15.391357Z",
     "start_time": "2022-04-02T16:30:50.176648Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_16/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_20_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=16384, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(16, 32, 32))\n",
      "    (deconv): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.7801, time: 17.3783\n",
      "reconstruction loss = 0.0550, similarity loss: 0.6806\n",
      "Epoch 1, loss = 1.2773, time: 17.1039\n",
      "reconstruction loss = 0.0341, similarity loss: 0.5950\n",
      "Epoch 2, loss = 1.1607, time: 17.0128\n",
      "reconstruction loss = 0.0297, similarity loss: 0.5669\n",
      "Epoch 3, loss = 0.9742, time: 17.0637\n",
      "reconstruction loss = 0.0242, similarity loss: 0.4901\n",
      "Epoch 4, loss = 1.0102, time: 17.1293\n",
      "reconstruction loss = 0.0214, similarity loss: 0.5832\n",
      "Epoch 5, loss = 0.9321, time: 17.0230\n",
      "reconstruction loss = 0.0202, similarity loss: 0.5282\n",
      "Epoch 6, loss = 0.9728, time: 17.2350\n",
      "reconstruction loss = 0.0220, similarity loss: 0.5335\n",
      "Epoch 7, loss = 0.7527, time: 17.0707\n",
      "reconstruction loss = 0.0170, similarity loss: 0.4127\n",
      "Epoch 8, loss = 0.7340, time: 17.1596\n",
      "reconstruction loss = 0.0162, similarity loss: 0.4093\n",
      "Epoch 9, loss = 0.7550, time: 17.1699\n",
      "reconstruction loss = 0.0171, similarity loss: 0.4133\n",
      "Epoch 10, loss = 0.7163, time: 17.0039\n",
      "reconstruction loss = 0.0162, similarity loss: 0.3924\n",
      "Epoch 11, loss = 0.7623, time: 16.8442\n",
      "reconstruction loss = 0.0167, similarity loss: 0.4292\n",
      "Epoch 12, loss = 0.6796, time: 16.5085\n",
      "reconstruction loss = 0.0157, similarity loss: 0.3648\n",
      "Epoch 13, loss = 0.6746, time: 16.4797\n",
      "reconstruction loss = 0.0146, similarity loss: 0.3821\n",
      "Epoch 14, loss = 0.6573, time: 16.5886\n",
      "reconstruction loss = 0.0149, similarity loss: 0.3590\n",
      "Epoch 15, loss = 0.6671, time: 16.4928\n",
      "reconstruction loss = 0.0151, similarity loss: 0.3652\n",
      "Epoch 16, loss = 0.6130, time: 16.4267\n",
      "reconstruction loss = 0.0148, similarity loss: 0.3179\n",
      "Epoch 17, loss = 0.6498, time: 16.4994\n",
      "reconstruction loss = 0.0152, similarity loss: 0.3461\n",
      "Epoch 18, loss = 0.6373, time: 16.4879\n",
      "reconstruction loss = 0.0134, similarity loss: 0.3695\n",
      "Epoch 19, loss = 0.6346, time: 16.4658\n",
      "reconstruction loss = 0.0138, similarity loss: 0.3588\n",
      "Epoch 20, loss = 0.6101, time: 16.5814\n",
      "reconstruction loss = 0.0135, similarity loss: 0.3404\n",
      "Epoch 21, loss = 0.5698, time: 16.5355\n",
      "reconstruction loss = 0.0131, similarity loss: 0.3073\n",
      "Epoch 22, loss = 0.6092, time: 16.6408\n",
      "reconstruction loss = 0.0141, similarity loss: 0.3265\n",
      "Epoch 23, loss = 0.5731, time: 16.4447\n",
      "reconstruction loss = 0.0141, similarity loss: 0.2907\n",
      "Epoch 24, loss = 0.6097, time: 16.4947\n",
      "reconstruction loss = 0.0129, similarity loss: 0.3515\n",
      "Epoch 25, loss = 0.5545, time: 16.4879\n",
      "reconstruction loss = 0.0122, similarity loss: 0.3096\n",
      "Epoch 26, loss = 0.5727, time: 16.5832\n",
      "reconstruction loss = 0.0125, similarity loss: 0.3236\n",
      "Epoch 27, loss = 0.5526, time: 16.4837\n",
      "reconstruction loss = 0.0121, similarity loss: 0.3108\n",
      "Epoch 28, loss = 0.6381, time: 16.4627\n",
      "reconstruction loss = 0.0156, similarity loss: 0.3258\n",
      "Epoch 29, loss = 0.5794, time: 16.4717\n",
      "reconstruction loss = 0.0119, similarity loss: 0.3413\n",
      "Epoch 30, loss = 0.6047, time: 17.1649\n",
      "reconstruction loss = 0.0137, similarity loss: 0.3310\n",
      "Epoch 31, loss = 0.5871, time: 16.9478\n",
      "reconstruction loss = 0.0119, similarity loss: 0.3484\n",
      "Epoch 32, loss = 0.5813, time: 17.0790\n",
      "reconstruction loss = 0.0124, similarity loss: 0.3337\n",
      "Epoch 33, loss = 0.5697, time: 17.0645\n",
      "reconstruction loss = 0.0116, similarity loss: 0.3374\n",
      "Epoch 34, loss = 0.5745, time: 16.9841\n",
      "reconstruction loss = 0.0125, similarity loss: 0.3249\n",
      "Epoch 35, loss = 0.5097, time: 17.0484\n",
      "reconstruction loss = 0.0106, similarity loss: 0.2986\n",
      "Epoch 36, loss = 0.5227, time: 17.0211\n",
      "reconstruction loss = 0.0096, similarity loss: 0.3313\n",
      "Epoch 37, loss = 0.5388, time: 17.0661\n",
      "reconstruction loss = 0.0117, similarity loss: 0.3038\n",
      "Epoch 38, loss = 0.4882, time: 17.1284\n",
      "reconstruction loss = 0.0100, similarity loss: 0.2878\n",
      "Epoch 39, loss = 0.5033, time: 17.0767\n",
      "reconstruction loss = 0.0107, similarity loss: 0.2899\n",
      "Epoch 40, loss = 0.4881, time: 17.0557\n",
      "reconstruction loss = 0.0100, similarity loss: 0.2880\n",
      "Epoch 41, loss = 0.5993, time: 17.0879\n",
      "reconstruction loss = 0.0121, similarity loss: 0.3576\n",
      "Epoch 42, loss = 0.5114, time: 17.0705\n",
      "reconstruction loss = 0.0103, similarity loss: 0.3063\n",
      "Epoch 43, loss = 0.6158, time: 17.0278\n",
      "reconstruction loss = 0.0122, similarity loss: 0.3715\n",
      "Epoch 44, loss = 0.5431, time: 17.0704\n",
      "reconstruction loss = 0.0104, similarity loss: 0.3345\n",
      "Epoch 45, loss = 0.4764, time: 17.1083\n",
      "reconstruction loss = 0.0095, similarity loss: 0.2854\n",
      "Epoch 46, loss = 0.4856, time: 17.1338\n",
      "reconstruction loss = 0.0105, similarity loss: 0.2747\n",
      "Epoch 47, loss = 0.5594, time: 16.9768\n",
      "reconstruction loss = 0.0118, similarity loss: 0.3244\n",
      "Epoch 48, loss = 0.4748, time: 16.9418\n",
      "reconstruction loss = 0.0091, similarity loss: 0.2925\n",
      "Epoch 49, loss = 0.5043, time: 16.9443\n",
      "reconstruction loss = 0.0103, similarity loss: 0.2983\n",
      "Epoch 50, loss = 0.4754, time: 16.9941\n",
      "reconstruction loss = 0.0097, similarity loss: 0.2806\n",
      "Epoch 51, loss = 0.4887, time: 17.1347\n",
      "reconstruction loss = 0.0095, similarity loss: 0.2981\n",
      "Epoch 52, loss = 0.4746, time: 17.1211\n",
      "reconstruction loss = 0.0098, similarity loss: 0.2778\n",
      "Epoch 53, loss = 0.4553, time: 17.1093\n",
      "reconstruction loss = 0.0086, similarity loss: 0.2843\n",
      "Epoch 54, loss = 0.5401, time: 17.1799\n",
      "reconstruction loss = 0.0111, similarity loss: 0.3178\n",
      "Epoch 55, loss = 0.4489, time: 17.1675\n",
      "reconstruction loss = 0.0091, similarity loss: 0.2675\n",
      "Epoch 56, loss = 0.5603, time: 17.0101\n",
      "reconstruction loss = 0.0102, similarity loss: 0.3554\n",
      "Epoch 57, loss = 0.4769, time: 16.9723\n",
      "reconstruction loss = 0.0091, similarity loss: 0.2954\n",
      "Epoch 58, loss = 0.4878, time: 17.0082\n",
      "reconstruction loss = 0.0091, similarity loss: 0.3051\n",
      "Epoch 59, loss = 0.4488, time: 16.9856\n",
      "reconstruction loss = 0.0095, similarity loss: 0.2580\n",
      "Epoch 60, loss = 0.4429, time: 17.0413\n",
      "reconstruction loss = 0.0090, similarity loss: 0.2629\n",
      "Epoch 61, loss = 0.5322, time: 16.9826\n",
      "reconstruction loss = 0.0097, similarity loss: 0.3391\n",
      "Epoch 62, loss = 0.5047, time: 17.1468\n",
      "reconstruction loss = 0.0091, similarity loss: 0.3217\n",
      "Epoch 63, loss = 0.4942, time: 17.0426\n",
      "reconstruction loss = 0.0092, similarity loss: 0.3110\n",
      "Epoch 64, loss = 0.4456, time: 17.0673\n",
      "reconstruction loss = 0.0082, similarity loss: 0.2807\n",
      "Epoch 65, loss = 0.4584, time: 16.4798\n",
      "reconstruction loss = 0.0090, similarity loss: 0.2791\n",
      "Epoch 66, loss = 0.4624, time: 16.4421\n",
      "reconstruction loss = 0.0095, similarity loss: 0.2723\n",
      "Epoch 67, loss = 0.4399, time: 16.4422\n",
      "reconstruction loss = 0.0080, similarity loss: 0.2805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.5049, time: 16.5647\n",
      "reconstruction loss = 0.0082, similarity loss: 0.3405\n",
      "Epoch 69, loss = 0.4494, time: 16.5161\n",
      "reconstruction loss = 0.0085, similarity loss: 0.2804\n",
      "Epoch 70, loss = 0.5045, time: 16.5451\n",
      "reconstruction loss = 0.0088, similarity loss: 0.3279\n",
      "Epoch 71, loss = 0.4920, time: 16.5511\n",
      "reconstruction loss = 0.0092, similarity loss: 0.3080\n",
      "Epoch 72, loss = 0.4941, time: 16.6118\n",
      "reconstruction loss = 0.0091, similarity loss: 0.3131\n",
      "Epoch 73, loss = 0.4981, time: 16.5720\n",
      "reconstruction loss = 0.0093, similarity loss: 0.3114\n",
      "Epoch 74, loss = 0.4307, time: 16.5571\n",
      "reconstruction loss = 0.0074, similarity loss: 0.2830\n",
      "Epoch 75, loss = 0.4201, time: 16.5468\n",
      "reconstruction loss = 0.0078, similarity loss: 0.2650\n",
      "Epoch 76, loss = 0.5001, time: 16.6169\n",
      "reconstruction loss = 0.0101, similarity loss: 0.2977\n",
      "Epoch 77, loss = 0.4279, time: 16.5869\n",
      "reconstruction loss = 0.0071, similarity loss: 0.2860\n",
      "Epoch 78, loss = 0.4701, time: 16.6558\n",
      "reconstruction loss = 0.0085, similarity loss: 0.3007\n",
      "Epoch 79, loss = 0.4747, time: 16.4318\n",
      "reconstruction loss = 0.0078, similarity loss: 0.3187\n",
      "Epoch 80, loss = 0.5032, time: 16.5858\n",
      "reconstruction loss = 0.0098, similarity loss: 0.3077\n",
      "Epoch 81, loss = 0.4152, time: 16.4879\n",
      "reconstruction loss = 0.0083, similarity loss: 0.2490\n",
      "Epoch 82, loss = 0.4967, time: 16.5442\n",
      "reconstruction loss = 0.0100, similarity loss: 0.2957\n",
      "Epoch 83, loss = 0.4244, time: 17.0329\n",
      "reconstruction loss = 0.0071, similarity loss: 0.2816\n",
      "Epoch 84, loss = 0.4075, time: 16.9073\n",
      "reconstruction loss = 0.0079, similarity loss: 0.2503\n",
      "Epoch 85, loss = 0.4264, time: 17.0751\n",
      "reconstruction loss = 0.0080, similarity loss: 0.2659\n",
      "Epoch 86, loss = 0.4488, time: 17.0023\n",
      "reconstruction loss = 0.0083, similarity loss: 0.2825\n",
      "Epoch 87, loss = 0.4157, time: 17.0669\n",
      "reconstruction loss = 0.0072, similarity loss: 0.2716\n",
      "Epoch 88, loss = 0.4741, time: 17.0440\n",
      "reconstruction loss = 0.0092, similarity loss: 0.2895\n",
      "Epoch 89, loss = 0.4159, time: 17.0647\n",
      "reconstruction loss = 0.0076, similarity loss: 0.2643\n",
      "Epoch 90, loss = 0.4834, time: 17.0308\n",
      "reconstruction loss = 0.0080, similarity loss: 0.3229\n",
      "Epoch 91, loss = 0.4345, time: 17.0513\n",
      "reconstruction loss = 0.0081, similarity loss: 0.2728\n",
      "Epoch 92, loss = 0.4070, time: 17.0537\n",
      "reconstruction loss = 0.0079, similarity loss: 0.2485\n",
      "Epoch 93, loss = 0.4506, time: 17.0079\n",
      "reconstruction loss = 0.0078, similarity loss: 0.2950\n",
      "Epoch 94, loss = 0.3804, time: 17.1481\n",
      "reconstruction loss = 0.0068, similarity loss: 0.2439\n",
      "Epoch 95, loss = 0.4162, time: 17.4380\n",
      "reconstruction loss = 0.0074, similarity loss: 0.2688\n",
      "Epoch 96, loss = 0.3958, time: 17.1301\n",
      "reconstruction loss = 0.0073, similarity loss: 0.2496\n",
      "Epoch 97, loss = 0.4204, time: 17.1208\n",
      "reconstruction loss = 0.0080, similarity loss: 0.2595\n",
      "Epoch 98, loss = 0.4575, time: 17.0432\n",
      "reconstruction loss = 0.0085, similarity loss: 0.2884\n",
      "Epoch 99, loss = 0.4085, time: 17.0985\n",
      "reconstruction loss = 0.0072, similarity loss: 0.2636\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 2.1073, val.loss = 1.9399, val.acc = 0.4012\n",
      "Epoch 1, loss = 1.8431, val.loss = 1.7670, val.acc = 0.4540\n",
      "Epoch 2, loss = 1.7086, val.loss = 1.6673, val.acc = 0.4792\n",
      "Epoch 3, loss = 1.6231, val.loss = 1.5990, val.acc = 0.4984\n",
      "Epoch 4, loss = 1.5610, val.loss = 1.5473, val.acc = 0.5112\n",
      "Epoch 5, loss = 1.5122, val.loss = 1.5058, val.acc = 0.5220\n",
      "Epoch 6, loss = 1.4721, val.loss = 1.4713, val.acc = 0.5318\n",
      "Epoch 7, loss = 1.4381, val.loss = 1.4418, val.acc = 0.5392\n",
      "Epoch 8, loss = 1.4086, val.loss = 1.4162, val.acc = 0.5440\n",
      "Epoch 9, loss = 1.3827, val.loss = 1.3937, val.acc = 0.5498\n",
      "Epoch 10, loss = 1.3596, val.loss = 1.3736, val.acc = 0.5578\n",
      "Epoch 11, loss = 1.3388, val.loss = 1.3555, val.acc = 0.5624\n",
      "Epoch 12, loss = 1.3199, val.loss = 1.3391, val.acc = 0.5674\n",
      "Epoch 13, loss = 1.3027, val.loss = 1.3242, val.acc = 0.5702\n",
      "Epoch 14, loss = 1.2868, val.loss = 1.3105, val.acc = 0.5746\n",
      "Epoch 15, loss = 1.2720, val.loss = 1.2979, val.acc = 0.5784\n",
      "Epoch 16, loss = 1.2584, val.loss = 1.2862, val.acc = 0.5828\n",
      "Epoch 17, loss = 1.2456, val.loss = 1.2754, val.acc = 0.5860\n",
      "Epoch 18, loss = 1.2336, val.loss = 1.2653, val.acc = 0.5890\n",
      "Epoch 19, loss = 1.2223, val.loss = 1.2559, val.acc = 0.5926\n",
      "Epoch 20, loss = 1.2117, val.loss = 1.2470, val.acc = 0.5966\n",
      "Epoch 21, loss = 1.2016, val.loss = 1.2387, val.acc = 0.5994\n",
      "Epoch 22, loss = 1.1921, val.loss = 1.2308, val.acc = 0.6024\n",
      "Epoch 23, loss = 1.1830, val.loss = 1.2234, val.acc = 0.6046\n",
      "Epoch 24, loss = 1.1744, val.loss = 1.2164, val.acc = 0.6048\n",
      "Epoch 25, loss = 1.1661, val.loss = 1.2098, val.acc = 0.6068\n",
      "Epoch 26, loss = 1.1582, val.loss = 1.2035, val.acc = 0.6090\n",
      "Epoch 27, loss = 1.1506, val.loss = 1.1975, val.acc = 0.6106\n",
      "Epoch 28, loss = 1.1433, val.loss = 1.1918, val.acc = 0.6118\n",
      "Epoch 29, loss = 1.1364, val.loss = 1.1864, val.acc = 0.6126\n",
      "Epoch 30, loss = 1.1296, val.loss = 1.1812, val.acc = 0.6148\n",
      "Epoch 31, loss = 1.1231, val.loss = 1.1762, val.acc = 0.6162\n",
      "Epoch 32, loss = 1.1168, val.loss = 1.1714, val.acc = 0.6172\n",
      "Epoch 33, loss = 1.1108, val.loss = 1.1669, val.acc = 0.6174\n",
      "Epoch 34, loss = 1.1049, val.loss = 1.1625, val.acc = 0.6182\n",
      "Epoch 35, loss = 1.0992, val.loss = 1.1583, val.acc = 0.6196\n",
      "Epoch 36, loss = 1.0937, val.loss = 1.1542, val.acc = 0.6200\n",
      "Epoch 37, loss = 1.0883, val.loss = 1.1503, val.acc = 0.6208\n",
      "Epoch 38, loss = 1.0831, val.loss = 1.1466, val.acc = 0.6220\n",
      "Epoch 39, loss = 1.0781, val.loss = 1.1430, val.acc = 0.6230\n",
      "Epoch 40, loss = 1.0731, val.loss = 1.1395, val.acc = 0.6234\n",
      "Epoch 41, loss = 1.0683, val.loss = 1.1361, val.acc = 0.6248\n",
      "Epoch 42, loss = 1.0637, val.loss = 1.1329, val.acc = 0.6256\n",
      "Epoch 43, loss = 1.0591, val.loss = 1.1298, val.acc = 0.6256\n",
      "Epoch 44, loss = 1.0546, val.loss = 1.1267, val.acc = 0.6268\n",
      "Epoch 45, loss = 1.0503, val.loss = 1.1238, val.acc = 0.6272\n",
      "Epoch 46, loss = 1.0460, val.loss = 1.1209, val.acc = 0.6272\n",
      "Epoch 47, loss = 1.0419, val.loss = 1.1182, val.acc = 0.6280\n",
      "Epoch 48, loss = 1.0378, val.loss = 1.1155, val.acc = 0.6290\n",
      "Epoch 49, loss = 1.0338, val.loss = 1.1129, val.acc = 0.6298\n",
      "Epoch 50, loss = 1.0299, val.loss = 1.1104, val.acc = 0.6304\n",
      "Epoch 51, loss = 1.0261, val.loss = 1.1080, val.acc = 0.6324\n",
      "Epoch 52, loss = 1.0223, val.loss = 1.1056, val.acc = 0.6334\n",
      "Epoch 53, loss = 1.0186, val.loss = 1.1033, val.acc = 0.6338\n",
      "Epoch 54, loss = 1.0150, val.loss = 1.1010, val.acc = 0.6342\n",
      "Epoch 55, loss = 1.0115, val.loss = 1.0989, val.acc = 0.6342\n",
      "Epoch 56, loss = 1.0080, val.loss = 1.0967, val.acc = 0.6346\n",
      "Epoch 57, loss = 1.0046, val.loss = 1.0947, val.acc = 0.6364\n",
      "Epoch 58, loss = 1.0012, val.loss = 1.0927, val.acc = 0.6374\n",
      "Epoch 59, loss = 0.9979, val.loss = 1.0907, val.acc = 0.6378\n",
      "Epoch 60, loss = 0.9946, val.loss = 1.0888, val.acc = 0.6388\n",
      "Epoch 61, loss = 0.9914, val.loss = 1.0869, val.acc = 0.6386\n",
      "Epoch 62, loss = 0.9883, val.loss = 1.0851, val.acc = 0.6398\n",
      "Epoch 63, loss = 0.9852, val.loss = 1.0833, val.acc = 0.6402\n",
      "Epoch 64, loss = 0.9821, val.loss = 1.0816, val.acc = 0.6408\n",
      "Epoch 65, loss = 0.9791, val.loss = 1.0799, val.acc = 0.6418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.9762, val.loss = 1.0783, val.acc = 0.6416\n",
      "Epoch 67, loss = 0.9733, val.loss = 1.0766, val.acc = 0.6430\n",
      "Epoch 68, loss = 0.9704, val.loss = 1.0751, val.acc = 0.6424\n",
      "Epoch 69, loss = 0.9675, val.loss = 1.0735, val.acc = 0.6426\n",
      "Epoch 70, loss = 0.9647, val.loss = 1.0720, val.acc = 0.6426\n",
      "Epoch 71, loss = 0.9620, val.loss = 1.0706, val.acc = 0.6430\n",
      "Epoch 72, loss = 0.9593, val.loss = 1.0691, val.acc = 0.6430\n",
      "Epoch 73, loss = 0.9566, val.loss = 1.0677, val.acc = 0.6434\n",
      "Epoch 74, loss = 0.9539, val.loss = 1.0663, val.acc = 0.6436\n",
      "Epoch 75, loss = 0.9513, val.loss = 1.0650, val.acc = 0.6444\n",
      "Epoch 76, loss = 0.9487, val.loss = 1.0637, val.acc = 0.6450\n",
      "Epoch 77, loss = 0.9462, val.loss = 1.0624, val.acc = 0.6454\n",
      "Epoch 78, loss = 0.9436, val.loss = 1.0611, val.acc = 0.6452\n",
      "Epoch 79, loss = 0.9411, val.loss = 1.0599, val.acc = 0.6454\n",
      "Epoch 80, loss = 0.9387, val.loss = 1.0587, val.acc = 0.6456\n",
      "Epoch 81, loss = 0.9363, val.loss = 1.0575, val.acc = 0.6460\n",
      "Epoch 82, loss = 0.9338, val.loss = 1.0563, val.acc = 0.6468\n",
      "Epoch 83, loss = 0.9315, val.loss = 1.0552, val.acc = 0.6468\n",
      "Epoch 84, loss = 0.9291, val.loss = 1.0541, val.acc = 0.6472\n",
      "Epoch 85, loss = 0.9268, val.loss = 1.0530, val.acc = 0.6468\n",
      "Epoch 86, loss = 0.9245, val.loss = 1.0519, val.acc = 0.6470\n",
      "Epoch 87, loss = 0.9222, val.loss = 1.0508, val.acc = 0.6474\n",
      "Epoch 88, loss = 0.9200, val.loss = 1.0498, val.acc = 0.6480\n",
      "Epoch 89, loss = 0.9177, val.loss = 1.0488, val.acc = 0.6486\n",
      "Epoch 90, loss = 0.9155, val.loss = 1.0478, val.acc = 0.6490\n",
      "Epoch 91, loss = 0.9133, val.loss = 1.0468, val.acc = 0.6486\n",
      "Epoch 92, loss = 0.9112, val.loss = 1.0459, val.acc = 0.6492\n",
      "Epoch 93, loss = 0.9090, val.loss = 1.0449, val.acc = 0.6494\n",
      "Epoch 94, loss = 0.9069, val.loss = 1.0440, val.acc = 0.6494\n",
      "Epoch 95, loss = 0.9048, val.loss = 1.0431, val.acc = 0.6500\n",
      "Epoch 96, loss = 0.9027, val.loss = 1.0422, val.acc = 0.6504\n",
      "Epoch 97, loss = 0.9007, val.loss = 1.0413, val.acc = 0.6504\n",
      "Epoch 98, loss = 0.8986, val.loss = 1.0405, val.acc = 0.6508\n",
      "Epoch 99, loss = 0.8966, val.loss = 1.0396, val.acc = 0.6514\n",
      "Epoch 100, loss = 0.8946, val.loss = 1.0388, val.acc = 0.6516\n",
      "Epoch 101, loss = 0.8926, val.loss = 1.0380, val.acc = 0.6518\n",
      "Epoch 102, loss = 0.8907, val.loss = 1.0372, val.acc = 0.6514\n",
      "Epoch 103, loss = 0.8887, val.loss = 1.0364, val.acc = 0.6514\n",
      "Epoch 104, loss = 0.8868, val.loss = 1.0356, val.acc = 0.6522\n",
      "Epoch 105, loss = 0.8849, val.loss = 1.0349, val.acc = 0.6524\n",
      "Epoch 106, loss = 0.8830, val.loss = 1.0341, val.acc = 0.6530\n",
      "Epoch 107, loss = 0.8811, val.loss = 1.0334, val.acc = 0.6532\n",
      "Epoch 108, loss = 0.8792, val.loss = 1.0327, val.acc = 0.6528\n",
      "Epoch 109, loss = 0.8774, val.loss = 1.0320, val.acc = 0.6530\n",
      "Epoch 110, loss = 0.8756, val.loss = 1.0313, val.acc = 0.6536\n",
      "Epoch 111, loss = 0.8737, val.loss = 1.0306, val.acc = 0.6538\n",
      "Epoch 112, loss = 0.8719, val.loss = 1.0299, val.acc = 0.6540\n",
      "Epoch 113, loss = 0.8702, val.loss = 1.0293, val.acc = 0.6538\n",
      "Epoch 114, loss = 0.8684, val.loss = 1.0286, val.acc = 0.6540\n",
      "Epoch 115, loss = 0.8666, val.loss = 1.0280, val.acc = 0.6546\n",
      "Epoch 116, loss = 0.8649, val.loss = 1.0273, val.acc = 0.6550\n",
      "Epoch 117, loss = 0.8631, val.loss = 1.0267, val.acc = 0.6552\n",
      "Epoch 118, loss = 0.8614, val.loss = 1.0261, val.acc = 0.6552\n",
      "Epoch 119, loss = 0.8597, val.loss = 1.0255, val.acc = 0.6558\n",
      "Epoch 120, loss = 0.8580, val.loss = 1.0249, val.acc = 0.6560\n",
      "Epoch 121, loss = 0.8563, val.loss = 1.0243, val.acc = 0.6562\n",
      "Epoch 122, loss = 0.8547, val.loss = 1.0238, val.acc = 0.6562\n",
      "Epoch 123, loss = 0.8530, val.loss = 1.0232, val.acc = 0.6568\n",
      "Epoch 124, loss = 0.8514, val.loss = 1.0227, val.acc = 0.6574\n",
      "Epoch 125, loss = 0.8497, val.loss = 1.0221, val.acc = 0.6576\n",
      "Epoch 126, loss = 0.8481, val.loss = 1.0216, val.acc = 0.6580\n",
      "Epoch 127, loss = 0.8465, val.loss = 1.0211, val.acc = 0.6580\n",
      "Epoch 128, loss = 0.8449, val.loss = 1.0205, val.acc = 0.6576\n",
      "Epoch 129, loss = 0.8433, val.loss = 1.0200, val.acc = 0.6574\n",
      "Epoch 130, loss = 0.8418, val.loss = 1.0195, val.acc = 0.6580\n",
      "Epoch 131, loss = 0.8402, val.loss = 1.0190, val.acc = 0.6582\n",
      "Epoch 132, loss = 0.8386, val.loss = 1.0185, val.acc = 0.6586\n",
      "Epoch 133, loss = 0.8371, val.loss = 1.0181, val.acc = 0.6586\n",
      "Epoch 134, loss = 0.8356, val.loss = 1.0176, val.acc = 0.6592\n",
      "Epoch 135, loss = 0.8340, val.loss = 1.0171, val.acc = 0.6600\n",
      "Epoch 136, loss = 0.8325, val.loss = 1.0167, val.acc = 0.6600\n",
      "Epoch 137, loss = 0.8310, val.loss = 1.0162, val.acc = 0.6600\n",
      "Epoch 138, loss = 0.8295, val.loss = 1.0158, val.acc = 0.6602\n",
      "Epoch 139, loss = 0.8281, val.loss = 1.0154, val.acc = 0.6604\n",
      "Epoch 140, loss = 0.8266, val.loss = 1.0149, val.acc = 0.6606\n",
      "Epoch 141, loss = 0.8251, val.loss = 1.0145, val.acc = 0.6606\n",
      "Epoch 142, loss = 0.8237, val.loss = 1.0141, val.acc = 0.6608\n",
      "Epoch 143, loss = 0.8222, val.loss = 1.0137, val.acc = 0.6606\n",
      "Epoch 144, loss = 0.8208, val.loss = 1.0133, val.acc = 0.6604\n",
      "Epoch 145, loss = 0.8194, val.loss = 1.0129, val.acc = 0.6602\n",
      "Epoch 146, loss = 0.8179, val.loss = 1.0125, val.acc = 0.6606\n",
      "Epoch 147, loss = 0.8165, val.loss = 1.0121, val.acc = 0.6612\n",
      "Epoch 148, loss = 0.8151, val.loss = 1.0117, val.acc = 0.6614\n",
      "Epoch 149, loss = 0.8137, val.loss = 1.0114, val.acc = 0.6618\n",
      "Rep: 1, te.acc = 0.6477\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6477]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 20\n",
    "vis = visdom.Visdom(port=8097,env='ae'+str(pars.decoder_channel)+'_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T17:35:18.175769Z",
     "start_time": "2022-04-02T17:03:15.393357Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_16/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_50_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=16384, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(16, 32, 32))\n",
      "    (deconv): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 2.7784, time: 17.3199\n",
      "reconstruction loss = 0.0438, similarity loss: 0.5883\n",
      "Epoch 1, loss = 1.9459, time: 17.0869\n",
      "reconstruction loss = 0.0275, similarity loss: 0.5717\n",
      "Epoch 2, loss = 1.5912, time: 17.0889\n",
      "reconstruction loss = 0.0200, similarity loss: 0.5932\n",
      "Epoch 3, loss = 1.4515, time: 16.6428\n",
      "reconstruction loss = 0.0166, similarity loss: 0.6235\n",
      "Epoch 4, loss = 1.3100, time: 16.5596\n",
      "reconstruction loss = 0.0147, similarity loss: 0.5763\n",
      "Epoch 5, loss = 1.3187, time: 16.5280\n",
      "reconstruction loss = 0.0134, similarity loss: 0.6468\n",
      "Epoch 6, loss = 1.3209, time: 16.4331\n",
      "reconstruction loss = 0.0133, similarity loss: 0.6549\n",
      "Epoch 7, loss = 1.1445, time: 16.5396\n",
      "reconstruction loss = 0.0124, similarity loss: 0.5235\n",
      "Epoch 8, loss = 1.2298, time: 16.5215\n",
      "reconstruction loss = 0.0136, similarity loss: 0.5516\n",
      "Epoch 9, loss = 1.1324, time: 16.6808\n",
      "reconstruction loss = 0.0116, similarity loss: 0.5535\n",
      "Epoch 10, loss = 1.0167, time: 16.4808\n",
      "reconstruction loss = 0.0108, similarity loss: 0.4771\n",
      "Epoch 11, loss = 1.0608, time: 16.4717\n",
      "reconstruction loss = 0.0111, similarity loss: 0.5082\n",
      "Epoch 12, loss = 1.1481, time: 16.5300\n",
      "reconstruction loss = 0.0121, similarity loss: 0.5415\n",
      "Epoch 13, loss = 1.1127, time: 16.5596\n",
      "reconstruction loss = 0.0126, similarity loss: 0.4811\n",
      "Epoch 14, loss = 0.9960, time: 16.4675\n",
      "reconstruction loss = 0.0110, similarity loss: 0.4484\n",
      "Epoch 15, loss = 0.9828, time: 16.5522\n",
      "reconstruction loss = 0.0112, similarity loss: 0.4209\n",
      "Epoch 16, loss = 1.0261, time: 16.5305\n",
      "reconstruction loss = 0.0114, similarity loss: 0.4580\n",
      "Epoch 17, loss = 0.9846, time: 16.5707\n",
      "reconstruction loss = 0.0108, similarity loss: 0.4452\n",
      "Epoch 18, loss = 1.0356, time: 16.5259\n",
      "reconstruction loss = 0.0113, similarity loss: 0.4708\n",
      "Epoch 19, loss = 0.8571, time: 16.5722\n",
      "reconstruction loss = 0.0093, similarity loss: 0.3898\n",
      "Epoch 20, loss = 0.9348, time: 16.5218\n",
      "reconstruction loss = 0.0108, similarity loss: 0.3931\n",
      "Epoch 21, loss = 0.9053, time: 16.5871\n",
      "reconstruction loss = 0.0103, similarity loss: 0.3881\n",
      "Epoch 22, loss = 0.9351, time: 16.5218\n",
      "reconstruction loss = 0.0108, similarity loss: 0.3955\n",
      "Epoch 23, loss = 0.8593, time: 16.5183\n",
      "reconstruction loss = 0.0090, similarity loss: 0.4070\n",
      "Epoch 24, loss = 0.8554, time: 16.5337\n",
      "reconstruction loss = 0.0096, similarity loss: 0.3746\n",
      "Epoch 25, loss = 0.7870, time: 16.6381\n",
      "reconstruction loss = 0.0082, similarity loss: 0.3786\n",
      "Epoch 26, loss = 0.7878, time: 16.5955\n",
      "reconstruction loss = 0.0093, similarity loss: 0.3218\n",
      "Epoch 27, loss = 0.7888, time: 16.5346\n",
      "reconstruction loss = 0.0088, similarity loss: 0.3494\n",
      "Epoch 28, loss = 0.9030, time: 16.4099\n",
      "reconstruction loss = 0.0103, similarity loss: 0.3858\n",
      "Epoch 29, loss = 0.7670, time: 16.3916\n",
      "reconstruction loss = 0.0078, similarity loss: 0.3752\n",
      "Epoch 30, loss = 0.7356, time: 16.5353\n",
      "reconstruction loss = 0.0077, similarity loss: 0.3528\n",
      "Epoch 31, loss = 0.7902, time: 16.5210\n",
      "reconstruction loss = 0.0079, similarity loss: 0.3958\n",
      "Epoch 32, loss = 0.8136, time: 16.6188\n",
      "reconstruction loss = 0.0083, similarity loss: 0.3978\n",
      "Epoch 33, loss = 0.7726, time: 16.5687\n",
      "reconstruction loss = 0.0077, similarity loss: 0.3886\n",
      "Epoch 34, loss = 0.7073, time: 16.4518\n",
      "reconstruction loss = 0.0076, similarity loss: 0.3249\n",
      "Epoch 35, loss = 0.7131, time: 16.5393\n",
      "reconstruction loss = 0.0075, similarity loss: 0.3383\n",
      "Epoch 36, loss = 0.6997, time: 16.5306\n",
      "reconstruction loss = 0.0075, similarity loss: 0.3265\n",
      "Epoch 37, loss = 0.6739, time: 16.4672\n",
      "reconstruction loss = 0.0072, similarity loss: 0.3134\n",
      "Epoch 38, loss = 0.7899, time: 16.4415\n",
      "reconstruction loss = 0.0087, similarity loss: 0.3567\n",
      "Epoch 39, loss = 0.7193, time: 16.6349\n",
      "reconstruction loss = 0.0076, similarity loss: 0.3399\n",
      "Epoch 40, loss = 0.7392, time: 16.5137\n",
      "reconstruction loss = 0.0075, similarity loss: 0.3637\n",
      "Epoch 41, loss = 0.6856, time: 16.5824\n",
      "reconstruction loss = 0.0075, similarity loss: 0.3105\n",
      "Epoch 42, loss = 0.8561, time: 16.5676\n",
      "reconstruction loss = 0.0089, similarity loss: 0.4091\n",
      "Epoch 43, loss = 0.6869, time: 16.5277\n",
      "reconstruction loss = 0.0077, similarity loss: 0.3007\n",
      "Epoch 44, loss = 0.7494, time: 16.5632\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3814\n",
      "Epoch 45, loss = 0.7236, time: 16.5040\n",
      "reconstruction loss = 0.0075, similarity loss: 0.3473\n",
      "Epoch 46, loss = 0.7029, time: 16.4775\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3462\n",
      "Epoch 47, loss = 0.7073, time: 16.4831\n",
      "reconstruction loss = 0.0072, similarity loss: 0.3492\n",
      "Epoch 48, loss = 0.6842, time: 16.4754\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3269\n",
      "Epoch 49, loss = 0.6789, time: 16.5233\n",
      "reconstruction loss = 0.0075, similarity loss: 0.3036\n",
      "Epoch 50, loss = 0.6866, time: 16.4756\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3316\n",
      "Epoch 51, loss = 0.6417, time: 16.4328\n",
      "reconstruction loss = 0.0069, similarity loss: 0.2976\n",
      "Epoch 52, loss = 0.6781, time: 16.6438\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3249\n",
      "Epoch 53, loss = 0.6139, time: 16.4150\n",
      "reconstruction loss = 0.0060, similarity loss: 0.3148\n",
      "Epoch 54, loss = 0.6470, time: 16.4540\n",
      "reconstruction loss = 0.0070, similarity loss: 0.2949\n",
      "Epoch 55, loss = 0.6964, time: 16.4570\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3434\n",
      "Epoch 56, loss = 0.8492, time: 16.5256\n",
      "reconstruction loss = 0.0087, similarity loss: 0.4143\n",
      "Epoch 57, loss = 0.6919, time: 16.5290\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3377\n",
      "Epoch 58, loss = 0.6338, time: 16.4777\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3134\n",
      "Epoch 59, loss = 0.6903, time: 16.4768\n",
      "reconstruction loss = 0.0068, similarity loss: 0.3526\n",
      "Epoch 60, loss = 0.6450, time: 16.5522\n",
      "reconstruction loss = 0.0067, similarity loss: 0.3089\n",
      "Epoch 61, loss = 0.6682, time: 16.5564\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3504\n",
      "Epoch 62, loss = 0.6253, time: 16.5220\n",
      "reconstruction loss = 0.0062, similarity loss: 0.3155\n",
      "Epoch 63, loss = 0.6568, time: 16.5425\n",
      "reconstruction loss = 0.0068, similarity loss: 0.3147\n",
      "Epoch 64, loss = 0.6053, time: 16.4292\n",
      "reconstruction loss = 0.0059, similarity loss: 0.3079\n",
      "Epoch 65, loss = 0.6469, time: 16.5502\n",
      "reconstruction loss = 0.0069, similarity loss: 0.3030\n",
      "Epoch 66, loss = 0.6316, time: 16.3388\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3112\n",
      "Epoch 67, loss = 0.7180, time: 16.4808\n",
      "reconstruction loss = 0.0075, similarity loss: 0.3422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.6216, time: 16.5008\n",
      "reconstruction loss = 0.0060, similarity loss: 0.3216\n",
      "Epoch 69, loss = 0.5757, time: 16.4161\n",
      "reconstruction loss = 0.0062, similarity loss: 0.2671\n",
      "Epoch 70, loss = 0.7074, time: 16.4893\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3382\n",
      "Epoch 71, loss = 0.6784, time: 16.4552\n",
      "reconstruction loss = 0.0073, similarity loss: 0.3133\n",
      "Epoch 72, loss = 0.6439, time: 16.5348\n",
      "reconstruction loss = 0.0059, similarity loss: 0.3512\n",
      "Epoch 73, loss = 0.8039, time: 16.5858\n",
      "reconstruction loss = 0.0086, similarity loss: 0.3746\n",
      "Epoch 74, loss = 0.5639, time: 16.5539\n",
      "reconstruction loss = 0.0057, similarity loss: 0.2804\n",
      "Epoch 75, loss = 0.6065, time: 16.6275\n",
      "reconstruction loss = 0.0056, similarity loss: 0.3246\n",
      "Epoch 76, loss = 0.5656, time: 17.0201\n",
      "reconstruction loss = 0.0061, similarity loss: 0.2599\n",
      "Epoch 77, loss = 0.6154, time: 17.0420\n",
      "reconstruction loss = 0.0059, similarity loss: 0.3226\n",
      "Epoch 78, loss = 0.6142, time: 16.9850\n",
      "reconstruction loss = 0.0061, similarity loss: 0.3085\n",
      "Epoch 79, loss = 0.6402, time: 16.9735\n",
      "reconstruction loss = 0.0065, similarity loss: 0.3164\n",
      "Epoch 80, loss = 0.6061, time: 16.9629\n",
      "reconstruction loss = 0.0057, similarity loss: 0.3195\n",
      "Epoch 81, loss = 0.5921, time: 17.2073\n",
      "reconstruction loss = 0.0058, similarity loss: 0.3020\n",
      "Epoch 82, loss = 0.6769, time: 17.0932\n",
      "reconstruction loss = 0.0065, similarity loss: 0.3542\n",
      "Epoch 83, loss = 0.5804, time: 16.9562\n",
      "reconstruction loss = 0.0059, similarity loss: 0.2843\n",
      "Epoch 84, loss = 0.5791, time: 17.0328\n",
      "reconstruction loss = 0.0063, similarity loss: 0.2640\n",
      "Epoch 85, loss = 0.6063, time: 17.0952\n",
      "reconstruction loss = 0.0060, similarity loss: 0.3055\n",
      "Epoch 86, loss = 0.6765, time: 17.1701\n",
      "reconstruction loss = 0.0070, similarity loss: 0.3269\n",
      "Epoch 87, loss = 0.6237, time: 17.0547\n",
      "reconstruction loss = 0.0060, similarity loss: 0.3213\n",
      "Epoch 88, loss = 0.6091, time: 16.9723\n",
      "reconstruction loss = 0.0061, similarity loss: 0.3018\n",
      "Epoch 89, loss = 0.7253, time: 17.1249\n",
      "reconstruction loss = 0.0070, similarity loss: 0.3745\n",
      "Epoch 90, loss = 0.5948, time: 17.0479\n",
      "reconstruction loss = 0.0061, similarity loss: 0.2885\n",
      "Epoch 91, loss = 0.5864, time: 16.9614\n",
      "reconstruction loss = 0.0060, similarity loss: 0.2848\n",
      "Epoch 92, loss = 0.6328, time: 16.9473\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3118\n",
      "Epoch 93, loss = 0.5543, time: 17.0977\n",
      "reconstruction loss = 0.0052, similarity loss: 0.2930\n",
      "Epoch 94, loss = 0.5473, time: 17.0128\n",
      "reconstruction loss = 0.0054, similarity loss: 0.2762\n",
      "Epoch 95, loss = 0.6058, time: 17.0481\n",
      "reconstruction loss = 0.0059, similarity loss: 0.3092\n",
      "Epoch 96, loss = 0.5768, time: 16.9917\n",
      "reconstruction loss = 0.0056, similarity loss: 0.2967\n",
      "Epoch 97, loss = 0.5786, time: 17.0620\n",
      "reconstruction loss = 0.0053, similarity loss: 0.3145\n",
      "Epoch 98, loss = 0.5169, time: 16.9623\n",
      "reconstruction loss = 0.0054, similarity loss: 0.2455\n",
      "Epoch 99, loss = 0.6834, time: 17.0636\n",
      "reconstruction loss = 0.0073, similarity loss: 0.3185\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 2.1274, val.loss = 1.9845, val.acc = 0.3950\n",
      "Epoch 1, loss = 1.9010, val.loss = 1.8258, val.acc = 0.4298\n",
      "Epoch 2, loss = 1.7765, val.loss = 1.7305, val.acc = 0.4520\n",
      "Epoch 3, loss = 1.6953, val.loss = 1.6644, val.acc = 0.4684\n",
      "Epoch 4, loss = 1.6358, val.loss = 1.6140, val.acc = 0.4820\n",
      "Epoch 5, loss = 1.5887, val.loss = 1.5732, val.acc = 0.4948\n",
      "Epoch 6, loss = 1.5497, val.loss = 1.5390, val.acc = 0.5054\n",
      "Epoch 7, loss = 1.5164, val.loss = 1.5095, val.acc = 0.5154\n",
      "Epoch 8, loss = 1.4873, val.loss = 1.4837, val.acc = 0.5208\n",
      "Epoch 9, loss = 1.4616, val.loss = 1.4607, val.acc = 0.5302\n",
      "Epoch 10, loss = 1.4385, val.loss = 1.4401, val.acc = 0.5336\n",
      "Epoch 11, loss = 1.4177, val.loss = 1.4215, val.acc = 0.5390\n",
      "Epoch 12, loss = 1.3986, val.loss = 1.4045, val.acc = 0.5432\n",
      "Epoch 13, loss = 1.3811, val.loss = 1.3889, val.acc = 0.5494\n",
      "Epoch 14, loss = 1.3650, val.loss = 1.3745, val.acc = 0.5560\n",
      "Epoch 15, loss = 1.3500, val.loss = 1.3612, val.acc = 0.5618\n",
      "Epoch 16, loss = 1.3360, val.loss = 1.3488, val.acc = 0.5652\n",
      "Epoch 17, loss = 1.3229, val.loss = 1.3372, val.acc = 0.5702\n",
      "Epoch 18, loss = 1.3106, val.loss = 1.3264, val.acc = 0.5722\n",
      "Epoch 19, loss = 1.2990, val.loss = 1.3163, val.acc = 0.5748\n",
      "Epoch 20, loss = 1.2881, val.loss = 1.3067, val.acc = 0.5776\n",
      "Epoch 21, loss = 1.2777, val.loss = 1.2977, val.acc = 0.5800\n",
      "Epoch 22, loss = 1.2679, val.loss = 1.2891, val.acc = 0.5834\n",
      "Epoch 23, loss = 1.2585, val.loss = 1.2811, val.acc = 0.5848\n",
      "Epoch 24, loss = 1.2495, val.loss = 1.2734, val.acc = 0.5874\n",
      "Epoch 25, loss = 1.2410, val.loss = 1.2661, val.acc = 0.5884\n",
      "Epoch 26, loss = 1.2328, val.loss = 1.2591, val.acc = 0.5902\n",
      "Epoch 27, loss = 1.2250, val.loss = 1.2524, val.acc = 0.5924\n",
      "Epoch 28, loss = 1.2175, val.loss = 1.2461, val.acc = 0.5948\n",
      "Epoch 29, loss = 1.2102, val.loss = 1.2400, val.acc = 0.5962\n",
      "Epoch 30, loss = 1.2032, val.loss = 1.2342, val.acc = 0.5978\n",
      "Epoch 31, loss = 1.1965, val.loss = 1.2286, val.acc = 0.5980\n",
      "Epoch 32, loss = 1.1900, val.loss = 1.2232, val.acc = 0.5990\n",
      "Epoch 33, loss = 1.1838, val.loss = 1.2180, val.acc = 0.5998\n",
      "Epoch 34, loss = 1.1777, val.loss = 1.2131, val.acc = 0.5994\n",
      "Epoch 35, loss = 1.1718, val.loss = 1.2083, val.acc = 0.6022\n",
      "Epoch 36, loss = 1.1662, val.loss = 1.2037, val.acc = 0.6028\n",
      "Epoch 37, loss = 1.1606, val.loss = 1.1992, val.acc = 0.6032\n",
      "Epoch 38, loss = 1.1553, val.loss = 1.1949, val.acc = 0.6040\n",
      "Epoch 39, loss = 1.1501, val.loss = 1.1907, val.acc = 0.6048\n",
      "Epoch 40, loss = 1.1450, val.loss = 1.1867, val.acc = 0.6054\n",
      "Epoch 41, loss = 1.1401, val.loss = 1.1828, val.acc = 0.6072\n",
      "Epoch 42, loss = 1.1353, val.loss = 1.1791, val.acc = 0.6080\n",
      "Epoch 43, loss = 1.1306, val.loss = 1.1754, val.acc = 0.6094\n",
      "Epoch 44, loss = 1.1261, val.loss = 1.1718, val.acc = 0.6098\n",
      "Epoch 45, loss = 1.1216, val.loss = 1.1684, val.acc = 0.6098\n",
      "Epoch 46, loss = 1.1173, val.loss = 1.1651, val.acc = 0.6106\n",
      "Epoch 47, loss = 1.1130, val.loss = 1.1618, val.acc = 0.6124\n",
      "Epoch 48, loss = 1.1089, val.loss = 1.1587, val.acc = 0.6130\n",
      "Epoch 49, loss = 1.1048, val.loss = 1.1556, val.acc = 0.6142\n",
      "Epoch 50, loss = 1.1009, val.loss = 1.1526, val.acc = 0.6144\n",
      "Epoch 51, loss = 1.0970, val.loss = 1.1497, val.acc = 0.6144\n",
      "Epoch 52, loss = 1.0932, val.loss = 1.1469, val.acc = 0.6156\n",
      "Epoch 53, loss = 1.0895, val.loss = 1.1441, val.acc = 0.6168\n",
      "Epoch 54, loss = 1.0858, val.loss = 1.1414, val.acc = 0.6182\n",
      "Epoch 55, loss = 1.0822, val.loss = 1.1388, val.acc = 0.6188\n",
      "Epoch 56, loss = 1.0787, val.loss = 1.1362, val.acc = 0.6198\n",
      "Epoch 57, loss = 1.0753, val.loss = 1.1337, val.acc = 0.6210\n",
      "Epoch 58, loss = 1.0719, val.loss = 1.1313, val.acc = 0.6218\n",
      "Epoch 59, loss = 1.0686, val.loss = 1.1289, val.acc = 0.6230\n",
      "Epoch 60, loss = 1.0653, val.loss = 1.1266, val.acc = 0.6248\n",
      "Epoch 61, loss = 1.0621, val.loss = 1.1243, val.acc = 0.6260\n",
      "Epoch 62, loss = 1.0590, val.loss = 1.1221, val.acc = 0.6276\n",
      "Epoch 63, loss = 1.0559, val.loss = 1.1199, val.acc = 0.6286\n",
      "Epoch 64, loss = 1.0528, val.loss = 1.1178, val.acc = 0.6300\n",
      "Epoch 65, loss = 1.0498, val.loss = 1.1157, val.acc = 0.6310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 1.0469, val.loss = 1.1137, val.acc = 0.6322\n",
      "Epoch 67, loss = 1.0440, val.loss = 1.1117, val.acc = 0.6328\n",
      "Epoch 68, loss = 1.0411, val.loss = 1.1098, val.acc = 0.6336\n",
      "Epoch 69, loss = 1.0383, val.loss = 1.1079, val.acc = 0.6348\n",
      "Epoch 70, loss = 1.0355, val.loss = 1.1060, val.acc = 0.6346\n",
      "Epoch 71, loss = 1.0328, val.loss = 1.1042, val.acc = 0.6348\n",
      "Epoch 72, loss = 1.0301, val.loss = 1.1024, val.acc = 0.6360\n",
      "Epoch 73, loss = 1.0274, val.loss = 1.1006, val.acc = 0.6358\n",
      "Epoch 74, loss = 1.0248, val.loss = 1.0989, val.acc = 0.6362\n",
      "Epoch 75, loss = 1.0222, val.loss = 1.0972, val.acc = 0.6366\n",
      "Epoch 76, loss = 1.0197, val.loss = 1.0955, val.acc = 0.6368\n",
      "Epoch 77, loss = 1.0171, val.loss = 1.0939, val.acc = 0.6374\n",
      "Epoch 78, loss = 1.0147, val.loss = 1.0923, val.acc = 0.6378\n",
      "Epoch 79, loss = 1.0122, val.loss = 1.0907, val.acc = 0.6384\n",
      "Epoch 80, loss = 1.0098, val.loss = 1.0892, val.acc = 0.6386\n",
      "Epoch 81, loss = 1.0074, val.loss = 1.0877, val.acc = 0.6398\n",
      "Epoch 82, loss = 1.0050, val.loss = 1.0862, val.acc = 0.6400\n",
      "Epoch 83, loss = 1.0027, val.loss = 1.0847, val.acc = 0.6402\n",
      "Epoch 84, loss = 1.0004, val.loss = 1.0833, val.acc = 0.6408\n",
      "Epoch 85, loss = 0.9981, val.loss = 1.0819, val.acc = 0.6408\n",
      "Epoch 86, loss = 0.9959, val.loss = 1.0805, val.acc = 0.6420\n",
      "Epoch 87, loss = 0.9937, val.loss = 1.0791, val.acc = 0.6424\n",
      "Epoch 88, loss = 0.9915, val.loss = 1.0778, val.acc = 0.6426\n",
      "Epoch 89, loss = 0.9893, val.loss = 1.0765, val.acc = 0.6434\n",
      "Epoch 90, loss = 0.9871, val.loss = 1.0752, val.acc = 0.6444\n",
      "Epoch 91, loss = 0.9850, val.loss = 1.0739, val.acc = 0.6450\n",
      "Epoch 92, loss = 0.9829, val.loss = 1.0726, val.acc = 0.6468\n",
      "Epoch 93, loss = 0.9808, val.loss = 1.0714, val.acc = 0.6472\n",
      "Epoch 94, loss = 0.9788, val.loss = 1.0702, val.acc = 0.6476\n",
      "Epoch 95, loss = 0.9767, val.loss = 1.0690, val.acc = 0.6486\n",
      "Epoch 96, loss = 0.9747, val.loss = 1.0678, val.acc = 0.6492\n",
      "Epoch 97, loss = 0.9727, val.loss = 1.0666, val.acc = 0.6498\n",
      "Epoch 98, loss = 0.9708, val.loss = 1.0655, val.acc = 0.6496\n",
      "Epoch 99, loss = 0.9688, val.loss = 1.0644, val.acc = 0.6494\n",
      "Epoch 100, loss = 0.9669, val.loss = 1.0633, val.acc = 0.6500\n",
      "Epoch 101, loss = 0.9649, val.loss = 1.0622, val.acc = 0.6498\n",
      "Epoch 102, loss = 0.9630, val.loss = 1.0611, val.acc = 0.6504\n",
      "Epoch 103, loss = 0.9612, val.loss = 1.0600, val.acc = 0.6504\n",
      "Epoch 104, loss = 0.9593, val.loss = 1.0590, val.acc = 0.6504\n",
      "Epoch 105, loss = 0.9575, val.loss = 1.0579, val.acc = 0.6504\n",
      "Epoch 106, loss = 0.9556, val.loss = 1.0569, val.acc = 0.6504\n",
      "Epoch 107, loss = 0.9538, val.loss = 1.0559, val.acc = 0.6510\n",
      "Epoch 108, loss = 0.9520, val.loss = 1.0549, val.acc = 0.6504\n",
      "Epoch 109, loss = 0.9502, val.loss = 1.0540, val.acc = 0.6510\n",
      "Epoch 110, loss = 0.9485, val.loss = 1.0530, val.acc = 0.6514\n",
      "Epoch 111, loss = 0.9467, val.loss = 1.0521, val.acc = 0.6518\n",
      "Epoch 112, loss = 0.9450, val.loss = 1.0511, val.acc = 0.6518\n",
      "Epoch 113, loss = 0.9433, val.loss = 1.0502, val.acc = 0.6524\n",
      "Epoch 114, loss = 0.9416, val.loss = 1.0493, val.acc = 0.6530\n",
      "Epoch 115, loss = 0.9399, val.loss = 1.0484, val.acc = 0.6530\n",
      "Epoch 116, loss = 0.9382, val.loss = 1.0475, val.acc = 0.6538\n",
      "Epoch 117, loss = 0.9365, val.loss = 1.0467, val.acc = 0.6542\n",
      "Epoch 118, loss = 0.9349, val.loss = 1.0458, val.acc = 0.6546\n",
      "Epoch 119, loss = 0.9332, val.loss = 1.0449, val.acc = 0.6552\n",
      "Epoch 120, loss = 0.9316, val.loss = 1.0441, val.acc = 0.6556\n",
      "Epoch 121, loss = 0.9300, val.loss = 1.0433, val.acc = 0.6558\n",
      "Epoch 122, loss = 0.9284, val.loss = 1.0425, val.acc = 0.6560\n",
      "Epoch 123, loss = 0.9268, val.loss = 1.0417, val.acc = 0.6558\n",
      "Epoch 124, loss = 0.9252, val.loss = 1.0409, val.acc = 0.6564\n",
      "Epoch 125, loss = 0.9237, val.loss = 1.0401, val.acc = 0.6568\n",
      "Epoch 126, loss = 0.9221, val.loss = 1.0393, val.acc = 0.6572\n",
      "Epoch 127, loss = 0.9206, val.loss = 1.0385, val.acc = 0.6572\n",
      "Epoch 128, loss = 0.9191, val.loss = 1.0378, val.acc = 0.6576\n",
      "Epoch 129, loss = 0.9175, val.loss = 1.0370, val.acc = 0.6580\n",
      "Epoch 130, loss = 0.9160, val.loss = 1.0363, val.acc = 0.6584\n",
      "Epoch 131, loss = 0.9145, val.loss = 1.0356, val.acc = 0.6588\n",
      "Epoch 132, loss = 0.9131, val.loss = 1.0348, val.acc = 0.6582\n",
      "Epoch 133, loss = 0.9116, val.loss = 1.0341, val.acc = 0.6586\n",
      "Epoch 134, loss = 0.9101, val.loss = 1.0334, val.acc = 0.6582\n",
      "Epoch 135, loss = 0.9087, val.loss = 1.0327, val.acc = 0.6582\n",
      "Epoch 136, loss = 0.9072, val.loss = 1.0320, val.acc = 0.6586\n",
      "Epoch 137, loss = 0.9058, val.loss = 1.0314, val.acc = 0.6590\n",
      "Epoch 138, loss = 0.9044, val.loss = 1.0307, val.acc = 0.6592\n",
      "Epoch 139, loss = 0.9030, val.loss = 1.0300, val.acc = 0.6586\n",
      "Epoch 140, loss = 0.9016, val.loss = 1.0294, val.acc = 0.6592\n",
      "Epoch 141, loss = 0.9002, val.loss = 1.0287, val.acc = 0.6590\n",
      "Epoch 142, loss = 0.8988, val.loss = 1.0281, val.acc = 0.6590\n",
      "Epoch 143, loss = 0.8974, val.loss = 1.0275, val.acc = 0.6590\n",
      "Epoch 144, loss = 0.8960, val.loss = 1.0268, val.acc = 0.6590\n",
      "Epoch 145, loss = 0.8947, val.loss = 1.0262, val.acc = 0.6590\n",
      "Epoch 146, loss = 0.8933, val.loss = 1.0256, val.acc = 0.6594\n",
      "Epoch 147, loss = 0.8920, val.loss = 1.0250, val.acc = 0.6598\n",
      "Epoch 148, loss = 0.8906, val.loss = 1.0244, val.acc = 0.6598\n",
      "Epoch 149, loss = 0.8893, val.loss = 1.0238, val.acc = 0.6598\n",
      "Rep: 1, te.acc = 0.6397\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6397]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 50\n",
    "vis = visdom.Visdom(port=8097,env='ae'+str(pars.decoder_channel)+'_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T18:07:54.101856Z",
     "start_time": "2022-04-02T17:35:18.176770Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_16/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_100_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=16384, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(16, 32, 32))\n",
      "    (deconv): ConvTranspose2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 4.8601, time: 17.2689\n",
      "reconstruction loss = 0.0423, similarity loss: 0.6291\n",
      "Epoch 1, loss = 3.1134, time: 16.9858\n",
      "reconstruction loss = 0.0235, similarity loss: 0.7653\n",
      "Epoch 2, loss = 2.2598, time: 17.0969\n",
      "reconstruction loss = 0.0167, similarity loss: 0.5895\n",
      "Epoch 3, loss = 2.1707, time: 17.1519\n",
      "reconstruction loss = 0.0156, similarity loss: 0.6124\n",
      "Epoch 4, loss = 1.8946, time: 17.0769\n",
      "reconstruction loss = 0.0130, similarity loss: 0.5987\n",
      "Epoch 5, loss = 1.8550, time: 16.9633\n",
      "reconstruction loss = 0.0122, similarity loss: 0.6308\n",
      "Epoch 6, loss = 1.5009, time: 16.9738\n",
      "reconstruction loss = 0.0104, similarity loss: 0.4654\n",
      "Epoch 7, loss = 1.5839, time: 16.9439\n",
      "reconstruction loss = 0.0102, similarity loss: 0.5664\n",
      "Epoch 8, loss = 1.6087, time: 17.0120\n",
      "reconstruction loss = 0.0096, similarity loss: 0.6453\n",
      "Epoch 9, loss = 1.5010, time: 16.9158\n",
      "reconstruction loss = 0.0093, similarity loss: 0.5757\n",
      "Epoch 10, loss = 1.4909, time: 17.0257\n",
      "reconstruction loss = 0.0091, similarity loss: 0.5785\n",
      "Epoch 11, loss = 1.3529, time: 16.9731\n",
      "reconstruction loss = 0.0081, similarity loss: 0.5436\n",
      "Epoch 12, loss = 1.5239, time: 17.3178\n",
      "reconstruction loss = 0.0089, similarity loss: 0.6309\n",
      "Epoch 13, loss = 1.5187, time: 17.3350\n",
      "reconstruction loss = 0.0087, similarity loss: 0.6466\n",
      "Epoch 14, loss = 1.4426, time: 17.1299\n",
      "reconstruction loss = 0.0086, similarity loss: 0.5782\n",
      "Epoch 15, loss = 1.2741, time: 17.0439\n",
      "reconstruction loss = 0.0084, similarity loss: 0.4390\n",
      "Epoch 16, loss = 1.2837, time: 17.2374\n",
      "reconstruction loss = 0.0076, similarity loss: 0.5232\n",
      "Epoch 17, loss = 1.1611, time: 17.1246\n",
      "reconstruction loss = 0.0067, similarity loss: 0.4889\n",
      "Epoch 18, loss = 1.5365, time: 17.0759\n",
      "reconstruction loss = 0.0092, similarity loss: 0.6116\n",
      "Epoch 19, loss = 1.3523, time: 17.1782\n",
      "reconstruction loss = 0.0074, similarity loss: 0.6100\n",
      "Epoch 20, loss = 1.1497, time: 17.0249\n",
      "reconstruction loss = 0.0068, similarity loss: 0.4746\n",
      "Epoch 21, loss = 1.1794, time: 17.0389\n",
      "reconstruction loss = 0.0071, similarity loss: 0.4739\n",
      "Epoch 22, loss = 1.3124, time: 17.1124\n",
      "reconstruction loss = 0.0079, similarity loss: 0.5212\n",
      "Epoch 23, loss = 1.3391, time: 17.1411\n",
      "reconstruction loss = 0.0079, similarity loss: 0.5498\n",
      "Epoch 24, loss = 1.3227, time: 17.7275\n",
      "reconstruction loss = 0.0078, similarity loss: 0.5469\n",
      "Epoch 25, loss = 1.3273, time: 17.3789\n",
      "reconstruction loss = 0.0084, similarity loss: 0.4862\n",
      "Epoch 26, loss = 1.1629, time: 17.1809\n",
      "reconstruction loss = 0.0069, similarity loss: 0.4776\n",
      "Epoch 27, loss = 1.2853, time: 17.3499\n",
      "reconstruction loss = 0.0079, similarity loss: 0.4918\n",
      "Epoch 28, loss = 1.1695, time: 16.9949\n",
      "reconstruction loss = 0.0067, similarity loss: 0.4993\n",
      "Epoch 29, loss = 1.0328, time: 17.2279\n",
      "reconstruction loss = 0.0063, similarity loss: 0.4016\n",
      "Epoch 30, loss = 1.2269, time: 17.6450\n",
      "reconstruction loss = 0.0073, similarity loss: 0.5014\n",
      "Epoch 31, loss = 1.0861, time: 16.9819\n",
      "reconstruction loss = 0.0067, similarity loss: 0.4144\n",
      "Epoch 32, loss = 1.0892, time: 16.9524\n",
      "reconstruction loss = 0.0065, similarity loss: 0.4430\n",
      "Epoch 33, loss = 1.0505, time: 17.0819\n",
      "reconstruction loss = 0.0065, similarity loss: 0.4041\n",
      "Epoch 34, loss = 1.1242, time: 16.8898\n",
      "reconstruction loss = 0.0068, similarity loss: 0.4491\n",
      "Epoch 35, loss = 1.1040, time: 16.6328\n",
      "reconstruction loss = 0.0067, similarity loss: 0.4341\n",
      "Epoch 36, loss = 1.2438, time: 17.1509\n",
      "reconstruction loss = 0.0073, similarity loss: 0.5183\n",
      "Epoch 37, loss = 0.9755, time: 17.1239\n",
      "reconstruction loss = 0.0061, similarity loss: 0.3668\n",
      "Epoch 38, loss = 1.2352, time: 16.7808\n",
      "reconstruction loss = 0.0072, similarity loss: 0.5177\n",
      "Epoch 39, loss = 0.9881, time: 16.5978\n",
      "reconstruction loss = 0.0056, similarity loss: 0.4325\n",
      "Epoch 40, loss = 0.9678, time: 17.0959\n",
      "reconstruction loss = 0.0059, similarity loss: 0.3796\n",
      "Epoch 41, loss = 1.3338, time: 17.0974\n",
      "reconstruction loss = 0.0078, similarity loss: 0.5535\n",
      "Epoch 42, loss = 1.1014, time: 17.3702\n",
      "reconstruction loss = 0.0065, similarity loss: 0.4513\n",
      "Epoch 43, loss = 0.9570, time: 17.7220\n",
      "reconstruction loss = 0.0058, similarity loss: 0.3722\n",
      "Epoch 44, loss = 1.0029, time: 17.9861\n",
      "reconstruction loss = 0.0062, similarity loss: 0.3820\n",
      "Epoch 45, loss = 1.0376, time: 17.2039\n",
      "reconstruction loss = 0.0060, similarity loss: 0.4420\n",
      "Epoch 46, loss = 0.9672, time: 17.2313\n",
      "reconstruction loss = 0.0061, similarity loss: 0.3547\n",
      "Epoch 47, loss = 1.0146, time: 16.8078\n",
      "reconstruction loss = 0.0061, similarity loss: 0.4029\n",
      "Epoch 48, loss = 1.0747, time: 16.5828\n",
      "reconstruction loss = 0.0067, similarity loss: 0.4003\n",
      "Epoch 49, loss = 0.8925, time: 16.6458\n",
      "reconstruction loss = 0.0054, similarity loss: 0.3570\n",
      "Epoch 50, loss = 1.0265, time: 16.6698\n",
      "reconstruction loss = 0.0061, similarity loss: 0.4116\n",
      "Epoch 51, loss = 0.8822, time: 16.8968\n",
      "reconstruction loss = 0.0053, similarity loss: 0.3505\n",
      "Epoch 52, loss = 0.8657, time: 16.6838\n",
      "reconstruction loss = 0.0056, similarity loss: 0.3104\n",
      "Epoch 53, loss = 0.9850, time: 16.7038\n",
      "reconstruction loss = 0.0062, similarity loss: 0.3691\n",
      "Epoch 54, loss = 0.9678, time: 16.6018\n",
      "reconstruction loss = 0.0059, similarity loss: 0.3783\n",
      "Epoch 55, loss = 0.9215, time: 16.6710\n",
      "reconstruction loss = 0.0056, similarity loss: 0.3613\n",
      "Epoch 56, loss = 0.9986, time: 16.6418\n",
      "reconstruction loss = 0.0062, similarity loss: 0.3771\n",
      "Epoch 57, loss = 0.9822, time: 16.4497\n",
      "reconstruction loss = 0.0059, similarity loss: 0.3934\n",
      "Epoch 58, loss = 1.0039, time: 16.5971\n",
      "reconstruction loss = 0.0062, similarity loss: 0.3842\n",
      "Epoch 59, loss = 0.8618, time: 16.6488\n",
      "reconstruction loss = 0.0053, similarity loss: 0.3318\n",
      "Epoch 60, loss = 0.9042, time: 16.5388\n",
      "reconstruction loss = 0.0054, similarity loss: 0.3636\n",
      "Epoch 61, loss = 0.9059, time: 16.7478\n",
      "reconstruction loss = 0.0057, similarity loss: 0.3336\n",
      "Epoch 62, loss = 0.8258, time: 16.6328\n",
      "reconstruction loss = 0.0053, similarity loss: 0.2965\n",
      "Epoch 63, loss = 0.8919, time: 16.9158\n",
      "reconstruction loss = 0.0053, similarity loss: 0.3618\n",
      "Epoch 64, loss = 0.8807, time: 17.1442\n",
      "reconstruction loss = 0.0054, similarity loss: 0.3362\n",
      "Epoch 65, loss = 0.8819, time: 17.2369\n",
      "reconstruction loss = 0.0055, similarity loss: 0.3349\n",
      "Epoch 66, loss = 0.8788, time: 17.6418\n",
      "reconstruction loss = 0.0054, similarity loss: 0.3404\n",
      "Epoch 67, loss = 0.8584, time: 17.2466\n",
      "reconstruction loss = 0.0054, similarity loss: 0.3152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.8851, time: 17.1112\n",
      "reconstruction loss = 0.0052, similarity loss: 0.3662\n",
      "Epoch 69, loss = 0.9024, time: 17.1439\n",
      "reconstruction loss = 0.0054, similarity loss: 0.3629\n",
      "Epoch 70, loss = 0.8738, time: 17.1797\n",
      "reconstruction loss = 0.0050, similarity loss: 0.3722\n",
      "Epoch 71, loss = 1.0774, time: 17.1529\n",
      "reconstruction loss = 0.0072, similarity loss: 0.3614\n",
      "Epoch 72, loss = 1.0361, time: 17.0858\n",
      "reconstruction loss = 0.0055, similarity loss: 0.4814\n",
      "Epoch 73, loss = 0.8185, time: 17.1224\n",
      "reconstruction loss = 0.0046, similarity loss: 0.3614\n",
      "Epoch 74, loss = 0.8635, time: 17.1899\n",
      "reconstruction loss = 0.0053, similarity loss: 0.3373\n",
      "Epoch 75, loss = 0.8733, time: 17.1894\n",
      "reconstruction loss = 0.0053, similarity loss: 0.3426\n",
      "Epoch 76, loss = 0.7684, time: 17.2599\n",
      "reconstruction loss = 0.0044, similarity loss: 0.3246\n",
      "Epoch 77, loss = 0.8096, time: 17.0609\n",
      "reconstruction loss = 0.0049, similarity loss: 0.3167\n",
      "Epoch 78, loss = 0.8771, time: 17.1528\n",
      "reconstruction loss = 0.0054, similarity loss: 0.3350\n",
      "Epoch 79, loss = 0.8741, time: 17.2808\n",
      "reconstruction loss = 0.0054, similarity loss: 0.3359\n",
      "Epoch 80, loss = 0.8451, time: 17.2189\n",
      "reconstruction loss = 0.0048, similarity loss: 0.3646\n",
      "Epoch 81, loss = 0.8372, time: 17.2239\n",
      "reconstruction loss = 0.0050, similarity loss: 0.3390\n",
      "Epoch 82, loss = 0.8877, time: 17.5205\n",
      "reconstruction loss = 0.0051, similarity loss: 0.3820\n",
      "Epoch 83, loss = 0.7932, time: 17.0469\n",
      "reconstruction loss = 0.0052, similarity loss: 0.2722\n",
      "Epoch 84, loss = 0.8259, time: 16.7842\n",
      "reconstruction loss = 0.0048, similarity loss: 0.3439\n",
      "Epoch 85, loss = 0.8716, time: 16.6858\n",
      "reconstruction loss = 0.0054, similarity loss: 0.3345\n",
      "Epoch 86, loss = 0.8133, time: 16.9189\n",
      "reconstruction loss = 0.0050, similarity loss: 0.3158\n",
      "Epoch 87, loss = 0.8194, time: 16.8048\n",
      "reconstruction loss = 0.0049, similarity loss: 0.3279\n",
      "Epoch 88, loss = 0.8416, time: 16.8708\n",
      "reconstruction loss = 0.0053, similarity loss: 0.3138\n",
      "Epoch 89, loss = 0.9410, time: 16.6988\n",
      "reconstruction loss = 0.0057, similarity loss: 0.3747\n",
      "Epoch 90, loss = 0.8823, time: 17.1234\n",
      "reconstruction loss = 0.0055, similarity loss: 0.3303\n",
      "Epoch 91, loss = 0.8404, time: 17.0018\n",
      "reconstruction loss = 0.0049, similarity loss: 0.3545\n",
      "Epoch 92, loss = 0.8066, time: 17.0622\n",
      "reconstruction loss = 0.0049, similarity loss: 0.3171\n",
      "Epoch 93, loss = 0.7669, time: 16.9853\n",
      "reconstruction loss = 0.0046, similarity loss: 0.3086\n",
      "Epoch 94, loss = 0.8829, time: 16.5448\n",
      "reconstruction loss = 0.0052, similarity loss: 0.3607\n",
      "Epoch 95, loss = 0.8786, time: 16.4918\n",
      "reconstruction loss = 0.0055, similarity loss: 0.3249\n",
      "Epoch 96, loss = 0.8128, time: 16.4577\n",
      "reconstruction loss = 0.0050, similarity loss: 0.3129\n",
      "Epoch 97, loss = 0.7819, time: 16.4507\n",
      "reconstruction loss = 0.0048, similarity loss: 0.3051\n",
      "Epoch 98, loss = 0.8974, time: 16.5368\n",
      "reconstruction loss = 0.0053, similarity loss: 0.3702\n",
      "Epoch 99, loss = 0.8661, time: 16.4937\n",
      "reconstruction loss = 0.0051, similarity loss: 0.3578\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 2.1174, val.loss = 1.9776, val.acc = 0.3906\n",
      "Epoch 1, loss = 1.8953, val.loss = 1.8225, val.acc = 0.4278\n",
      "Epoch 2, loss = 1.7729, val.loss = 1.7282, val.acc = 0.4498\n",
      "Epoch 3, loss = 1.6925, val.loss = 1.6626, val.acc = 0.4644\n",
      "Epoch 4, loss = 1.6335, val.loss = 1.6128, val.acc = 0.4790\n",
      "Epoch 5, loss = 1.5871, val.loss = 1.5727, val.acc = 0.4940\n",
      "Epoch 6, loss = 1.5488, val.loss = 1.5393, val.acc = 0.5022\n",
      "Epoch 7, loss = 1.5163, val.loss = 1.5107, val.acc = 0.5100\n",
      "Epoch 8, loss = 1.4881, val.loss = 1.4859, val.acc = 0.5172\n",
      "Epoch 9, loss = 1.4632, val.loss = 1.4639, val.acc = 0.5238\n",
      "Epoch 10, loss = 1.4410, val.loss = 1.4443, val.acc = 0.5322\n",
      "Epoch 11, loss = 1.4210, val.loss = 1.4266, val.acc = 0.5378\n",
      "Epoch 12, loss = 1.4028, val.loss = 1.4105, val.acc = 0.5420\n",
      "Epoch 13, loss = 1.3861, val.loss = 1.3959, val.acc = 0.5454\n",
      "Epoch 14, loss = 1.3707, val.loss = 1.3824, val.acc = 0.5506\n",
      "Epoch 15, loss = 1.3565, val.loss = 1.3700, val.acc = 0.5540\n",
      "Epoch 16, loss = 1.3433, val.loss = 1.3585, val.acc = 0.5576\n",
      "Epoch 17, loss = 1.3309, val.loss = 1.3477, val.acc = 0.5614\n",
      "Epoch 18, loss = 1.3193, val.loss = 1.3377, val.acc = 0.5644\n",
      "Epoch 19, loss = 1.3084, val.loss = 1.3283, val.acc = 0.5680\n",
      "Epoch 20, loss = 1.2981, val.loss = 1.3195, val.acc = 0.5688\n",
      "Epoch 21, loss = 1.2883, val.loss = 1.3111, val.acc = 0.5722\n",
      "Epoch 22, loss = 1.2790, val.loss = 1.3032, val.acc = 0.5724\n",
      "Epoch 23, loss = 1.2702, val.loss = 1.2958, val.acc = 0.5772\n",
      "Epoch 24, loss = 1.2618, val.loss = 1.2887, val.acc = 0.5782\n",
      "Epoch 25, loss = 1.2538, val.loss = 1.2819, val.acc = 0.5804\n",
      "Epoch 26, loss = 1.2461, val.loss = 1.2755, val.acc = 0.5824\n",
      "Epoch 27, loss = 1.2387, val.loss = 1.2693, val.acc = 0.5848\n",
      "Epoch 28, loss = 1.2316, val.loss = 1.2634, val.acc = 0.5856\n",
      "Epoch 29, loss = 1.2248, val.loss = 1.2578, val.acc = 0.5878\n",
      "Epoch 30, loss = 1.2183, val.loss = 1.2524, val.acc = 0.5888\n",
      "Epoch 31, loss = 1.2119, val.loss = 1.2472, val.acc = 0.5894\n",
      "Epoch 32, loss = 1.2058, val.loss = 1.2422, val.acc = 0.5916\n",
      "Epoch 33, loss = 1.1999, val.loss = 1.2374, val.acc = 0.5932\n",
      "Epoch 34, loss = 1.1942, val.loss = 1.2328, val.acc = 0.5952\n",
      "Epoch 35, loss = 1.1887, val.loss = 1.2284, val.acc = 0.5964\n",
      "Epoch 36, loss = 1.1833, val.loss = 1.2241, val.acc = 0.5976\n",
      "Epoch 37, loss = 1.1781, val.loss = 1.2199, val.acc = 0.5998\n",
      "Epoch 38, loss = 1.1731, val.loss = 1.2159, val.acc = 0.6000\n",
      "Epoch 39, loss = 1.1681, val.loss = 1.2120, val.acc = 0.6008\n",
      "Epoch 40, loss = 1.1634, val.loss = 1.2082, val.acc = 0.6014\n",
      "Epoch 41, loss = 1.1587, val.loss = 1.2046, val.acc = 0.6020\n",
      "Epoch 42, loss = 1.1542, val.loss = 1.2010, val.acc = 0.6024\n",
      "Epoch 43, loss = 1.1498, val.loss = 1.1976, val.acc = 0.6030\n",
      "Epoch 44, loss = 1.1455, val.loss = 1.1942, val.acc = 0.6044\n",
      "Epoch 45, loss = 1.1413, val.loss = 1.1910, val.acc = 0.6052\n",
      "Epoch 46, loss = 1.1371, val.loss = 1.1878, val.acc = 0.6070\n",
      "Epoch 47, loss = 1.1331, val.loss = 1.1847, val.acc = 0.6078\n",
      "Epoch 48, loss = 1.1292, val.loss = 1.1818, val.acc = 0.6094\n",
      "Epoch 49, loss = 1.1254, val.loss = 1.1788, val.acc = 0.6100\n",
      "Epoch 50, loss = 1.1216, val.loss = 1.1760, val.acc = 0.6104\n",
      "Epoch 51, loss = 1.1180, val.loss = 1.1732, val.acc = 0.6114\n",
      "Epoch 52, loss = 1.1144, val.loss = 1.1705, val.acc = 0.6116\n",
      "Epoch 53, loss = 1.1108, val.loss = 1.1679, val.acc = 0.6130\n",
      "Epoch 54, loss = 1.1074, val.loss = 1.1653, val.acc = 0.6144\n",
      "Epoch 55, loss = 1.1040, val.loss = 1.1628, val.acc = 0.6156\n",
      "Epoch 56, loss = 1.1007, val.loss = 1.1604, val.acc = 0.6170\n",
      "Epoch 57, loss = 1.0974, val.loss = 1.1580, val.acc = 0.6176\n",
      "Epoch 58, loss = 1.0942, val.loss = 1.1557, val.acc = 0.6178\n",
      "Epoch 59, loss = 1.0911, val.loss = 1.1534, val.acc = 0.6174\n",
      "Epoch 60, loss = 1.0880, val.loss = 1.1511, val.acc = 0.6178\n",
      "Epoch 61, loss = 1.0849, val.loss = 1.1489, val.acc = 0.6184\n",
      "Epoch 62, loss = 1.0819, val.loss = 1.1468, val.acc = 0.6188\n",
      "Epoch 63, loss = 1.0790, val.loss = 1.1447, val.acc = 0.6198\n",
      "Epoch 64, loss = 1.0761, val.loss = 1.1427, val.acc = 0.6202\n",
      "Epoch 65, loss = 1.0733, val.loss = 1.1407, val.acc = 0.6210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 1.0705, val.loss = 1.1387, val.acc = 0.6224\n",
      "Epoch 67, loss = 1.0677, val.loss = 1.1368, val.acc = 0.6230\n",
      "Epoch 68, loss = 1.0650, val.loss = 1.1349, val.acc = 0.6240\n",
      "Epoch 69, loss = 1.0624, val.loss = 1.1330, val.acc = 0.6252\n",
      "Epoch 70, loss = 1.0597, val.loss = 1.1312, val.acc = 0.6256\n",
      "Epoch 71, loss = 1.0571, val.loss = 1.1294, val.acc = 0.6266\n",
      "Epoch 72, loss = 1.0546, val.loss = 1.1277, val.acc = 0.6266\n",
      "Epoch 73, loss = 1.0521, val.loss = 1.1259, val.acc = 0.6268\n",
      "Epoch 74, loss = 1.0496, val.loss = 1.1243, val.acc = 0.6276\n",
      "Epoch 75, loss = 1.0472, val.loss = 1.1226, val.acc = 0.6278\n",
      "Epoch 76, loss = 1.0447, val.loss = 1.1210, val.acc = 0.6286\n",
      "Epoch 77, loss = 1.0424, val.loss = 1.1194, val.acc = 0.6290\n",
      "Epoch 78, loss = 1.0400, val.loss = 1.1178, val.acc = 0.6296\n",
      "Epoch 79, loss = 1.0377, val.loss = 1.1163, val.acc = 0.6292\n",
      "Epoch 80, loss = 1.0354, val.loss = 1.1147, val.acc = 0.6290\n",
      "Epoch 81, loss = 1.0331, val.loss = 1.1133, val.acc = 0.6292\n",
      "Epoch 82, loss = 1.0309, val.loss = 1.1118, val.acc = 0.6302\n",
      "Epoch 83, loss = 1.0287, val.loss = 1.1104, val.acc = 0.6306\n",
      "Epoch 84, loss = 1.0265, val.loss = 1.1089, val.acc = 0.6312\n",
      "Epoch 85, loss = 1.0244, val.loss = 1.1075, val.acc = 0.6330\n",
      "Epoch 86, loss = 1.0222, val.loss = 1.1062, val.acc = 0.6340\n",
      "Epoch 87, loss = 1.0201, val.loss = 1.1048, val.acc = 0.6340\n",
      "Epoch 88, loss = 1.0180, val.loss = 1.1035, val.acc = 0.6340\n",
      "Epoch 89, loss = 1.0160, val.loss = 1.1022, val.acc = 0.6350\n",
      "Epoch 90, loss = 1.0140, val.loss = 1.1009, val.acc = 0.6350\n",
      "Epoch 91, loss = 1.0119, val.loss = 1.0996, val.acc = 0.6354\n",
      "Epoch 92, loss = 1.0100, val.loss = 1.0984, val.acc = 0.6352\n",
      "Epoch 93, loss = 1.0080, val.loss = 1.0972, val.acc = 0.6356\n",
      "Epoch 94, loss = 1.0060, val.loss = 1.0959, val.acc = 0.6358\n",
      "Epoch 95, loss = 1.0041, val.loss = 1.0948, val.acc = 0.6356\n",
      "Epoch 96, loss = 1.0022, val.loss = 1.0936, val.acc = 0.6358\n",
      "Epoch 97, loss = 1.0003, val.loss = 1.0924, val.acc = 0.6362\n",
      "Epoch 98, loss = 0.9985, val.loss = 1.0913, val.acc = 0.6366\n",
      "Epoch 99, loss = 0.9966, val.loss = 1.0902, val.acc = 0.6368\n",
      "Epoch 100, loss = 0.9948, val.loss = 1.0890, val.acc = 0.6372\n",
      "Epoch 101, loss = 0.9930, val.loss = 1.0880, val.acc = 0.6378\n",
      "Epoch 102, loss = 0.9912, val.loss = 1.0869, val.acc = 0.6380\n",
      "Epoch 103, loss = 0.9894, val.loss = 1.0858, val.acc = 0.6376\n",
      "Epoch 104, loss = 0.9876, val.loss = 1.0848, val.acc = 0.6380\n",
      "Epoch 105, loss = 0.9859, val.loss = 1.0837, val.acc = 0.6382\n",
      "Epoch 106, loss = 0.9841, val.loss = 1.0827, val.acc = 0.6384\n",
      "Epoch 107, loss = 0.9824, val.loss = 1.0817, val.acc = 0.6386\n",
      "Epoch 108, loss = 0.9807, val.loss = 1.0807, val.acc = 0.6388\n",
      "Epoch 109, loss = 0.9791, val.loss = 1.0797, val.acc = 0.6390\n",
      "Epoch 110, loss = 0.9774, val.loss = 1.0788, val.acc = 0.6382\n",
      "Epoch 111, loss = 0.9757, val.loss = 1.0778, val.acc = 0.6386\n",
      "Epoch 112, loss = 0.9741, val.loss = 1.0769, val.acc = 0.6388\n",
      "Epoch 113, loss = 0.9725, val.loss = 1.0759, val.acc = 0.6388\n",
      "Epoch 114, loss = 0.9709, val.loss = 1.0750, val.acc = 0.6392\n",
      "Epoch 115, loss = 0.9693, val.loss = 1.0741, val.acc = 0.6394\n",
      "Epoch 116, loss = 0.9677, val.loss = 1.0732, val.acc = 0.6392\n",
      "Epoch 117, loss = 0.9661, val.loss = 1.0723, val.acc = 0.6396\n",
      "Epoch 118, loss = 0.9645, val.loss = 1.0715, val.acc = 0.6392\n",
      "Epoch 119, loss = 0.9630, val.loss = 1.0706, val.acc = 0.6396\n",
      "Epoch 120, loss = 0.9615, val.loss = 1.0697, val.acc = 0.6394\n",
      "Epoch 121, loss = 0.9599, val.loss = 1.0689, val.acc = 0.6400\n",
      "Epoch 122, loss = 0.9584, val.loss = 1.0681, val.acc = 0.6412\n",
      "Epoch 123, loss = 0.9569, val.loss = 1.0673, val.acc = 0.6416\n",
      "Epoch 124, loss = 0.9554, val.loss = 1.0664, val.acc = 0.6416\n",
      "Epoch 125, loss = 0.9540, val.loss = 1.0656, val.acc = 0.6410\n",
      "Epoch 126, loss = 0.9525, val.loss = 1.0648, val.acc = 0.6412\n",
      "Epoch 127, loss = 0.9511, val.loss = 1.0641, val.acc = 0.6418\n",
      "Epoch 128, loss = 0.9496, val.loss = 1.0633, val.acc = 0.6424\n",
      "Epoch 129, loss = 0.9482, val.loss = 1.0625, val.acc = 0.6426\n",
      "Epoch 130, loss = 0.9468, val.loss = 1.0618, val.acc = 0.6430\n",
      "Epoch 131, loss = 0.9453, val.loss = 1.0610, val.acc = 0.6428\n",
      "Epoch 132, loss = 0.9439, val.loss = 1.0603, val.acc = 0.6432\n",
      "Epoch 133, loss = 0.9426, val.loss = 1.0596, val.acc = 0.6438\n",
      "Epoch 134, loss = 0.9412, val.loss = 1.0588, val.acc = 0.6444\n",
      "Epoch 135, loss = 0.9398, val.loss = 1.0581, val.acc = 0.6448\n",
      "Epoch 136, loss = 0.9384, val.loss = 1.0574, val.acc = 0.6450\n",
      "Epoch 137, loss = 0.9371, val.loss = 1.0567, val.acc = 0.6450\n",
      "Epoch 138, loss = 0.9357, val.loss = 1.0560, val.acc = 0.6456\n",
      "Epoch 139, loss = 0.9344, val.loss = 1.0553, val.acc = 0.6458\n",
      "Epoch 140, loss = 0.9331, val.loss = 1.0547, val.acc = 0.6460\n",
      "Epoch 141, loss = 0.9318, val.loss = 1.0540, val.acc = 0.6464\n",
      "Epoch 142, loss = 0.9305, val.loss = 1.0533, val.acc = 0.6466\n",
      "Epoch 143, loss = 0.9292, val.loss = 1.0527, val.acc = 0.6466\n",
      "Epoch 144, loss = 0.9279, val.loss = 1.0520, val.acc = 0.6464\n",
      "Epoch 145, loss = 0.9266, val.loss = 1.0514, val.acc = 0.6466\n",
      "Epoch 146, loss = 0.9253, val.loss = 1.0507, val.acc = 0.6468\n",
      "Epoch 147, loss = 0.9240, val.loss = 1.0501, val.acc = 0.6470\n",
      "Epoch 148, loss = 0.9228, val.loss = 1.0495, val.acc = 0.6474\n",
      "Epoch 149, loss = 0.9215, val.loss = 1.0489, val.acc = 0.6478\n",
      "Rep: 1, te.acc = 0.6395\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6395]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 100\n",
    "vis = visdom.Visdom(port=8097,env='ae'+str(pars.decoder_channel)+'_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T05:36:15.527075Z",
     "start_time": "2022-04-02T05:36:15.513072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture: CONV6\n",
      "nonlinear: hardtanh\n",
      "batch_size: 500\n",
      "headsize: 64\n",
      "dataset: Cifar100\n",
      "loss: SimCLR\n",
      "OPT: Adam\n",
      "LR: 0.0005\n",
      "epochs: 100\n",
      "clf_dataset: Cifar10\n",
      "clf_loss: CE\n",
      "clf_opt: Adam\n",
      "clf_lr: 5e-05\n",
      "clf_epochs: 150\n",
      "repeat: 1\n",
      "device: cuda:0\n",
      "datapath: data/\n",
      "savepath: save/\n",
      "loadnet: False\n",
      "loadclf: False\n",
      "lam: 1\n",
      "decoder_channel: 8\n",
      "decoder_layer: 2\n",
      "clfnonlinear: None\n",
      "headnonlinear: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pars = PARS(device, datapath, savepath)\n",
    "pars.architecture = 'CONV6'\n",
    "pars.LR = 5e-4\n",
    "pars.clf_lr = 5e-5\n",
    "pars.epochs = 100\n",
    "pars.clf_epochs = 150\n",
    "pars.nonlinear = 'hardtanh'\n",
    "pars.repeat = 1\n",
    "pars.loadnet = False\n",
    "pars.decoder_channel = 8\n",
    "pars.decoder_layer = 2\n",
    "print(pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (auxdecoder): Sequential(\n",
       "    (fc): Linear(in_features=64, out_features=8192, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (unflatten): Unflatten(dim=1, unflattened_size=(8, 32, 32))\n",
       "    (deconv0): ConvTranspose2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu0): ReLU()\n",
       "    (deconv): ConvTranspose2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_decoder(pars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T06:08:56.208431Z",
     "start_time": "2022-04-02T05:36:16.774373Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_3/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_1_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(3, 32, 32))\n",
      "    (deconv): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 0.8512, time: 25.4070\n",
      "reconstruction loss = 0.0676, similarity loss: 0.7836\n",
      "Epoch 1, loss = 0.5908, time: 16.6738\n",
      "reconstruction loss = 0.0671, similarity loss: 0.5237\n",
      "Epoch 2, loss = 0.6114, time: 16.5367\n",
      "reconstruction loss = 0.0646, similarity loss: 0.5468\n",
      "Epoch 3, loss = 0.6442, time: 16.6018\n",
      "reconstruction loss = 0.0645, similarity loss: 0.5797\n",
      "Epoch 4, loss = 0.6485, time: 16.7058\n",
      "reconstruction loss = 0.0633, similarity loss: 0.5852\n",
      "Epoch 5, loss = 0.6081, time: 16.6368\n",
      "reconstruction loss = 0.0770, similarity loss: 0.5311\n",
      "Epoch 6, loss = 0.4577, time: 17.8480\n",
      "reconstruction loss = 0.0670, similarity loss: 0.3906\n",
      "Epoch 7, loss = 0.4566, time: 18.5432\n",
      "reconstruction loss = 0.0660, similarity loss: 0.3906\n",
      "Epoch 8, loss = 0.5312, time: 20.3439\n",
      "reconstruction loss = 0.0674, similarity loss: 0.4638\n",
      "Epoch 9, loss = 0.4707, time: 20.1446\n",
      "reconstruction loss = 0.0668, similarity loss: 0.4039\n",
      "Epoch 10, loss = 0.4518, time: 18.1267\n",
      "reconstruction loss = 0.0635, similarity loss: 0.3883\n",
      "Epoch 11, loss = 0.3740, time: 16.5168\n",
      "reconstruction loss = 0.0694, similarity loss: 0.3046\n",
      "Epoch 12, loss = 0.3873, time: 16.2153\n",
      "reconstruction loss = 0.0647, similarity loss: 0.3227\n",
      "Epoch 13, loss = 0.4290, time: 16.9380\n",
      "reconstruction loss = 0.0650, similarity loss: 0.3640\n",
      "Epoch 14, loss = 0.3982, time: 17.5393\n",
      "reconstruction loss = 0.0640, similarity loss: 0.3342\n",
      "Epoch 15, loss = 0.3646, time: 17.8049\n",
      "reconstruction loss = 0.0649, similarity loss: 0.2997\n",
      "Epoch 16, loss = 0.3968, time: 17.3214\n",
      "reconstruction loss = 0.0655, similarity loss: 0.3313\n",
      "Epoch 17, loss = 0.3467, time: 17.3358\n",
      "reconstruction loss = 0.0637, similarity loss: 0.2829\n",
      "Epoch 18, loss = 0.3433, time: 17.3527\n",
      "reconstruction loss = 0.0649, similarity loss: 0.2784\n",
      "Epoch 19, loss = 0.3439, time: 17.3671\n",
      "reconstruction loss = 0.0640, similarity loss: 0.2800\n",
      "Epoch 20, loss = 0.3451, time: 17.2839\n",
      "reconstruction loss = 0.0641, similarity loss: 0.2810\n",
      "Epoch 21, loss = 0.3550, time: 17.2078\n",
      "reconstruction loss = 0.0639, similarity loss: 0.2911\n",
      "Epoch 22, loss = 0.3273, time: 17.3204\n",
      "reconstruction loss = 0.0621, similarity loss: 0.2652\n",
      "Epoch 23, loss = 0.3084, time: 17.1773\n",
      "reconstruction loss = 0.0637, similarity loss: 0.2447\n",
      "Epoch 24, loss = 0.3161, time: 17.3790\n",
      "reconstruction loss = 0.0626, similarity loss: 0.2535\n",
      "Epoch 25, loss = 0.3410, time: 17.2410\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2757\n",
      "Epoch 26, loss = 0.2941, time: 17.2531\n",
      "reconstruction loss = 0.0641, similarity loss: 0.2300\n",
      "Epoch 27, loss = 0.3086, time: 17.2184\n",
      "reconstruction loss = 0.0636, similarity loss: 0.2450\n",
      "Epoch 28, loss = 0.3309, time: 17.3649\n",
      "reconstruction loss = 0.0662, similarity loss: 0.2647\n",
      "Epoch 29, loss = 0.3081, time: 17.6452\n",
      "reconstruction loss = 0.0627, similarity loss: 0.2454\n",
      "Epoch 30, loss = 0.3289, time: 18.1384\n",
      "reconstruction loss = 0.0692, similarity loss: 0.2597\n",
      "Epoch 31, loss = 0.3491, time: 18.0628\n",
      "reconstruction loss = 0.0635, similarity loss: 0.2856\n",
      "Epoch 32, loss = 0.3513, time: 17.8561\n",
      "reconstruction loss = 0.0646, similarity loss: 0.2866\n",
      "Epoch 33, loss = 0.3606, time: 17.9757\n",
      "reconstruction loss = 0.0667, similarity loss: 0.2939\n",
      "Epoch 34, loss = 0.3205, time: 17.8782\n",
      "reconstruction loss = 0.0646, similarity loss: 0.2559\n",
      "Epoch 35, loss = 0.2689, time: 17.9159\n",
      "reconstruction loss = 0.0650, similarity loss: 0.2040\n",
      "Epoch 36, loss = 0.3484, time: 17.9210\n",
      "reconstruction loss = 0.0656, similarity loss: 0.2827\n",
      "Epoch 37, loss = 0.3220, time: 17.9421\n",
      "reconstruction loss = 0.0659, similarity loss: 0.2561\n",
      "Epoch 38, loss = 0.3339, time: 17.8281\n",
      "reconstruction loss = 0.0636, similarity loss: 0.2703\n",
      "Epoch 39, loss = 0.3384, time: 17.9673\n",
      "reconstruction loss = 0.0670, similarity loss: 0.2714\n",
      "Epoch 40, loss = 0.2998, time: 17.8299\n",
      "reconstruction loss = 0.0637, similarity loss: 0.2361\n",
      "Epoch 41, loss = 0.3360, time: 17.8469\n",
      "reconstruction loss = 0.0669, similarity loss: 0.2692\n",
      "Epoch 42, loss = 0.3242, time: 17.9402\n",
      "reconstruction loss = 0.0672, similarity loss: 0.2570\n",
      "Epoch 43, loss = 0.3033, time: 17.7706\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2381\n",
      "Epoch 44, loss = 0.3243, time: 17.8536\n",
      "reconstruction loss = 0.0626, similarity loss: 0.2617\n",
      "Epoch 45, loss = 0.3501, time: 18.0553\n",
      "reconstruction loss = 0.0658, similarity loss: 0.2842\n",
      "Epoch 46, loss = 0.3114, time: 17.6547\n",
      "reconstruction loss = 0.0649, similarity loss: 0.2464\n",
      "Epoch 47, loss = 0.3102, time: 16.5128\n",
      "reconstruction loss = 0.0645, similarity loss: 0.2457\n",
      "Epoch 48, loss = 0.3124, time: 16.5088\n",
      "reconstruction loss = 0.0624, similarity loss: 0.2501\n",
      "Epoch 49, loss = 0.3079, time: 16.5596\n",
      "reconstruction loss = 0.0639, similarity loss: 0.2440\n",
      "Epoch 50, loss = 0.3033, time: 16.4479\n",
      "reconstruction loss = 0.0636, similarity loss: 0.2397\n",
      "Epoch 51, loss = 0.2864, time: 16.4899\n",
      "reconstruction loss = 0.0671, similarity loss: 0.2194\n",
      "Epoch 52, loss = 0.3042, time: 16.4106\n",
      "reconstruction loss = 0.0634, similarity loss: 0.2407\n",
      "Epoch 53, loss = 0.3512, time: 16.1097\n",
      "reconstruction loss = 0.0681, similarity loss: 0.2831\n",
      "Epoch 54, loss = 0.2996, time: 16.1837\n",
      "reconstruction loss = 0.0634, similarity loss: 0.2362\n",
      "Epoch 55, loss = 0.3045, time: 16.2247\n",
      "reconstruction loss = 0.0628, similarity loss: 0.2418\n",
      "Epoch 56, loss = 0.2678, time: 16.0498\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2025\n",
      "Epoch 57, loss = 0.3158, time: 16.1517\n",
      "reconstruction loss = 0.0630, similarity loss: 0.2528\n",
      "Epoch 58, loss = 0.3113, time: 16.1410\n",
      "reconstruction loss = 0.0641, similarity loss: 0.2472\n",
      "Epoch 59, loss = 0.2849, time: 16.2239\n",
      "reconstruction loss = 0.0667, similarity loss: 0.2182\n",
      "Epoch 60, loss = 0.3140, time: 16.2302\n",
      "reconstruction loss = 0.0634, similarity loss: 0.2506\n",
      "Epoch 61, loss = 0.3012, time: 16.2347\n",
      "reconstruction loss = 0.0620, similarity loss: 0.2392\n",
      "Epoch 62, loss = 0.3289, time: 16.3140\n",
      "reconstruction loss = 0.0665, similarity loss: 0.2623\n",
      "Epoch 63, loss = 0.2917, time: 16.2027\n",
      "reconstruction loss = 0.0629, similarity loss: 0.2288\n",
      "Epoch 64, loss = 0.2937, time: 16.2120\n",
      "reconstruction loss = 0.0676, similarity loss: 0.2261\n",
      "Epoch 65, loss = 0.2761, time: 16.0767\n",
      "reconstruction loss = 0.0667, similarity loss: 0.2095\n",
      "Epoch 66, loss = 0.2842, time: 16.2397\n",
      "reconstruction loss = 0.0648, similarity loss: 0.2193\n",
      "Epoch 67, loss = 0.3079, time: 16.1427\n",
      "reconstruction loss = 0.0631, similarity loss: 0.2448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.3607, time: 16.2127\n",
      "reconstruction loss = 0.0666, similarity loss: 0.2941\n",
      "Epoch 69, loss = 0.3334, time: 16.1447\n",
      "reconstruction loss = 0.0666, similarity loss: 0.2668\n",
      "Epoch 70, loss = 0.2913, time: 16.1241\n",
      "reconstruction loss = 0.0641, similarity loss: 0.2272\n",
      "Epoch 71, loss = 0.3131, time: 16.3780\n",
      "reconstruction loss = 0.0663, similarity loss: 0.2468\n",
      "Epoch 72, loss = 0.2814, time: 16.4393\n",
      "reconstruction loss = 0.0643, similarity loss: 0.2171\n",
      "Epoch 73, loss = 0.3207, time: 16.1217\n",
      "reconstruction loss = 0.0642, similarity loss: 0.2565\n",
      "Epoch 74, loss = 0.3165, time: 16.2997\n",
      "reconstruction loss = 0.0605, similarity loss: 0.2560\n",
      "Epoch 75, loss = 0.2956, time: 16.4304\n",
      "reconstruction loss = 0.0644, similarity loss: 0.2312\n",
      "Epoch 76, loss = 0.2915, time: 16.4294\n",
      "reconstruction loss = 0.0650, similarity loss: 0.2265\n",
      "Epoch 77, loss = 0.3578, time: 16.3390\n",
      "reconstruction loss = 0.0652, similarity loss: 0.2926\n",
      "Epoch 78, loss = 0.2926, time: 16.2832\n",
      "reconstruction loss = 0.0632, similarity loss: 0.2294\n",
      "Epoch 79, loss = 0.3345, time: 16.3087\n",
      "reconstruction loss = 0.0660, similarity loss: 0.2685\n",
      "Epoch 80, loss = 0.2948, time: 16.2307\n",
      "reconstruction loss = 0.0669, similarity loss: 0.2279\n",
      "Epoch 81, loss = 0.2908, time: 16.1281\n",
      "reconstruction loss = 0.0650, similarity loss: 0.2259\n",
      "Epoch 82, loss = 0.3109, time: 16.3276\n",
      "reconstruction loss = 0.0663, similarity loss: 0.2447\n",
      "Epoch 83, loss = 0.3242, time: 16.1931\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2589\n",
      "Epoch 84, loss = 0.2855, time: 16.2969\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2201\n",
      "Epoch 85, loss = 0.2696, time: 16.3014\n",
      "reconstruction loss = 0.0646, similarity loss: 0.2050\n",
      "Epoch 86, loss = 0.2888, time: 16.1961\n",
      "reconstruction loss = 0.0661, similarity loss: 0.2227\n",
      "Epoch 87, loss = 0.2846, time: 16.2340\n",
      "reconstruction loss = 0.0670, similarity loss: 0.2176\n",
      "Epoch 88, loss = 0.2854, time: 16.1754\n",
      "reconstruction loss = 0.0659, similarity loss: 0.2195\n",
      "Epoch 89, loss = 0.3093, time: 16.3711\n",
      "reconstruction loss = 0.0658, similarity loss: 0.2435\n",
      "Epoch 90, loss = 0.3080, time: 16.3042\n",
      "reconstruction loss = 0.0652, similarity loss: 0.2428\n",
      "Epoch 91, loss = 0.2909, time: 16.1098\n",
      "reconstruction loss = 0.0644, similarity loss: 0.2264\n",
      "Epoch 92, loss = 0.2842, time: 16.1653\n",
      "reconstruction loss = 0.0655, similarity loss: 0.2187\n",
      "Epoch 93, loss = 0.2653, time: 16.1037\n",
      "reconstruction loss = 0.0648, similarity loss: 0.2004\n",
      "Epoch 94, loss = 0.3046, time: 16.2957\n",
      "reconstruction loss = 0.0644, similarity loss: 0.2402\n",
      "Epoch 95, loss = 0.2919, time: 16.2044\n",
      "reconstruction loss = 0.0679, similarity loss: 0.2240\n",
      "Epoch 96, loss = 0.2886, time: 16.1804\n",
      "reconstruction loss = 0.0659, similarity loss: 0.2227\n",
      "Epoch 97, loss = 0.2639, time: 16.7901\n",
      "reconstruction loss = 0.0685, similarity loss: 0.1954\n",
      "Epoch 98, loss = 0.3251, time: 16.9319\n",
      "reconstruction loss = 0.0662, similarity loss: 0.2589\n",
      "Epoch 99, loss = 0.2920, time: 16.8394\n",
      "reconstruction loss = 0.0611, similarity loss: 0.2309\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.9545, val.loss = 1.6340, val.acc = 0.4412\n",
      "Epoch 1, loss = 1.5680, val.loss = 1.4795, val.acc = 0.4964\n",
      "Epoch 2, loss = 1.4505, val.loss = 1.4045, val.acc = 0.5276\n",
      "Epoch 3, loss = 1.3813, val.loss = 1.3578, val.acc = 0.5434\n",
      "Epoch 4, loss = 1.3328, val.loss = 1.3250, val.acc = 0.5522\n",
      "Epoch 5, loss = 1.2957, val.loss = 1.3002, val.acc = 0.5612\n",
      "Epoch 6, loss = 1.2655, val.loss = 1.2806, val.acc = 0.5682\n",
      "Epoch 7, loss = 1.2400, val.loss = 1.2643, val.acc = 0.5734\n",
      "Epoch 8, loss = 1.2179, val.loss = 1.2506, val.acc = 0.5814\n",
      "Epoch 9, loss = 1.1982, val.loss = 1.2387, val.acc = 0.5826\n",
      "Epoch 10, loss = 1.1805, val.loss = 1.2283, val.acc = 0.5852\n",
      "Epoch 11, loss = 1.1643, val.loss = 1.2190, val.acc = 0.5872\n",
      "Epoch 12, loss = 1.1494, val.loss = 1.2107, val.acc = 0.5896\n",
      "Epoch 13, loss = 1.1355, val.loss = 1.2032, val.acc = 0.5926\n",
      "Epoch 14, loss = 1.1226, val.loss = 1.1964, val.acc = 0.5952\n",
      "Epoch 15, loss = 1.1104, val.loss = 1.1902, val.acc = 0.5974\n",
      "Epoch 16, loss = 1.0989, val.loss = 1.1845, val.acc = 0.5980\n",
      "Epoch 17, loss = 1.0880, val.loss = 1.1793, val.acc = 0.5990\n",
      "Epoch 18, loss = 1.0776, val.loss = 1.1744, val.acc = 0.6010\n",
      "Epoch 19, loss = 1.0677, val.loss = 1.1699, val.acc = 0.6038\n",
      "Epoch 20, loss = 1.0583, val.loss = 1.1657, val.acc = 0.6044\n",
      "Epoch 21, loss = 1.0492, val.loss = 1.1618, val.acc = 0.6056\n",
      "Epoch 22, loss = 1.0405, val.loss = 1.1582, val.acc = 0.6060\n",
      "Epoch 23, loss = 1.0322, val.loss = 1.1548, val.acc = 0.6074\n",
      "Epoch 24, loss = 1.0241, val.loss = 1.1516, val.acc = 0.6076\n",
      "Epoch 25, loss = 1.0163, val.loss = 1.1486, val.acc = 0.6086\n",
      "Epoch 26, loss = 1.0088, val.loss = 1.1459, val.acc = 0.6094\n",
      "Epoch 27, loss = 1.0015, val.loss = 1.1432, val.acc = 0.6112\n",
      "Epoch 28, loss = 0.9945, val.loss = 1.1407, val.acc = 0.6124\n",
      "Epoch 29, loss = 0.9876, val.loss = 1.1385, val.acc = 0.6136\n",
      "Epoch 30, loss = 0.9810, val.loss = 1.1363, val.acc = 0.6146\n",
      "Epoch 31, loss = 0.9745, val.loss = 1.1342, val.acc = 0.6152\n",
      "Epoch 32, loss = 0.9682, val.loss = 1.1323, val.acc = 0.6154\n",
      "Epoch 33, loss = 0.9621, val.loss = 1.1305, val.acc = 0.6148\n",
      "Epoch 34, loss = 0.9562, val.loss = 1.1288, val.acc = 0.6154\n",
      "Epoch 35, loss = 0.9504, val.loss = 1.1272, val.acc = 0.6156\n",
      "Epoch 36, loss = 0.9447, val.loss = 1.1256, val.acc = 0.6172\n",
      "Epoch 37, loss = 0.9392, val.loss = 1.1242, val.acc = 0.6184\n",
      "Epoch 38, loss = 0.9338, val.loss = 1.1228, val.acc = 0.6188\n",
      "Epoch 39, loss = 0.9285, val.loss = 1.1216, val.acc = 0.6190\n",
      "Epoch 40, loss = 0.9233, val.loss = 1.1205, val.acc = 0.6202\n",
      "Epoch 41, loss = 0.9183, val.loss = 1.1193, val.acc = 0.6208\n",
      "Epoch 42, loss = 0.9133, val.loss = 1.1182, val.acc = 0.6208\n",
      "Epoch 43, loss = 0.9085, val.loss = 1.1172, val.acc = 0.6210\n",
      "Epoch 44, loss = 0.9038, val.loss = 1.1163, val.acc = 0.6210\n",
      "Epoch 45, loss = 0.8991, val.loss = 1.1154, val.acc = 0.6210\n",
      "Epoch 46, loss = 0.8945, val.loss = 1.1146, val.acc = 0.6214\n",
      "Epoch 47, loss = 0.8900, val.loss = 1.1138, val.acc = 0.6218\n",
      "Epoch 48, loss = 0.8857, val.loss = 1.1131, val.acc = 0.6218\n",
      "Epoch 49, loss = 0.8813, val.loss = 1.1124, val.acc = 0.6216\n",
      "Epoch 50, loss = 0.8771, val.loss = 1.1118, val.acc = 0.6212\n",
      "Epoch 51, loss = 0.8729, val.loss = 1.1112, val.acc = 0.6210\n",
      "Epoch 52, loss = 0.8689, val.loss = 1.1107, val.acc = 0.6222\n",
      "Epoch 53, loss = 0.8648, val.loss = 1.1101, val.acc = 0.6224\n",
      "Epoch 54, loss = 0.8609, val.loss = 1.1097, val.acc = 0.6232\n",
      "Epoch 55, loss = 0.8570, val.loss = 1.1092, val.acc = 0.6232\n",
      "Epoch 56, loss = 0.8532, val.loss = 1.1089, val.acc = 0.6236\n",
      "Epoch 57, loss = 0.8494, val.loss = 1.1085, val.acc = 0.6242\n",
      "Epoch 58, loss = 0.8457, val.loss = 1.1081, val.acc = 0.6250\n",
      "Epoch 59, loss = 0.8421, val.loss = 1.1079, val.acc = 0.6252\n",
      "Epoch 60, loss = 0.8385, val.loss = 1.1076, val.acc = 0.6246\n",
      "Epoch 61, loss = 0.8350, val.loss = 1.1073, val.acc = 0.6240\n",
      "Epoch 62, loss = 0.8315, val.loss = 1.1071, val.acc = 0.6246\n",
      "Epoch 63, loss = 0.8280, val.loss = 1.1069, val.acc = 0.6250\n",
      "Epoch 64, loss = 0.8246, val.loss = 1.1067, val.acc = 0.6246\n",
      "Epoch 65, loss = 0.8213, val.loss = 1.1066, val.acc = 0.6248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.8180, val.loss = 1.1065, val.acc = 0.6250\n",
      "Epoch 67, loss = 0.8148, val.loss = 1.1064, val.acc = 0.6250\n",
      "Epoch 68, loss = 0.8116, val.loss = 1.1064, val.acc = 0.6252\n",
      "Epoch 69, loss = 0.8084, val.loss = 1.1062, val.acc = 0.6252\n",
      "Epoch 70, loss = 0.8053, val.loss = 1.1063, val.acc = 0.6246\n",
      "Epoch 71, loss = 0.8022, val.loss = 1.1062, val.acc = 0.6246\n",
      "Epoch 72, loss = 0.7992, val.loss = 1.1063, val.acc = 0.6242\n",
      "Epoch 73, loss = 0.7962, val.loss = 1.1063, val.acc = 0.6248\n",
      "Epoch 74, loss = 0.7932, val.loss = 1.1064, val.acc = 0.6246\n",
      "Epoch 75, loss = 0.7903, val.loss = 1.1064, val.acc = 0.6242\n",
      "Epoch 76, loss = 0.7874, val.loss = 1.1065, val.acc = 0.6238\n",
      "Epoch 77, loss = 0.7846, val.loss = 1.1066, val.acc = 0.6240\n",
      "Epoch 78, loss = 0.7818, val.loss = 1.1067, val.acc = 0.6248\n",
      "Epoch 79, loss = 0.7790, val.loss = 1.1068, val.acc = 0.6244\n",
      "Epoch 80, loss = 0.7762, val.loss = 1.1070, val.acc = 0.6240\n",
      "Epoch 81, loss = 0.7735, val.loss = 1.1071, val.acc = 0.6242\n",
      "Epoch 82, loss = 0.7708, val.loss = 1.1073, val.acc = 0.6238\n",
      "Epoch 83, loss = 0.7682, val.loss = 1.1075, val.acc = 0.6226\n",
      "Epoch 84, loss = 0.7655, val.loss = 1.1077, val.acc = 0.6222\n",
      "Epoch 85, loss = 0.7629, val.loss = 1.1079, val.acc = 0.6226\n",
      "Epoch 86, loss = 0.7604, val.loss = 1.1082, val.acc = 0.6224\n",
      "Epoch 87, loss = 0.7578, val.loss = 1.1084, val.acc = 0.6216\n",
      "Epoch 88, loss = 0.7553, val.loss = 1.1087, val.acc = 0.6220\n",
      "Epoch 89, loss = 0.7528, val.loss = 1.1089, val.acc = 0.6220\n",
      "Epoch 90, loss = 0.7504, val.loss = 1.1092, val.acc = 0.6224\n",
      "Epoch 91, loss = 0.7479, val.loss = 1.1095, val.acc = 0.6220\n",
      "Epoch 92, loss = 0.7455, val.loss = 1.1098, val.acc = 0.6220\n",
      "Epoch 93, loss = 0.7432, val.loss = 1.1101, val.acc = 0.6226\n",
      "Epoch 94, loss = 0.7408, val.loss = 1.1104, val.acc = 0.6222\n",
      "Epoch 95, loss = 0.7385, val.loss = 1.1108, val.acc = 0.6220\n",
      "Epoch 96, loss = 0.7362, val.loss = 1.1111, val.acc = 0.6218\n",
      "Epoch 97, loss = 0.7339, val.loss = 1.1115, val.acc = 0.6218\n",
      "Epoch 98, loss = 0.7316, val.loss = 1.1118, val.acc = 0.6218\n",
      "Epoch 99, loss = 0.7294, val.loss = 1.1122, val.acc = 0.6226\n",
      "Epoch 100, loss = 0.7272, val.loss = 1.1126, val.acc = 0.6224\n",
      "Epoch 101, loss = 0.7250, val.loss = 1.1129, val.acc = 0.6230\n",
      "Epoch 102, loss = 0.7228, val.loss = 1.1134, val.acc = 0.6232\n",
      "Epoch 103, loss = 0.7206, val.loss = 1.1138, val.acc = 0.6232\n",
      "Epoch 104, loss = 0.7185, val.loss = 1.1142, val.acc = 0.6234\n",
      "Epoch 105, loss = 0.7164, val.loss = 1.1146, val.acc = 0.6226\n",
      "Epoch 106, loss = 0.7143, val.loss = 1.1150, val.acc = 0.6228\n",
      "Epoch 107, loss = 0.7122, val.loss = 1.1155, val.acc = 0.6230\n",
      "Epoch 108, loss = 0.7102, val.loss = 1.1159, val.acc = 0.6230\n",
      "Epoch 109, loss = 0.7082, val.loss = 1.1164, val.acc = 0.6230\n",
      "Epoch 110, loss = 0.7061, val.loss = 1.1168, val.acc = 0.6240\n",
      "Epoch 111, loss = 0.7042, val.loss = 1.1173, val.acc = 0.6240\n",
      "Epoch 112, loss = 0.7022, val.loss = 1.1178, val.acc = 0.6242\n",
      "Epoch 113, loss = 0.7002, val.loss = 1.1183, val.acc = 0.6240\n",
      "Epoch 114, loss = 0.6983, val.loss = 1.1188, val.acc = 0.6244\n",
      "Epoch 115, loss = 0.6964, val.loss = 1.1193, val.acc = 0.6248\n",
      "Epoch 116, loss = 0.6945, val.loss = 1.1198, val.acc = 0.6250\n",
      "Epoch 117, loss = 0.6926, val.loss = 1.1203, val.acc = 0.6248\n",
      "Epoch 118, loss = 0.6907, val.loss = 1.1208, val.acc = 0.6244\n",
      "Epoch 119, loss = 0.6889, val.loss = 1.1214, val.acc = 0.6236\n",
      "Epoch 120, loss = 0.6870, val.loss = 1.1219, val.acc = 0.6240\n",
      "Epoch 121, loss = 0.6852, val.loss = 1.1225, val.acc = 0.6244\n",
      "Epoch 122, loss = 0.6834, val.loss = 1.1231, val.acc = 0.6238\n",
      "Epoch 123, loss = 0.6817, val.loss = 1.1237, val.acc = 0.6240\n",
      "Epoch 124, loss = 0.6799, val.loss = 1.1242, val.acc = 0.6240\n",
      "Epoch 125, loss = 0.6781, val.loss = 1.1248, val.acc = 0.6240\n",
      "Epoch 126, loss = 0.6764, val.loss = 1.1254, val.acc = 0.6242\n",
      "Epoch 127, loss = 0.6747, val.loss = 1.1260, val.acc = 0.6240\n",
      "Epoch 128, loss = 0.6730, val.loss = 1.1266, val.acc = 0.6234\n",
      "Epoch 129, loss = 0.6713, val.loss = 1.1272, val.acc = 0.6228\n",
      "Epoch 130, loss = 0.6697, val.loss = 1.1279, val.acc = 0.6234\n",
      "Epoch 131, loss = 0.6680, val.loss = 1.1285, val.acc = 0.6224\n",
      "Epoch 132, loss = 0.6664, val.loss = 1.1292, val.acc = 0.6224\n",
      "Epoch 133, loss = 0.6648, val.loss = 1.1299, val.acc = 0.6218\n",
      "Epoch 134, loss = 0.6632, val.loss = 1.1305, val.acc = 0.6216\n",
      "Epoch 135, loss = 0.6616, val.loss = 1.1313, val.acc = 0.6212\n",
      "Epoch 136, loss = 0.6601, val.loss = 1.1320, val.acc = 0.6210\n",
      "Epoch 137, loss = 0.6586, val.loss = 1.1327, val.acc = 0.6212\n",
      "Epoch 138, loss = 0.6570, val.loss = 1.1335, val.acc = 0.6218\n",
      "Epoch 139, loss = 0.6555, val.loss = 1.1343, val.acc = 0.6218\n",
      "Epoch 140, loss = 0.6540, val.loss = 1.1351, val.acc = 0.6224\n",
      "Epoch 141, loss = 0.6526, val.loss = 1.1359, val.acc = 0.6226\n",
      "Epoch 142, loss = 0.6512, val.loss = 1.1368, val.acc = 0.6220\n",
      "Epoch 143, loss = 0.6497, val.loss = 1.1377, val.acc = 0.6208\n",
      "Epoch 144, loss = 0.6483, val.loss = 1.1386, val.acc = 0.6204\n",
      "Epoch 145, loss = 0.6469, val.loss = 1.1395, val.acc = 0.6196\n",
      "Epoch 146, loss = 0.6455, val.loss = 1.1404, val.acc = 0.6194\n",
      "Epoch 147, loss = 0.6441, val.loss = 1.1414, val.acc = 0.6198\n",
      "Epoch 148, loss = 0.6428, val.loss = 1.1425, val.acc = 0.6194\n",
      "Epoch 149, loss = 0.6414, val.loss = 1.1434, val.acc = 0.6190\n",
      "Rep: 1, te.acc = 0.6066\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6066]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 1\n",
    "vis = visdom.Visdom(port=8097,env='ae_2l_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T06:40:47.633678Z",
     "start_time": "2022-04-02T06:08:56.210433Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_3/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_5_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(3, 32, 32))\n",
      "    (deconv): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 0.9982, time: 17.1765\n",
      "reconstruction loss = 0.0650, similarity loss: 0.6734\n",
      "Epoch 1, loss = 0.9441, time: 16.7957\n",
      "reconstruction loss = 0.0527, similarity loss: 0.6805\n",
      "Epoch 2, loss = 0.7917, time: 16.8167\n",
      "reconstruction loss = 0.0420, similarity loss: 0.5817\n",
      "Epoch 3, loss = 0.7666, time: 16.7539\n",
      "reconstruction loss = 0.0412, similarity loss: 0.5607\n",
      "Epoch 4, loss = 0.6793, time: 16.7686\n",
      "reconstruction loss = 0.0349, similarity loss: 0.5049\n",
      "Epoch 5, loss = 0.6993, time: 16.7349\n",
      "reconstruction loss = 0.0398, similarity loss: 0.5002\n",
      "Epoch 6, loss = 0.6201, time: 16.7173\n",
      "reconstruction loss = 0.0354, similarity loss: 0.4430\n",
      "Epoch 7, loss = 0.5716, time: 16.7235\n",
      "reconstruction loss = 0.0309, similarity loss: 0.4172\n",
      "Epoch 8, loss = 0.5138, time: 16.7914\n",
      "reconstruction loss = 0.0277, similarity loss: 0.3751\n",
      "Epoch 9, loss = 0.5485, time: 16.8112\n",
      "reconstruction loss = 0.0269, similarity loss: 0.4142\n",
      "Epoch 10, loss = 0.4982, time: 16.7979\n",
      "reconstruction loss = 0.0302, similarity loss: 0.3474\n",
      "Epoch 11, loss = 0.4373, time: 16.6903\n",
      "reconstruction loss = 0.0263, similarity loss: 0.3058\n",
      "Epoch 12, loss = 0.5319, time: 16.8472\n",
      "reconstruction loss = 0.0292, similarity loss: 0.3860\n",
      "Epoch 13, loss = 0.4367, time: 16.7369\n",
      "reconstruction loss = 0.0240, similarity loss: 0.3167\n",
      "Epoch 14, loss = 0.4588, time: 16.7315\n",
      "reconstruction loss = 0.0256, similarity loss: 0.3306\n",
      "Epoch 15, loss = 0.4537, time: 16.7578\n",
      "reconstruction loss = 0.0256, similarity loss: 0.3257\n",
      "Epoch 16, loss = 0.4282, time: 16.8189\n",
      "reconstruction loss = 0.0253, similarity loss: 0.3017\n",
      "Epoch 17, loss = 0.3893, time: 16.4567\n",
      "reconstruction loss = 0.0247, similarity loss: 0.2660\n",
      "Epoch 18, loss = 0.4680, time: 16.2331\n",
      "reconstruction loss = 0.0237, similarity loss: 0.3495\n",
      "Epoch 19, loss = 0.4103, time: 16.2187\n",
      "reconstruction loss = 0.0209, similarity loss: 0.3058\n",
      "Epoch 20, loss = 0.4192, time: 16.2196\n",
      "reconstruction loss = 0.0211, similarity loss: 0.3135\n",
      "Epoch 21, loss = 0.4155, time: 16.1476\n",
      "reconstruction loss = 0.0244, similarity loss: 0.2934\n",
      "Epoch 22, loss = 0.3949, time: 16.2378\n",
      "reconstruction loss = 0.0226, similarity loss: 0.2821\n",
      "Epoch 23, loss = 0.3908, time: 16.2707\n",
      "reconstruction loss = 0.0240, similarity loss: 0.2708\n",
      "Epoch 24, loss = 0.4009, time: 16.1988\n",
      "reconstruction loss = 0.0213, similarity loss: 0.2945\n",
      "Epoch 25, loss = 0.4036, time: 16.2677\n",
      "reconstruction loss = 0.0212, similarity loss: 0.2975\n",
      "Epoch 26, loss = 0.3928, time: 16.1087\n",
      "reconstruction loss = 0.0206, similarity loss: 0.2895\n",
      "Epoch 27, loss = 0.4310, time: 16.1962\n",
      "reconstruction loss = 0.0190, similarity loss: 0.3359\n",
      "Epoch 28, loss = 0.3484, time: 16.3522\n",
      "reconstruction loss = 0.0210, similarity loss: 0.2432\n",
      "Epoch 29, loss = 0.3889, time: 16.8412\n",
      "reconstruction loss = 0.0214, similarity loss: 0.2820\n",
      "Epoch 30, loss = 0.3751, time: 16.7115\n",
      "reconstruction loss = 0.0189, similarity loss: 0.2807\n",
      "Epoch 31, loss = 0.3986, time: 16.7498\n",
      "reconstruction loss = 0.0199, similarity loss: 0.2990\n",
      "Epoch 32, loss = 0.3878, time: 16.8291\n",
      "reconstruction loss = 0.0207, similarity loss: 0.2843\n",
      "Epoch 33, loss = 0.3505, time: 16.8009\n",
      "reconstruction loss = 0.0200, similarity loss: 0.2507\n",
      "Epoch 34, loss = 0.3912, time: 16.6334\n",
      "reconstruction loss = 0.0214, similarity loss: 0.2843\n",
      "Epoch 35, loss = 0.3778, time: 16.5904\n",
      "reconstruction loss = 0.0220, similarity loss: 0.2678\n",
      "Epoch 36, loss = 0.3843, time: 16.7109\n",
      "reconstruction loss = 0.0196, similarity loss: 0.2864\n",
      "Epoch 37, loss = 0.3921, time: 16.6736\n",
      "reconstruction loss = 0.0240, similarity loss: 0.2720\n",
      "Epoch 38, loss = 0.3746, time: 16.6867\n",
      "reconstruction loss = 0.0185, similarity loss: 0.2823\n",
      "Epoch 39, loss = 0.3520, time: 16.8223\n",
      "reconstruction loss = 0.0185, similarity loss: 0.2597\n",
      "Epoch 40, loss = 0.3276, time: 16.8168\n",
      "reconstruction loss = 0.0157, similarity loss: 0.2493\n",
      "Epoch 41, loss = 0.3576, time: 16.7155\n",
      "reconstruction loss = 0.0182, similarity loss: 0.2667\n",
      "Epoch 42, loss = 0.4023, time: 16.6404\n",
      "reconstruction loss = 0.0178, similarity loss: 0.3132\n",
      "Epoch 43, loss = 0.3481, time: 16.7024\n",
      "reconstruction loss = 0.0181, similarity loss: 0.2576\n",
      "Epoch 44, loss = 0.4131, time: 16.6611\n",
      "reconstruction loss = 0.0186, similarity loss: 0.3203\n",
      "Epoch 45, loss = 0.3846, time: 16.6815\n",
      "reconstruction loss = 0.0192, similarity loss: 0.2887\n",
      "Epoch 46, loss = 0.3522, time: 16.6030\n",
      "reconstruction loss = 0.0177, similarity loss: 0.2636\n",
      "Epoch 47, loss = 0.3772, time: 16.6773\n",
      "reconstruction loss = 0.0166, similarity loss: 0.2940\n",
      "Epoch 48, loss = 0.3391, time: 16.7783\n",
      "reconstruction loss = 0.0160, similarity loss: 0.2591\n",
      "Epoch 49, loss = 0.3521, time: 16.6998\n",
      "reconstruction loss = 0.0189, similarity loss: 0.2574\n",
      "Epoch 50, loss = 0.3770, time: 16.6720\n",
      "reconstruction loss = 0.0174, similarity loss: 0.2900\n",
      "Epoch 51, loss = 0.3770, time: 16.7072\n",
      "reconstruction loss = 0.0168, similarity loss: 0.2930\n",
      "Epoch 52, loss = 0.3582, time: 16.7159\n",
      "reconstruction loss = 0.0161, similarity loss: 0.2780\n",
      "Epoch 53, loss = 0.3971, time: 16.6742\n",
      "reconstruction loss = 0.0219, similarity loss: 0.2877\n",
      "Epoch 54, loss = 0.3555, time: 16.6659\n",
      "reconstruction loss = 0.0184, similarity loss: 0.2633\n",
      "Epoch 55, loss = 0.3381, time: 16.7476\n",
      "reconstruction loss = 0.0180, similarity loss: 0.2482\n",
      "Epoch 56, loss = 0.3057, time: 16.7230\n",
      "reconstruction loss = 0.0175, similarity loss: 0.2182\n",
      "Epoch 57, loss = 0.3433, time: 16.7856\n",
      "reconstruction loss = 0.0175, similarity loss: 0.2558\n",
      "Epoch 58, loss = 0.3456, time: 16.7159\n",
      "reconstruction loss = 0.0175, similarity loss: 0.2582\n",
      "Epoch 59, loss = 0.3533, time: 16.6744\n",
      "reconstruction loss = 0.0182, similarity loss: 0.2623\n",
      "Epoch 60, loss = 0.3248, time: 16.7075\n",
      "reconstruction loss = 0.0174, similarity loss: 0.2380\n",
      "Epoch 61, loss = 0.3186, time: 16.8686\n",
      "reconstruction loss = 0.0153, similarity loss: 0.2420\n",
      "Epoch 62, loss = 0.3671, time: 16.9179\n",
      "reconstruction loss = 0.0196, similarity loss: 0.2689\n",
      "Epoch 63, loss = 0.3492, time: 16.7317\n",
      "reconstruction loss = 0.0166, similarity loss: 0.2664\n",
      "Epoch 64, loss = 0.3425, time: 16.4603\n",
      "reconstruction loss = 0.0169, similarity loss: 0.2579\n",
      "Epoch 65, loss = 0.3263, time: 16.2039\n",
      "reconstruction loss = 0.0162, similarity loss: 0.2452\n",
      "Epoch 66, loss = 0.3299, time: 16.1081\n",
      "reconstruction loss = 0.0181, similarity loss: 0.2394\n",
      "Epoch 67, loss = 0.3209, time: 16.1237\n",
      "reconstruction loss = 0.0156, similarity loss: 0.2429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.3117, time: 16.1072\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2356\n",
      "Epoch 69, loss = 0.3241, time: 16.2189\n",
      "reconstruction loss = 0.0167, similarity loss: 0.2408\n",
      "Epoch 70, loss = 0.3187, time: 16.1210\n",
      "reconstruction loss = 0.0154, similarity loss: 0.2417\n",
      "Epoch 71, loss = 0.3373, time: 16.0565\n",
      "reconstruction loss = 0.0151, similarity loss: 0.2620\n",
      "Epoch 72, loss = 0.3580, time: 16.2377\n",
      "reconstruction loss = 0.0177, similarity loss: 0.2697\n",
      "Epoch 73, loss = 0.3265, time: 16.1650\n",
      "reconstruction loss = 0.0157, similarity loss: 0.2478\n",
      "Epoch 74, loss = 0.3412, time: 16.0947\n",
      "reconstruction loss = 0.0174, similarity loss: 0.2543\n",
      "Epoch 75, loss = 0.3335, time: 16.1387\n",
      "reconstruction loss = 0.0175, similarity loss: 0.2460\n",
      "Epoch 76, loss = 0.3000, time: 16.2158\n",
      "reconstruction loss = 0.0156, similarity loss: 0.2223\n",
      "Epoch 77, loss = 0.3493, time: 16.1222\n",
      "reconstruction loss = 0.0160, similarity loss: 0.2690\n",
      "Epoch 78, loss = 0.3271, time: 16.2087\n",
      "reconstruction loss = 0.0160, similarity loss: 0.2470\n",
      "Epoch 79, loss = 0.2863, time: 16.1837\n",
      "reconstruction loss = 0.0155, similarity loss: 0.2089\n",
      "Epoch 80, loss = 0.3427, time: 16.1454\n",
      "reconstruction loss = 0.0163, similarity loss: 0.2611\n",
      "Epoch 81, loss = 0.3752, time: 16.1650\n",
      "reconstruction loss = 0.0213, similarity loss: 0.2689\n",
      "Epoch 82, loss = 0.3214, time: 16.1357\n",
      "reconstruction loss = 0.0149, similarity loss: 0.2470\n",
      "Epoch 83, loss = 0.3070, time: 16.0880\n",
      "reconstruction loss = 0.0155, similarity loss: 0.2296\n",
      "Epoch 84, loss = 0.3040, time: 16.1608\n",
      "reconstruction loss = 0.0139, similarity loss: 0.2345\n",
      "Epoch 85, loss = 0.3274, time: 16.1179\n",
      "reconstruction loss = 0.0155, similarity loss: 0.2498\n",
      "Epoch 86, loss = 0.3404, time: 16.1497\n",
      "reconstruction loss = 0.0153, similarity loss: 0.2639\n",
      "Epoch 87, loss = 0.3329, time: 16.2843\n",
      "reconstruction loss = 0.0138, similarity loss: 0.2637\n",
      "Epoch 88, loss = 0.3320, time: 16.1058\n",
      "reconstruction loss = 0.0156, similarity loss: 0.2538\n",
      "Epoch 89, loss = 0.3041, time: 16.1235\n",
      "reconstruction loss = 0.0155, similarity loss: 0.2266\n",
      "Epoch 90, loss = 0.3142, time: 16.5067\n",
      "reconstruction loss = 0.0163, similarity loss: 0.2328\n",
      "Epoch 91, loss = 0.3386, time: 16.7438\n",
      "reconstruction loss = 0.0165, similarity loss: 0.2559\n",
      "Epoch 92, loss = 0.2987, time: 16.8571\n",
      "reconstruction loss = 0.0157, similarity loss: 0.2204\n",
      "Epoch 93, loss = 0.3152, time: 16.7933\n",
      "reconstruction loss = 0.0148, similarity loss: 0.2412\n",
      "Epoch 94, loss = 0.3462, time: 16.8492\n",
      "reconstruction loss = 0.0171, similarity loss: 0.2605\n",
      "Epoch 95, loss = 0.2849, time: 16.8789\n",
      "reconstruction loss = 0.0145, similarity loss: 0.2125\n",
      "Epoch 96, loss = 0.3312, time: 16.8005\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2554\n",
      "Epoch 97, loss = 0.2985, time: 16.7538\n",
      "reconstruction loss = 0.0151, similarity loss: 0.2228\n",
      "Epoch 98, loss = 0.3085, time: 16.6652\n",
      "reconstruction loss = 0.0147, similarity loss: 0.2349\n",
      "Epoch 99, loss = 0.3415, time: 16.6679\n",
      "reconstruction loss = 0.0167, similarity loss: 0.2581\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.9983, val.loss = 1.7353, val.acc = 0.4268\n",
      "Epoch 1, loss = 1.6417, val.loss = 1.5639, val.acc = 0.4856\n",
      "Epoch 2, loss = 1.5110, val.loss = 1.4732, val.acc = 0.5140\n",
      "Epoch 3, loss = 1.4314, val.loss = 1.4138, val.acc = 0.5342\n",
      "Epoch 4, loss = 1.3750, val.loss = 1.3708, val.acc = 0.5478\n",
      "Epoch 5, loss = 1.3318, val.loss = 1.3379, val.acc = 0.5570\n",
      "Epoch 6, loss = 1.2970, val.loss = 1.3116, val.acc = 0.5650\n",
      "Epoch 7, loss = 1.2679, val.loss = 1.2901, val.acc = 0.5702\n",
      "Epoch 8, loss = 1.2429, val.loss = 1.2719, val.acc = 0.5790\n",
      "Epoch 9, loss = 1.2210, val.loss = 1.2564, val.acc = 0.5808\n",
      "Epoch 10, loss = 1.2014, val.loss = 1.2429, val.acc = 0.5846\n",
      "Epoch 11, loss = 1.1838, val.loss = 1.2311, val.acc = 0.5868\n",
      "Epoch 12, loss = 1.1677, val.loss = 1.2205, val.acc = 0.5898\n",
      "Epoch 13, loss = 1.1529, val.loss = 1.2111, val.acc = 0.5918\n",
      "Epoch 14, loss = 1.1391, val.loss = 1.2025, val.acc = 0.5952\n",
      "Epoch 15, loss = 1.1262, val.loss = 1.1948, val.acc = 0.5976\n",
      "Epoch 16, loss = 1.1142, val.loss = 1.1877, val.acc = 0.5986\n",
      "Epoch 17, loss = 1.1028, val.loss = 1.1812, val.acc = 0.6006\n",
      "Epoch 18, loss = 1.0920, val.loss = 1.1752, val.acc = 0.6020\n",
      "Epoch 19, loss = 1.0818, val.loss = 1.1696, val.acc = 0.6046\n",
      "Epoch 20, loss = 1.0720, val.loss = 1.1644, val.acc = 0.6068\n",
      "Epoch 21, loss = 1.0627, val.loss = 1.1596, val.acc = 0.6072\n",
      "Epoch 22, loss = 1.0538, val.loss = 1.1552, val.acc = 0.6074\n",
      "Epoch 23, loss = 1.0452, val.loss = 1.1510, val.acc = 0.6096\n",
      "Epoch 24, loss = 1.0370, val.loss = 1.1470, val.acc = 0.6116\n",
      "Epoch 25, loss = 1.0290, val.loss = 1.1434, val.acc = 0.6136\n",
      "Epoch 26, loss = 1.0214, val.loss = 1.1399, val.acc = 0.6144\n",
      "Epoch 27, loss = 1.0140, val.loss = 1.1367, val.acc = 0.6158\n",
      "Epoch 28, loss = 1.0068, val.loss = 1.1336, val.acc = 0.6158\n",
      "Epoch 29, loss = 0.9999, val.loss = 1.1307, val.acc = 0.6180\n",
      "Epoch 30, loss = 0.9932, val.loss = 1.1280, val.acc = 0.6196\n",
      "Epoch 31, loss = 0.9867, val.loss = 1.1254, val.acc = 0.6210\n",
      "Epoch 32, loss = 0.9803, val.loss = 1.1230, val.acc = 0.6224\n",
      "Epoch 33, loss = 0.9742, val.loss = 1.1207, val.acc = 0.6224\n",
      "Epoch 34, loss = 0.9682, val.loss = 1.1185, val.acc = 0.6228\n",
      "Epoch 35, loss = 0.9624, val.loss = 1.1164, val.acc = 0.6222\n",
      "Epoch 36, loss = 0.9567, val.loss = 1.1144, val.acc = 0.6222\n",
      "Epoch 37, loss = 0.9511, val.loss = 1.1126, val.acc = 0.6226\n",
      "Epoch 38, loss = 0.9457, val.loss = 1.1108, val.acc = 0.6238\n",
      "Epoch 39, loss = 0.9404, val.loss = 1.1091, val.acc = 0.6240\n",
      "Epoch 40, loss = 0.9352, val.loss = 1.1076, val.acc = 0.6256\n",
      "Epoch 41, loss = 0.9302, val.loss = 1.1060, val.acc = 0.6256\n",
      "Epoch 42, loss = 0.9252, val.loss = 1.1046, val.acc = 0.6268\n",
      "Epoch 43, loss = 0.9204, val.loss = 1.1032, val.acc = 0.6274\n",
      "Epoch 44, loss = 0.9156, val.loss = 1.1020, val.acc = 0.6278\n",
      "Epoch 45, loss = 0.9110, val.loss = 1.1007, val.acc = 0.6278\n",
      "Epoch 46, loss = 0.9064, val.loss = 1.0996, val.acc = 0.6278\n",
      "Epoch 47, loss = 0.9020, val.loss = 1.0985, val.acc = 0.6296\n",
      "Epoch 48, loss = 0.8976, val.loss = 1.0974, val.acc = 0.6304\n",
      "Epoch 49, loss = 0.8933, val.loss = 1.0964, val.acc = 0.6308\n",
      "Epoch 50, loss = 0.8890, val.loss = 1.0955, val.acc = 0.6306\n",
      "Epoch 51, loss = 0.8849, val.loss = 1.0946, val.acc = 0.6312\n",
      "Epoch 52, loss = 0.8808, val.loss = 1.0938, val.acc = 0.6312\n",
      "Epoch 53, loss = 0.8768, val.loss = 1.0929, val.acc = 0.6320\n",
      "Epoch 54, loss = 0.8729, val.loss = 1.0922, val.acc = 0.6320\n",
      "Epoch 55, loss = 0.8690, val.loss = 1.0915, val.acc = 0.6312\n",
      "Epoch 56, loss = 0.8652, val.loss = 1.0908, val.acc = 0.6314\n",
      "Epoch 57, loss = 0.8614, val.loss = 1.0902, val.acc = 0.6312\n",
      "Epoch 58, loss = 0.8577, val.loss = 1.0896, val.acc = 0.6314\n",
      "Epoch 59, loss = 0.8541, val.loss = 1.0890, val.acc = 0.6316\n",
      "Epoch 60, loss = 0.8505, val.loss = 1.0885, val.acc = 0.6318\n",
      "Epoch 61, loss = 0.8470, val.loss = 1.0880, val.acc = 0.6322\n",
      "Epoch 62, loss = 0.8435, val.loss = 1.0875, val.acc = 0.6324\n",
      "Epoch 63, loss = 0.8401, val.loss = 1.0871, val.acc = 0.6322\n",
      "Epoch 64, loss = 0.8367, val.loss = 1.0867, val.acc = 0.6318\n",
      "Epoch 65, loss = 0.8334, val.loss = 1.0863, val.acc = 0.6324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.8301, val.loss = 1.0860, val.acc = 0.6324\n",
      "Epoch 67, loss = 0.8269, val.loss = 1.0856, val.acc = 0.6322\n",
      "Epoch 68, loss = 0.8237, val.loss = 1.0853, val.acc = 0.6324\n",
      "Epoch 69, loss = 0.8205, val.loss = 1.0850, val.acc = 0.6322\n",
      "Epoch 70, loss = 0.8174, val.loss = 1.0848, val.acc = 0.6322\n",
      "Epoch 71, loss = 0.8144, val.loss = 1.0846, val.acc = 0.6328\n",
      "Epoch 72, loss = 0.8113, val.loss = 1.0843, val.acc = 0.6334\n",
      "Epoch 73, loss = 0.8084, val.loss = 1.0842, val.acc = 0.6338\n",
      "Epoch 74, loss = 0.8054, val.loss = 1.0840, val.acc = 0.6336\n",
      "Epoch 75, loss = 0.8025, val.loss = 1.0839, val.acc = 0.6340\n",
      "Epoch 76, loss = 0.7996, val.loss = 1.0837, val.acc = 0.6344\n",
      "Epoch 77, loss = 0.7968, val.loss = 1.0836, val.acc = 0.6340\n",
      "Epoch 78, loss = 0.7940, val.loss = 1.0835, val.acc = 0.6342\n",
      "Epoch 79, loss = 0.7912, val.loss = 1.0835, val.acc = 0.6346\n",
      "Epoch 80, loss = 0.7884, val.loss = 1.0834, val.acc = 0.6350\n",
      "Epoch 81, loss = 0.7857, val.loss = 1.0834, val.acc = 0.6356\n",
      "Epoch 82, loss = 0.7830, val.loss = 1.0833, val.acc = 0.6354\n",
      "Epoch 83, loss = 0.7804, val.loss = 1.0833, val.acc = 0.6360\n",
      "Epoch 84, loss = 0.7778, val.loss = 1.0834, val.acc = 0.6354\n",
      "Epoch 85, loss = 0.7752, val.loss = 1.0834, val.acc = 0.6362\n",
      "Epoch 86, loss = 0.7726, val.loss = 1.0834, val.acc = 0.6366\n",
      "Epoch 87, loss = 0.7701, val.loss = 1.0835, val.acc = 0.6366\n",
      "Epoch 88, loss = 0.7675, val.loss = 1.0835, val.acc = 0.6362\n",
      "Epoch 89, loss = 0.7651, val.loss = 1.0836, val.acc = 0.6358\n",
      "Epoch 90, loss = 0.7626, val.loss = 1.0837, val.acc = 0.6362\n",
      "Epoch 91, loss = 0.7602, val.loss = 1.0838, val.acc = 0.6360\n",
      "Epoch 92, loss = 0.7578, val.loss = 1.0839, val.acc = 0.6358\n",
      "Epoch 93, loss = 0.7554, val.loss = 1.0840, val.acc = 0.6352\n",
      "Epoch 94, loss = 0.7530, val.loss = 1.0842, val.acc = 0.6350\n",
      "Epoch 95, loss = 0.7507, val.loss = 1.0843, val.acc = 0.6354\n",
      "Epoch 96, loss = 0.7484, val.loss = 1.0845, val.acc = 0.6350\n",
      "Epoch 97, loss = 0.7461, val.loss = 1.0847, val.acc = 0.6348\n",
      "Epoch 98, loss = 0.7438, val.loss = 1.0849, val.acc = 0.6346\n",
      "Epoch 99, loss = 0.7416, val.loss = 1.0850, val.acc = 0.6346\n",
      "Epoch 100, loss = 0.7393, val.loss = 1.0853, val.acc = 0.6348\n",
      "Epoch 101, loss = 0.7371, val.loss = 1.0855, val.acc = 0.6344\n",
      "Epoch 102, loss = 0.7349, val.loss = 1.0857, val.acc = 0.6352\n",
      "Epoch 103, loss = 0.7328, val.loss = 1.0859, val.acc = 0.6346\n",
      "Epoch 104, loss = 0.7306, val.loss = 1.0861, val.acc = 0.6344\n",
      "Epoch 105, loss = 0.7285, val.loss = 1.0864, val.acc = 0.6346\n",
      "Epoch 106, loss = 0.7264, val.loss = 1.0866, val.acc = 0.6346\n",
      "Epoch 107, loss = 0.7243, val.loss = 1.0869, val.acc = 0.6348\n",
      "Epoch 108, loss = 0.7222, val.loss = 1.0872, val.acc = 0.6342\n",
      "Epoch 109, loss = 0.7202, val.loss = 1.0875, val.acc = 0.6344\n",
      "Epoch 110, loss = 0.7181, val.loss = 1.0877, val.acc = 0.6334\n",
      "Epoch 111, loss = 0.7161, val.loss = 1.0880, val.acc = 0.6334\n",
      "Epoch 112, loss = 0.7141, val.loss = 1.0883, val.acc = 0.6338\n",
      "Epoch 113, loss = 0.7121, val.loss = 1.0886, val.acc = 0.6336\n",
      "Epoch 114, loss = 0.7102, val.loss = 1.0890, val.acc = 0.6336\n",
      "Epoch 115, loss = 0.7082, val.loss = 1.0893, val.acc = 0.6344\n",
      "Epoch 116, loss = 0.7063, val.loss = 1.0896, val.acc = 0.6340\n",
      "Epoch 117, loss = 0.7044, val.loss = 1.0899, val.acc = 0.6336\n",
      "Epoch 118, loss = 0.7025, val.loss = 1.0903, val.acc = 0.6334\n",
      "Epoch 119, loss = 0.7006, val.loss = 1.0906, val.acc = 0.6336\n",
      "Epoch 120, loss = 0.6987, val.loss = 1.0910, val.acc = 0.6334\n",
      "Epoch 121, loss = 0.6969, val.loss = 1.0913, val.acc = 0.6334\n",
      "Epoch 122, loss = 0.6950, val.loss = 1.0917, val.acc = 0.6336\n",
      "Epoch 123, loss = 0.6932, val.loss = 1.0921, val.acc = 0.6336\n",
      "Epoch 124, loss = 0.6914, val.loss = 1.0925, val.acc = 0.6336\n",
      "Epoch 125, loss = 0.6896, val.loss = 1.0928, val.acc = 0.6338\n",
      "Epoch 126, loss = 0.6878, val.loss = 1.0932, val.acc = 0.6340\n",
      "Epoch 127, loss = 0.6860, val.loss = 1.0936, val.acc = 0.6340\n",
      "Epoch 128, loss = 0.6843, val.loss = 1.0940, val.acc = 0.6338\n",
      "Epoch 129, loss = 0.6825, val.loss = 1.0944, val.acc = 0.6342\n",
      "Epoch 130, loss = 0.6808, val.loss = 1.0948, val.acc = 0.6348\n",
      "Epoch 131, loss = 0.6791, val.loss = 1.0952, val.acc = 0.6352\n",
      "Epoch 132, loss = 0.6774, val.loss = 1.0957, val.acc = 0.6346\n",
      "Epoch 133, loss = 0.6757, val.loss = 1.0961, val.acc = 0.6348\n",
      "Epoch 134, loss = 0.6740, val.loss = 1.0965, val.acc = 0.6348\n",
      "Epoch 135, loss = 0.6723, val.loss = 1.0969, val.acc = 0.6346\n",
      "Epoch 136, loss = 0.6706, val.loss = 1.0973, val.acc = 0.6346\n",
      "Epoch 137, loss = 0.6690, val.loss = 1.0978, val.acc = 0.6344\n",
      "Epoch 138, loss = 0.6674, val.loss = 1.0982, val.acc = 0.6346\n",
      "Epoch 139, loss = 0.6657, val.loss = 1.0987, val.acc = 0.6348\n",
      "Epoch 140, loss = 0.6641, val.loss = 1.0991, val.acc = 0.6348\n",
      "Epoch 141, loss = 0.6625, val.loss = 1.0996, val.acc = 0.6346\n",
      "Epoch 142, loss = 0.6609, val.loss = 1.1000, val.acc = 0.6348\n",
      "Epoch 143, loss = 0.6593, val.loss = 1.1005, val.acc = 0.6346\n",
      "Epoch 144, loss = 0.6578, val.loss = 1.1010, val.acc = 0.6344\n",
      "Epoch 145, loss = 0.6562, val.loss = 1.1015, val.acc = 0.6344\n",
      "Epoch 146, loss = 0.6547, val.loss = 1.1019, val.acc = 0.6346\n",
      "Epoch 147, loss = 0.6531, val.loss = 1.1024, val.acc = 0.6348\n",
      "Epoch 148, loss = 0.6516, val.loss = 1.1029, val.acc = 0.6344\n",
      "Epoch 149, loss = 0.6501, val.loss = 1.1033, val.acc = 0.6344\n",
      "Rep: 1, te.acc = 0.6171\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6171]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 5\n",
    "vis = visdom.Visdom(port=8097,env='ae_2l_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T07:12:42.621036Z",
     "start_time": "2022-04-02T06:40:47.634678Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_3/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_10_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(3, 32, 32))\n",
      "    (deconv): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.2851, time: 16.9509\n",
      "reconstruction loss = 0.0595, similarity loss: 0.6897\n",
      "Epoch 1, loss = 1.0052, time: 16.8189\n",
      "reconstruction loss = 0.0406, similarity loss: 0.5994\n",
      "Epoch 2, loss = 0.9385, time: 16.9150\n",
      "reconstruction loss = 0.0364, similarity loss: 0.5746\n",
      "Epoch 3, loss = 0.9584, time: 16.7967\n",
      "reconstruction loss = 0.0299, similarity loss: 0.6593\n",
      "Epoch 4, loss = 0.8362, time: 16.8130\n",
      "reconstruction loss = 0.0278, similarity loss: 0.5577\n",
      "Epoch 5, loss = 0.8048, time: 16.7666\n",
      "reconstruction loss = 0.0260, similarity loss: 0.5448\n",
      "Epoch 6, loss = 0.6390, time: 16.8126\n",
      "reconstruction loss = 0.0238, similarity loss: 0.4007\n",
      "Epoch 7, loss = 0.6672, time: 16.8726\n",
      "reconstruction loss = 0.0238, similarity loss: 0.4293\n",
      "Epoch 8, loss = 0.6793, time: 16.8152\n",
      "reconstruction loss = 0.0233, similarity loss: 0.4460\n",
      "Epoch 9, loss = 0.5558, time: 16.8487\n",
      "reconstruction loss = 0.0208, similarity loss: 0.3481\n",
      "Epoch 10, loss = 0.5951, time: 16.7202\n",
      "reconstruction loss = 0.0221, similarity loss: 0.3739\n",
      "Epoch 11, loss = 0.5787, time: 16.1024\n",
      "reconstruction loss = 0.0214, similarity loss: 0.3648\n",
      "Epoch 12, loss = 0.5256, time: 16.1701\n",
      "reconstruction loss = 0.0178, similarity loss: 0.3477\n",
      "Epoch 13, loss = 0.5977, time: 16.1930\n",
      "reconstruction loss = 0.0226, similarity loss: 0.3720\n",
      "Epoch 14, loss = 0.5313, time: 16.1272\n",
      "reconstruction loss = 0.0187, similarity loss: 0.3438\n",
      "Epoch 15, loss = 0.5451, time: 16.0750\n",
      "reconstruction loss = 0.0212, similarity loss: 0.3330\n",
      "Epoch 16, loss = 0.5255, time: 16.2827\n",
      "reconstruction loss = 0.0201, similarity loss: 0.3246\n",
      "Epoch 17, loss = 0.5405, time: 16.2693\n",
      "reconstruction loss = 0.0210, similarity loss: 0.3304\n",
      "Epoch 18, loss = 0.5213, time: 16.2862\n",
      "reconstruction loss = 0.0192, similarity loss: 0.3291\n",
      "Epoch 19, loss = 0.5261, time: 16.1749\n",
      "reconstruction loss = 0.0207, similarity loss: 0.3190\n",
      "Epoch 20, loss = 0.4287, time: 16.0831\n",
      "reconstruction loss = 0.0175, similarity loss: 0.2541\n",
      "Epoch 21, loss = 0.4727, time: 16.1116\n",
      "reconstruction loss = 0.0182, similarity loss: 0.2912\n",
      "Epoch 22, loss = 0.4957, time: 16.2275\n",
      "reconstruction loss = 0.0184, similarity loss: 0.3113\n",
      "Epoch 23, loss = 0.5164, time: 16.1297\n",
      "reconstruction loss = 0.0181, similarity loss: 0.3352\n",
      "Epoch 24, loss = 0.4836, time: 16.0924\n",
      "reconstruction loss = 0.0194, similarity loss: 0.2900\n",
      "Epoch 25, loss = 0.4469, time: 16.2034\n",
      "reconstruction loss = 0.0169, similarity loss: 0.2775\n",
      "Epoch 26, loss = 0.4767, time: 16.2919\n",
      "reconstruction loss = 0.0170, similarity loss: 0.3066\n",
      "Epoch 27, loss = 0.4564, time: 15.9889\n",
      "reconstruction loss = 0.0172, similarity loss: 0.2844\n",
      "Epoch 28, loss = 0.4564, time: 16.0877\n",
      "reconstruction loss = 0.0182, similarity loss: 0.2741\n",
      "Epoch 29, loss = 0.4452, time: 16.4886\n",
      "reconstruction loss = 0.0167, similarity loss: 0.2778\n",
      "Epoch 30, loss = 0.4269, time: 16.6506\n",
      "reconstruction loss = 0.0171, similarity loss: 0.2562\n",
      "Epoch 31, loss = 0.4460, time: 16.6568\n",
      "reconstruction loss = 0.0148, similarity loss: 0.2977\n",
      "Epoch 32, loss = 0.4802, time: 16.7593\n",
      "reconstruction loss = 0.0186, similarity loss: 0.2941\n",
      "Epoch 33, loss = 0.4847, time: 16.8565\n",
      "reconstruction loss = 0.0180, similarity loss: 0.3052\n",
      "Epoch 34, loss = 0.4491, time: 16.7596\n",
      "reconstruction loss = 0.0174, similarity loss: 0.2751\n",
      "Epoch 35, loss = 0.4233, time: 16.6659\n",
      "reconstruction loss = 0.0168, similarity loss: 0.2551\n",
      "Epoch 36, loss = 0.4579, time: 16.7456\n",
      "reconstruction loss = 0.0164, similarity loss: 0.2943\n",
      "Epoch 37, loss = 0.5121, time: 16.7003\n",
      "reconstruction loss = 0.0174, similarity loss: 0.3382\n",
      "Epoch 38, loss = 0.4333, time: 16.8179\n",
      "reconstruction loss = 0.0183, similarity loss: 0.2505\n",
      "Epoch 39, loss = 0.4454, time: 16.8643\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2935\n",
      "Epoch 40, loss = 0.4323, time: 16.8845\n",
      "reconstruction loss = 0.0156, similarity loss: 0.2759\n",
      "Epoch 41, loss = 0.4189, time: 16.7537\n",
      "reconstruction loss = 0.0151, similarity loss: 0.2682\n",
      "Epoch 42, loss = 0.4313, time: 16.7655\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2798\n",
      "Epoch 43, loss = 0.5032, time: 16.7563\n",
      "reconstruction loss = 0.0173, similarity loss: 0.3303\n",
      "Epoch 44, loss = 0.4311, time: 16.7421\n",
      "reconstruction loss = 0.0164, similarity loss: 0.2673\n",
      "Epoch 45, loss = 0.4198, time: 16.7754\n",
      "reconstruction loss = 0.0151, similarity loss: 0.2684\n",
      "Epoch 46, loss = 0.4022, time: 16.7102\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2498\n",
      "Epoch 47, loss = 0.4203, time: 16.7858\n",
      "reconstruction loss = 0.0163, similarity loss: 0.2578\n",
      "Epoch 48, loss = 0.3993, time: 16.8359\n",
      "reconstruction loss = 0.0144, similarity loss: 0.2553\n",
      "Epoch 49, loss = 0.4104, time: 16.7761\n",
      "reconstruction loss = 0.0145, similarity loss: 0.2654\n",
      "Epoch 50, loss = 0.4650, time: 16.7962\n",
      "reconstruction loss = 0.0171, similarity loss: 0.2939\n",
      "Epoch 51, loss = 0.4444, time: 16.7767\n",
      "reconstruction loss = 0.0176, similarity loss: 0.2685\n",
      "Epoch 52, loss = 0.3919, time: 16.7367\n",
      "reconstruction loss = 0.0145, similarity loss: 0.2467\n",
      "Epoch 53, loss = 0.4072, time: 16.6973\n",
      "reconstruction loss = 0.0150, similarity loss: 0.2568\n",
      "Epoch 54, loss = 0.4149, time: 16.7094\n",
      "reconstruction loss = 0.0147, similarity loss: 0.2677\n",
      "Epoch 55, loss = 0.4261, time: 16.6904\n",
      "reconstruction loss = 0.0158, similarity loss: 0.2686\n",
      "Epoch 56, loss = 0.3963, time: 16.6667\n",
      "reconstruction loss = 0.0141, similarity loss: 0.2552\n",
      "Epoch 57, loss = 0.4052, time: 16.7961\n",
      "reconstruction loss = 0.0147, similarity loss: 0.2582\n",
      "Epoch 58, loss = 0.3724, time: 17.1065\n",
      "reconstruction loss = 0.0146, similarity loss: 0.2267\n",
      "Epoch 59, loss = 0.4065, time: 16.8231\n",
      "reconstruction loss = 0.0140, similarity loss: 0.2660\n",
      "Epoch 60, loss = 0.4131, time: 16.6740\n",
      "reconstruction loss = 0.0136, similarity loss: 0.2775\n",
      "Epoch 61, loss = 0.4067, time: 16.7214\n",
      "reconstruction loss = 0.0151, similarity loss: 0.2559\n",
      "Epoch 62, loss = 0.3831, time: 16.6674\n",
      "reconstruction loss = 0.0134, similarity loss: 0.2491\n",
      "Epoch 63, loss = 0.4233, time: 16.6546\n",
      "reconstruction loss = 0.0143, similarity loss: 0.2802\n",
      "Epoch 64, loss = 0.4289, time: 17.2590\n",
      "reconstruction loss = 0.0142, similarity loss: 0.2873\n",
      "Epoch 65, loss = 0.4064, time: 16.7819\n",
      "reconstruction loss = 0.0158, similarity loss: 0.2481\n",
      "Epoch 66, loss = 0.3966, time: 16.7990\n",
      "reconstruction loss = 0.0144, similarity loss: 0.2526\n",
      "Epoch 67, loss = 0.4016, time: 16.4906\n",
      "reconstruction loss = 0.0131, similarity loss: 0.2703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.3839, time: 16.1613\n",
      "reconstruction loss = 0.0141, similarity loss: 0.2434\n",
      "Epoch 69, loss = 0.3992, time: 16.2017\n",
      "reconstruction loss = 0.0144, similarity loss: 0.2553\n",
      "Epoch 70, loss = 0.3699, time: 16.0370\n",
      "reconstruction loss = 0.0134, similarity loss: 0.2363\n",
      "Epoch 71, loss = 0.3951, time: 16.1445\n",
      "reconstruction loss = 0.0135, similarity loss: 0.2599\n",
      "Epoch 72, loss = 0.4081, time: 16.2980\n",
      "reconstruction loss = 0.0142, similarity loss: 0.2663\n",
      "Epoch 73, loss = 0.3973, time: 16.1157\n",
      "reconstruction loss = 0.0133, similarity loss: 0.2643\n",
      "Epoch 74, loss = 0.4065, time: 16.0675\n",
      "reconstruction loss = 0.0157, similarity loss: 0.2500\n",
      "Epoch 75, loss = 0.3852, time: 16.1705\n",
      "reconstruction loss = 0.0136, similarity loss: 0.2495\n",
      "Epoch 76, loss = 0.4152, time: 16.1131\n",
      "reconstruction loss = 0.0154, similarity loss: 0.2610\n",
      "Epoch 77, loss = 0.3953, time: 16.2677\n",
      "reconstruction loss = 0.0132, similarity loss: 0.2635\n",
      "Epoch 78, loss = 0.4023, time: 16.2866\n",
      "reconstruction loss = 0.0134, similarity loss: 0.2683\n",
      "Epoch 79, loss = 0.4285, time: 16.1394\n",
      "reconstruction loss = 0.0156, similarity loss: 0.2724\n",
      "Epoch 80, loss = 0.3496, time: 16.2604\n",
      "reconstruction loss = 0.0126, similarity loss: 0.2237\n",
      "Epoch 81, loss = 0.3871, time: 16.0717\n",
      "reconstruction loss = 0.0139, similarity loss: 0.2484\n",
      "Epoch 82, loss = 0.3686, time: 16.1139\n",
      "reconstruction loss = 0.0124, similarity loss: 0.2449\n",
      "Epoch 83, loss = 0.3797, time: 16.5250\n",
      "reconstruction loss = 0.0126, similarity loss: 0.2537\n",
      "Epoch 84, loss = 0.3923, time: 16.7964\n",
      "reconstruction loss = 0.0133, similarity loss: 0.2596\n",
      "Epoch 85, loss = 0.3708, time: 16.8418\n",
      "reconstruction loss = 0.0131, similarity loss: 0.2401\n",
      "Epoch 86, loss = 0.3548, time: 16.7267\n",
      "reconstruction loss = 0.0117, similarity loss: 0.2378\n",
      "Epoch 87, loss = 0.3833, time: 16.8481\n",
      "reconstruction loss = 0.0130, similarity loss: 0.2530\n",
      "Epoch 88, loss = 0.3688, time: 16.9004\n",
      "reconstruction loss = 0.0122, similarity loss: 0.2465\n",
      "Epoch 89, loss = 0.3809, time: 16.7912\n",
      "reconstruction loss = 0.0121, similarity loss: 0.2595\n",
      "Epoch 90, loss = 0.3783, time: 16.7678\n",
      "reconstruction loss = 0.0125, similarity loss: 0.2529\n",
      "Epoch 91, loss = 0.3599, time: 16.9043\n",
      "reconstruction loss = 0.0122, similarity loss: 0.2376\n",
      "Epoch 92, loss = 0.3497, time: 16.7362\n",
      "reconstruction loss = 0.0115, similarity loss: 0.2346\n",
      "Epoch 93, loss = 0.3529, time: 16.6796\n",
      "reconstruction loss = 0.0122, similarity loss: 0.2309\n",
      "Epoch 94, loss = 0.3589, time: 16.6683\n",
      "reconstruction loss = 0.0110, similarity loss: 0.2485\n",
      "Epoch 95, loss = 0.3244, time: 16.8104\n",
      "reconstruction loss = 0.0107, similarity loss: 0.2178\n",
      "Epoch 96, loss = 0.3786, time: 16.6296\n",
      "reconstruction loss = 0.0113, similarity loss: 0.2652\n",
      "Epoch 97, loss = 0.3817, time: 16.6757\n",
      "reconstruction loss = 0.0114, similarity loss: 0.2681\n",
      "Epoch 98, loss = 0.3332, time: 16.6220\n",
      "reconstruction loss = 0.0103, similarity loss: 0.2301\n",
      "Epoch 99, loss = 0.3564, time: 16.7413\n",
      "reconstruction loss = 0.0109, similarity loss: 0.2476\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.9365, val.loss = 1.6745, val.acc = 0.4526\n",
      "Epoch 1, loss = 1.5814, val.loss = 1.5100, val.acc = 0.5034\n",
      "Epoch 2, loss = 1.4560, val.loss = 1.4212, val.acc = 0.5342\n",
      "Epoch 3, loss = 1.3779, val.loss = 1.3619, val.acc = 0.5488\n",
      "Epoch 4, loss = 1.3217, val.loss = 1.3187, val.acc = 0.5638\n",
      "Epoch 5, loss = 1.2782, val.loss = 1.2853, val.acc = 0.5740\n",
      "Epoch 6, loss = 1.2431, val.loss = 1.2585, val.acc = 0.5804\n",
      "Epoch 7, loss = 1.2136, val.loss = 1.2364, val.acc = 0.5878\n",
      "Epoch 8, loss = 1.1883, val.loss = 1.2177, val.acc = 0.5922\n",
      "Epoch 9, loss = 1.1662, val.loss = 1.2018, val.acc = 0.5948\n",
      "Epoch 10, loss = 1.1465, val.loss = 1.1879, val.acc = 0.5988\n",
      "Epoch 11, loss = 1.1288, val.loss = 1.1757, val.acc = 0.6050\n",
      "Epoch 12, loss = 1.1127, val.loss = 1.1648, val.acc = 0.6076\n",
      "Epoch 13, loss = 1.0979, val.loss = 1.1551, val.acc = 0.6098\n",
      "Epoch 14, loss = 1.0843, val.loss = 1.1463, val.acc = 0.6134\n",
      "Epoch 15, loss = 1.0716, val.loss = 1.1384, val.acc = 0.6172\n",
      "Epoch 16, loss = 1.0597, val.loss = 1.1311, val.acc = 0.6210\n",
      "Epoch 17, loss = 1.0485, val.loss = 1.1244, val.acc = 0.6234\n",
      "Epoch 18, loss = 1.0379, val.loss = 1.1183, val.acc = 0.6244\n",
      "Epoch 19, loss = 1.0279, val.loss = 1.1126, val.acc = 0.6260\n",
      "Epoch 20, loss = 1.0184, val.loss = 1.1074, val.acc = 0.6284\n",
      "Epoch 21, loss = 1.0093, val.loss = 1.1025, val.acc = 0.6288\n",
      "Epoch 22, loss = 1.0007, val.loss = 1.0979, val.acc = 0.6302\n",
      "Epoch 23, loss = 0.9924, val.loss = 1.0936, val.acc = 0.6316\n",
      "Epoch 24, loss = 0.9844, val.loss = 1.0896, val.acc = 0.6322\n",
      "Epoch 25, loss = 0.9767, val.loss = 1.0858, val.acc = 0.6340\n",
      "Epoch 26, loss = 0.9693, val.loss = 1.0822, val.acc = 0.6352\n",
      "Epoch 27, loss = 0.9622, val.loss = 1.0789, val.acc = 0.6358\n",
      "Epoch 28, loss = 0.9553, val.loss = 1.0757, val.acc = 0.6366\n",
      "Epoch 29, loss = 0.9486, val.loss = 1.0727, val.acc = 0.6366\n",
      "Epoch 30, loss = 0.9422, val.loss = 1.0698, val.acc = 0.6374\n",
      "Epoch 31, loss = 0.9359, val.loss = 1.0671, val.acc = 0.6372\n",
      "Epoch 32, loss = 0.9298, val.loss = 1.0645, val.acc = 0.6388\n",
      "Epoch 33, loss = 0.9239, val.loss = 1.0621, val.acc = 0.6392\n",
      "Epoch 34, loss = 0.9181, val.loss = 1.0598, val.acc = 0.6394\n",
      "Epoch 35, loss = 0.9125, val.loss = 1.0576, val.acc = 0.6404\n",
      "Epoch 36, loss = 0.9070, val.loss = 1.0555, val.acc = 0.6410\n",
      "Epoch 37, loss = 0.9017, val.loss = 1.0535, val.acc = 0.6416\n",
      "Epoch 38, loss = 0.8964, val.loss = 1.0515, val.acc = 0.6426\n",
      "Epoch 39, loss = 0.8913, val.loss = 1.0497, val.acc = 0.6438\n",
      "Epoch 40, loss = 0.8864, val.loss = 1.0480, val.acc = 0.6450\n",
      "Epoch 41, loss = 0.8815, val.loss = 1.0463, val.acc = 0.6452\n",
      "Epoch 42, loss = 0.8767, val.loss = 1.0447, val.acc = 0.6444\n",
      "Epoch 43, loss = 0.8721, val.loss = 1.0431, val.acc = 0.6452\n",
      "Epoch 44, loss = 0.8675, val.loss = 1.0417, val.acc = 0.6460\n",
      "Epoch 45, loss = 0.8630, val.loss = 1.0403, val.acc = 0.6462\n",
      "Epoch 46, loss = 0.8586, val.loss = 1.0389, val.acc = 0.6464\n",
      "Epoch 47, loss = 0.8543, val.loss = 1.0376, val.acc = 0.6462\n",
      "Epoch 48, loss = 0.8501, val.loss = 1.0364, val.acc = 0.6468\n",
      "Epoch 49, loss = 0.8459, val.loss = 1.0352, val.acc = 0.6466\n",
      "Epoch 50, loss = 0.8419, val.loss = 1.0341, val.acc = 0.6472\n",
      "Epoch 51, loss = 0.8379, val.loss = 1.0330, val.acc = 0.6476\n",
      "Epoch 52, loss = 0.8339, val.loss = 1.0320, val.acc = 0.6480\n",
      "Epoch 53, loss = 0.8301, val.loss = 1.0310, val.acc = 0.6480\n",
      "Epoch 54, loss = 0.8263, val.loss = 1.0300, val.acc = 0.6480\n",
      "Epoch 55, loss = 0.8225, val.loss = 1.0291, val.acc = 0.6474\n",
      "Epoch 56, loss = 0.8189, val.loss = 1.0282, val.acc = 0.6480\n",
      "Epoch 57, loss = 0.8152, val.loss = 1.0274, val.acc = 0.6484\n",
      "Epoch 58, loss = 0.8117, val.loss = 1.0266, val.acc = 0.6492\n",
      "Epoch 59, loss = 0.8082, val.loss = 1.0258, val.acc = 0.6496\n",
      "Epoch 60, loss = 0.8047, val.loss = 1.0251, val.acc = 0.6508\n",
      "Epoch 61, loss = 0.8013, val.loss = 1.0244, val.acc = 0.6520\n",
      "Epoch 62, loss = 0.7980, val.loss = 1.0238, val.acc = 0.6526\n",
      "Epoch 63, loss = 0.7947, val.loss = 1.0231, val.acc = 0.6522\n",
      "Epoch 64, loss = 0.7914, val.loss = 1.0225, val.acc = 0.6524\n",
      "Epoch 65, loss = 0.7882, val.loss = 1.0219, val.acc = 0.6528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.7850, val.loss = 1.0214, val.acc = 0.6534\n",
      "Epoch 67, loss = 0.7819, val.loss = 1.0208, val.acc = 0.6538\n",
      "Epoch 68, loss = 0.7788, val.loss = 1.0203, val.acc = 0.6538\n",
      "Epoch 69, loss = 0.7758, val.loss = 1.0199, val.acc = 0.6546\n",
      "Epoch 70, loss = 0.7728, val.loss = 1.0194, val.acc = 0.6554\n",
      "Epoch 71, loss = 0.7698, val.loss = 1.0190, val.acc = 0.6560\n",
      "Epoch 72, loss = 0.7669, val.loss = 1.0186, val.acc = 0.6564\n",
      "Epoch 73, loss = 0.7640, val.loss = 1.0182, val.acc = 0.6562\n",
      "Epoch 74, loss = 0.7611, val.loss = 1.0178, val.acc = 0.6566\n",
      "Epoch 75, loss = 0.7583, val.loss = 1.0175, val.acc = 0.6568\n",
      "Epoch 76, loss = 0.7555, val.loss = 1.0172, val.acc = 0.6576\n",
      "Epoch 77, loss = 0.7528, val.loss = 1.0169, val.acc = 0.6580\n",
      "Epoch 78, loss = 0.7500, val.loss = 1.0166, val.acc = 0.6574\n",
      "Epoch 79, loss = 0.7474, val.loss = 1.0163, val.acc = 0.6574\n",
      "Epoch 80, loss = 0.7447, val.loss = 1.0161, val.acc = 0.6576\n",
      "Epoch 81, loss = 0.7421, val.loss = 1.0159, val.acc = 0.6576\n",
      "Epoch 82, loss = 0.7395, val.loss = 1.0156, val.acc = 0.6582\n",
      "Epoch 83, loss = 0.7369, val.loss = 1.0154, val.acc = 0.6582\n",
      "Epoch 84, loss = 0.7344, val.loss = 1.0153, val.acc = 0.6582\n",
      "Epoch 85, loss = 0.7319, val.loss = 1.0151, val.acc = 0.6586\n",
      "Epoch 86, loss = 0.7294, val.loss = 1.0149, val.acc = 0.6586\n",
      "Epoch 87, loss = 0.7269, val.loss = 1.0148, val.acc = 0.6594\n",
      "Epoch 88, loss = 0.7245, val.loss = 1.0147, val.acc = 0.6598\n",
      "Epoch 89, loss = 0.7221, val.loss = 1.0146, val.acc = 0.6602\n",
      "Epoch 90, loss = 0.7197, val.loss = 1.0145, val.acc = 0.6598\n",
      "Epoch 91, loss = 0.7174, val.loss = 1.0144, val.acc = 0.6602\n",
      "Epoch 92, loss = 0.7150, val.loss = 1.0144, val.acc = 0.6600\n",
      "Epoch 93, loss = 0.7127, val.loss = 1.0143, val.acc = 0.6600\n",
      "Epoch 94, loss = 0.7104, val.loss = 1.0143, val.acc = 0.6602\n",
      "Epoch 95, loss = 0.7082, val.loss = 1.0142, val.acc = 0.6598\n",
      "Epoch 96, loss = 0.7059, val.loss = 1.0142, val.acc = 0.6606\n",
      "Epoch 97, loss = 0.7037, val.loss = 1.0142, val.acc = 0.6600\n",
      "Epoch 98, loss = 0.7015, val.loss = 1.0142, val.acc = 0.6604\n",
      "Epoch 99, loss = 0.6993, val.loss = 1.0143, val.acc = 0.6602\n",
      "Epoch 100, loss = 0.6972, val.loss = 1.0143, val.acc = 0.6598\n",
      "Epoch 101, loss = 0.6951, val.loss = 1.0143, val.acc = 0.6592\n",
      "Epoch 102, loss = 0.6929, val.loss = 1.0144, val.acc = 0.6596\n",
      "Epoch 103, loss = 0.6908, val.loss = 1.0144, val.acc = 0.6598\n",
      "Epoch 104, loss = 0.6888, val.loss = 1.0145, val.acc = 0.6598\n",
      "Epoch 105, loss = 0.6867, val.loss = 1.0146, val.acc = 0.6602\n",
      "Epoch 106, loss = 0.6847, val.loss = 1.0147, val.acc = 0.6602\n",
      "Epoch 107, loss = 0.6826, val.loss = 1.0148, val.acc = 0.6594\n",
      "Epoch 108, loss = 0.6806, val.loss = 1.0149, val.acc = 0.6594\n",
      "Epoch 109, loss = 0.6787, val.loss = 1.0150, val.acc = 0.6592\n",
      "Epoch 110, loss = 0.6767, val.loss = 1.0151, val.acc = 0.6592\n",
      "Epoch 111, loss = 0.6747, val.loss = 1.0153, val.acc = 0.6590\n",
      "Epoch 112, loss = 0.6728, val.loss = 1.0154, val.acc = 0.6588\n",
      "Epoch 113, loss = 0.6709, val.loss = 1.0156, val.acc = 0.6588\n",
      "Epoch 114, loss = 0.6690, val.loss = 1.0158, val.acc = 0.6584\n",
      "Epoch 115, loss = 0.6671, val.loss = 1.0159, val.acc = 0.6582\n",
      "Epoch 116, loss = 0.6652, val.loss = 1.0161, val.acc = 0.6582\n",
      "Epoch 117, loss = 0.6634, val.loss = 1.0163, val.acc = 0.6576\n",
      "Epoch 118, loss = 0.6615, val.loss = 1.0165, val.acc = 0.6576\n",
      "Epoch 119, loss = 0.6597, val.loss = 1.0167, val.acc = 0.6578\n",
      "Epoch 120, loss = 0.6579, val.loss = 1.0169, val.acc = 0.6578\n",
      "Epoch 121, loss = 0.6561, val.loss = 1.0171, val.acc = 0.6574\n",
      "Epoch 122, loss = 0.6543, val.loss = 1.0173, val.acc = 0.6578\n",
      "Epoch 123, loss = 0.6525, val.loss = 1.0176, val.acc = 0.6576\n",
      "Epoch 124, loss = 0.6508, val.loss = 1.0178, val.acc = 0.6576\n",
      "Epoch 125, loss = 0.6490, val.loss = 1.0180, val.acc = 0.6580\n",
      "Epoch 126, loss = 0.6473, val.loss = 1.0183, val.acc = 0.6584\n",
      "Epoch 127, loss = 0.6456, val.loss = 1.0186, val.acc = 0.6576\n",
      "Epoch 128, loss = 0.6439, val.loss = 1.0188, val.acc = 0.6576\n",
      "Epoch 129, loss = 0.6422, val.loss = 1.0191, val.acc = 0.6574\n",
      "Epoch 130, loss = 0.6405, val.loss = 1.0194, val.acc = 0.6574\n",
      "Epoch 131, loss = 0.6389, val.loss = 1.0196, val.acc = 0.6576\n",
      "Epoch 132, loss = 0.6372, val.loss = 1.0199, val.acc = 0.6576\n",
      "Epoch 133, loss = 0.6356, val.loss = 1.0202, val.acc = 0.6576\n",
      "Epoch 134, loss = 0.6339, val.loss = 1.0205, val.acc = 0.6572\n",
      "Epoch 135, loss = 0.6323, val.loss = 1.0208, val.acc = 0.6570\n",
      "Epoch 136, loss = 0.6307, val.loss = 1.0211, val.acc = 0.6568\n",
      "Epoch 137, loss = 0.6291, val.loss = 1.0214, val.acc = 0.6566\n",
      "Epoch 138, loss = 0.6275, val.loss = 1.0217, val.acc = 0.6558\n",
      "Epoch 139, loss = 0.6260, val.loss = 1.0221, val.acc = 0.6554\n",
      "Epoch 140, loss = 0.6244, val.loss = 1.0224, val.acc = 0.6562\n",
      "Epoch 141, loss = 0.6229, val.loss = 1.0227, val.acc = 0.6562\n",
      "Epoch 142, loss = 0.6213, val.loss = 1.0231, val.acc = 0.6562\n",
      "Epoch 143, loss = 0.6198, val.loss = 1.0234, val.acc = 0.6560\n",
      "Epoch 144, loss = 0.6183, val.loss = 1.0237, val.acc = 0.6564\n",
      "Epoch 145, loss = 0.6168, val.loss = 1.0241, val.acc = 0.6560\n",
      "Epoch 146, loss = 0.6153, val.loss = 1.0245, val.acc = 0.6556\n",
      "Epoch 147, loss = 0.6138, val.loss = 1.0248, val.acc = 0.6560\n",
      "Epoch 148, loss = 0.6123, val.loss = 1.0252, val.acc = 0.6560\n",
      "Epoch 149, loss = 0.6109, val.loss = 1.0256, val.acc = 0.6554\n",
      "Rep: 1, te.acc = 0.6420\n",
      "\n",
      "All reps test.acc:\n",
      "[0.642]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 10\n",
    "vis = visdom.Visdom(port=8097,env='ae_2l_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T07:44:32.311997Z",
     "start_time": "2022-04-02T07:12:42.623036Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_3/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_20_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(3, 32, 32))\n",
      "    (deconv): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.7734, time: 16.7825\n",
      "reconstruction loss = 0.0623, similarity loss: 0.5274\n",
      "Epoch 1, loss = 1.3383, time: 16.6820\n",
      "reconstruction loss = 0.0374, similarity loss: 0.5902\n",
      "Epoch 2, loss = 1.3718, time: 16.7248\n",
      "reconstruction loss = 0.0293, similarity loss: 0.7868\n",
      "Epoch 3, loss = 1.0574, time: 16.6679\n",
      "reconstruction loss = 0.0252, similarity loss: 0.5541\n",
      "Epoch 4, loss = 1.1135, time: 16.1379\n",
      "reconstruction loss = 0.0257, similarity loss: 0.5998\n",
      "Epoch 5, loss = 1.0959, time: 16.1604\n",
      "reconstruction loss = 0.0202, similarity loss: 0.6922\n",
      "Epoch 6, loss = 0.9048, time: 16.0840\n",
      "reconstruction loss = 0.0193, similarity loss: 0.5179\n",
      "Epoch 7, loss = 0.9247, time: 16.1607\n",
      "reconstruction loss = 0.0209, similarity loss: 0.5076\n",
      "Epoch 8, loss = 0.8566, time: 16.1307\n",
      "reconstruction loss = 0.0196, similarity loss: 0.4645\n",
      "Epoch 9, loss = 0.8165, time: 16.0797\n",
      "reconstruction loss = 0.0171, similarity loss: 0.4747\n",
      "Epoch 10, loss = 0.8908, time: 16.0459\n",
      "reconstruction loss = 0.0206, similarity loss: 0.4787\n",
      "Epoch 11, loss = 0.7516, time: 16.3761\n",
      "reconstruction loss = 0.0202, similarity loss: 0.3480\n",
      "Epoch 12, loss = 0.7600, time: 16.1287\n",
      "reconstruction loss = 0.0183, similarity loss: 0.3938\n",
      "Epoch 13, loss = 0.6733, time: 16.1309\n",
      "reconstruction loss = 0.0167, similarity loss: 0.3388\n",
      "Epoch 14, loss = 0.8283, time: 16.0577\n",
      "reconstruction loss = 0.0185, similarity loss: 0.4584\n",
      "Epoch 15, loss = 0.7164, time: 16.2349\n",
      "reconstruction loss = 0.0174, similarity loss: 0.3679\n",
      "Epoch 16, loss = 0.7166, time: 16.2034\n",
      "reconstruction loss = 0.0176, similarity loss: 0.3644\n",
      "Epoch 17, loss = 0.6719, time: 16.1147\n",
      "reconstruction loss = 0.0158, similarity loss: 0.3563\n",
      "Epoch 18, loss = 0.6842, time: 16.0505\n",
      "reconstruction loss = 0.0167, similarity loss: 0.3502\n",
      "Epoch 19, loss = 0.7243, time: 16.2020\n",
      "reconstruction loss = 0.0177, similarity loss: 0.3701\n",
      "Epoch 20, loss = 0.6423, time: 16.0512\n",
      "reconstruction loss = 0.0163, similarity loss: 0.3164\n",
      "Epoch 21, loss = 0.6615, time: 16.0935\n",
      "reconstruction loss = 0.0158, similarity loss: 0.3447\n",
      "Epoch 22, loss = 0.6361, time: 16.3165\n",
      "reconstruction loss = 0.0176, similarity loss: 0.2832\n",
      "Epoch 23, loss = 0.6629, time: 16.6538\n",
      "reconstruction loss = 0.0171, similarity loss: 0.3217\n",
      "Epoch 24, loss = 0.6777, time: 16.6416\n",
      "reconstruction loss = 0.0175, similarity loss: 0.3274\n",
      "Epoch 25, loss = 0.6619, time: 16.7714\n",
      "reconstruction loss = 0.0141, similarity loss: 0.3791\n",
      "Epoch 26, loss = 0.5789, time: 16.7521\n",
      "reconstruction loss = 0.0143, similarity loss: 0.2927\n",
      "Epoch 27, loss = 0.6745, time: 16.8034\n",
      "reconstruction loss = 0.0162, similarity loss: 0.3514\n",
      "Epoch 28, loss = 0.6373, time: 16.7706\n",
      "reconstruction loss = 0.0164, similarity loss: 0.3099\n",
      "Epoch 29, loss = 0.6571, time: 16.6335\n",
      "reconstruction loss = 0.0163, similarity loss: 0.3302\n",
      "Epoch 30, loss = 0.5618, time: 16.6588\n",
      "reconstruction loss = 0.0141, similarity loss: 0.2791\n",
      "Epoch 31, loss = 0.6320, time: 16.6595\n",
      "reconstruction loss = 0.0160, similarity loss: 0.3127\n",
      "Epoch 32, loss = 0.6470, time: 16.7880\n",
      "reconstruction loss = 0.0154, similarity loss: 0.3393\n",
      "Epoch 33, loss = 0.6446, time: 16.7309\n",
      "reconstruction loss = 0.0155, similarity loss: 0.3350\n",
      "Epoch 34, loss = 0.5969, time: 16.7452\n",
      "reconstruction loss = 0.0150, similarity loss: 0.2965\n",
      "Epoch 35, loss = 0.6681, time: 16.7338\n",
      "reconstruction loss = 0.0170, similarity loss: 0.3272\n",
      "Epoch 36, loss = 0.5612, time: 16.8717\n",
      "reconstruction loss = 0.0148, similarity loss: 0.2642\n",
      "Epoch 37, loss = 0.5981, time: 16.7164\n",
      "reconstruction loss = 0.0134, similarity loss: 0.3304\n",
      "Epoch 38, loss = 0.6424, time: 16.7218\n",
      "reconstruction loss = 0.0156, similarity loss: 0.3312\n",
      "Epoch 39, loss = 0.6350, time: 16.7600\n",
      "reconstruction loss = 0.0162, similarity loss: 0.3113\n",
      "Epoch 40, loss = 0.6073, time: 16.6991\n",
      "reconstruction loss = 0.0160, similarity loss: 0.2864\n",
      "Epoch 41, loss = 0.6311, time: 16.7860\n",
      "reconstruction loss = 0.0159, similarity loss: 0.3130\n",
      "Epoch 42, loss = 0.5685, time: 16.8170\n",
      "reconstruction loss = 0.0146, similarity loss: 0.2764\n",
      "Epoch 43, loss = 0.6142, time: 16.8342\n",
      "reconstruction loss = 0.0155, similarity loss: 0.3034\n",
      "Epoch 44, loss = 0.6383, time: 16.6865\n",
      "reconstruction loss = 0.0159, similarity loss: 0.3207\n",
      "Epoch 45, loss = 0.5832, time: 16.7044\n",
      "reconstruction loss = 0.0143, similarity loss: 0.2970\n",
      "Epoch 46, loss = 0.6414, time: 16.6403\n",
      "reconstruction loss = 0.0160, similarity loss: 0.3211\n",
      "Epoch 47, loss = 0.6055, time: 16.7567\n",
      "reconstruction loss = 0.0144, similarity loss: 0.3184\n",
      "Epoch 48, loss = 0.5869, time: 16.7768\n",
      "reconstruction loss = 0.0152, similarity loss: 0.2836\n",
      "Epoch 49, loss = 0.5597, time: 16.7048\n",
      "reconstruction loss = 0.0136, similarity loss: 0.2882\n",
      "Epoch 50, loss = 0.6059, time: 16.8781\n",
      "reconstruction loss = 0.0154, similarity loss: 0.2980\n",
      "Epoch 51, loss = 0.5701, time: 16.8260\n",
      "reconstruction loss = 0.0149, similarity loss: 0.2727\n",
      "Epoch 52, loss = 0.5750, time: 16.8243\n",
      "reconstruction loss = 0.0145, similarity loss: 0.2847\n",
      "Epoch 53, loss = 0.5671, time: 16.7261\n",
      "reconstruction loss = 0.0137, similarity loss: 0.2936\n",
      "Epoch 54, loss = 0.5483, time: 16.7908\n",
      "reconstruction loss = 0.0136, similarity loss: 0.2764\n",
      "Epoch 55, loss = 0.5990, time: 16.7559\n",
      "reconstruction loss = 0.0138, similarity loss: 0.3230\n",
      "Epoch 56, loss = 0.5681, time: 16.7714\n",
      "reconstruction loss = 0.0134, similarity loss: 0.2996\n",
      "Epoch 57, loss = 0.5333, time: 16.8475\n",
      "reconstruction loss = 0.0139, similarity loss: 0.2551\n",
      "Epoch 58, loss = 0.5773, time: 16.2088\n",
      "reconstruction loss = 0.0147, similarity loss: 0.2825\n",
      "Epoch 59, loss = 0.6096, time: 16.1733\n",
      "reconstruction loss = 0.0143, similarity loss: 0.3227\n",
      "Epoch 60, loss = 0.5793, time: 16.0818\n",
      "reconstruction loss = 0.0141, similarity loss: 0.2981\n",
      "Epoch 61, loss = 0.5380, time: 16.1483\n",
      "reconstruction loss = 0.0121, similarity loss: 0.2951\n",
      "Epoch 62, loss = 0.6003, time: 16.2057\n",
      "reconstruction loss = 0.0134, similarity loss: 0.3314\n",
      "Epoch 63, loss = 0.5456, time: 16.2723\n",
      "reconstruction loss = 0.0140, similarity loss: 0.2654\n",
      "Epoch 64, loss = 0.5250, time: 16.0948\n",
      "reconstruction loss = 0.0138, similarity loss: 0.2483\n",
      "Epoch 65, loss = 0.5348, time: 16.1490\n",
      "reconstruction loss = 0.0136, similarity loss: 0.2618\n",
      "Epoch 66, loss = 0.5419, time: 16.2851\n",
      "reconstruction loss = 0.0129, similarity loss: 0.2830\n",
      "Epoch 67, loss = 0.5370, time: 16.1111\n",
      "reconstruction loss = 0.0134, similarity loss: 0.2682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.5706, time: 16.1485\n",
      "reconstruction loss = 0.0140, similarity loss: 0.2897\n",
      "Epoch 69, loss = 0.6140, time: 16.2167\n",
      "reconstruction loss = 0.0141, similarity loss: 0.3317\n",
      "Epoch 70, loss = 0.5539, time: 16.2416\n",
      "reconstruction loss = 0.0130, similarity loss: 0.2930\n",
      "Epoch 71, loss = 0.5268, time: 16.1777\n",
      "reconstruction loss = 0.0143, similarity loss: 0.2404\n",
      "Epoch 72, loss = 0.5135, time: 16.1185\n",
      "reconstruction loss = 0.0114, similarity loss: 0.2857\n",
      "Epoch 73, loss = 0.5586, time: 16.3037\n",
      "reconstruction loss = 0.0129, similarity loss: 0.3007\n",
      "Epoch 74, loss = 0.5375, time: 16.1924\n",
      "reconstruction loss = 0.0128, similarity loss: 0.2823\n",
      "Epoch 75, loss = 0.5153, time: 16.2862\n",
      "reconstruction loss = 0.0126, similarity loss: 0.2638\n",
      "Epoch 76, loss = 0.5251, time: 16.2513\n",
      "reconstruction loss = 0.0119, similarity loss: 0.2877\n",
      "Epoch 77, loss = 0.5116, time: 16.7958\n",
      "reconstruction loss = 0.0113, similarity loss: 0.2853\n",
      "Epoch 78, loss = 0.4912, time: 16.7948\n",
      "reconstruction loss = 0.0109, similarity loss: 0.2729\n",
      "Epoch 79, loss = 0.5136, time: 16.8159\n",
      "reconstruction loss = 0.0115, similarity loss: 0.2827\n",
      "Epoch 80, loss = 0.5121, time: 16.7385\n",
      "reconstruction loss = 0.0108, similarity loss: 0.2961\n",
      "Epoch 81, loss = 0.4750, time: 16.9319\n",
      "reconstruction loss = 0.0106, similarity loss: 0.2622\n",
      "Epoch 82, loss = 0.5334, time: 16.7749\n",
      "reconstruction loss = 0.0111, similarity loss: 0.3108\n",
      "Epoch 83, loss = 0.4659, time: 16.7429\n",
      "reconstruction loss = 0.0104, similarity loss: 0.2578\n",
      "Epoch 84, loss = 0.4885, time: 16.7266\n",
      "reconstruction loss = 0.0111, similarity loss: 0.2659\n",
      "Epoch 85, loss = 0.4487, time: 16.7806\n",
      "reconstruction loss = 0.0095, similarity loss: 0.2582\n",
      "Epoch 86, loss = 0.4882, time: 16.8450\n",
      "reconstruction loss = 0.0103, similarity loss: 0.2821\n",
      "Epoch 87, loss = 0.4985, time: 16.8414\n",
      "reconstruction loss = 0.0104, similarity loss: 0.2898\n",
      "Epoch 88, loss = 0.4705, time: 16.7741\n",
      "reconstruction loss = 0.0107, similarity loss: 0.2565\n",
      "Epoch 89, loss = 0.4618, time: 16.7807\n",
      "reconstruction loss = 0.0101, similarity loss: 0.2595\n",
      "Epoch 90, loss = 0.4069, time: 16.5954\n",
      "reconstruction loss = 0.0093, similarity loss: 0.2201\n",
      "Epoch 91, loss = 0.4665, time: 16.6648\n",
      "reconstruction loss = 0.0094, similarity loss: 0.2790\n",
      "Epoch 92, loss = 0.4701, time: 16.7124\n",
      "reconstruction loss = 0.0100, similarity loss: 0.2705\n",
      "Epoch 93, loss = 0.4217, time: 16.7647\n",
      "reconstruction loss = 0.0091, similarity loss: 0.2398\n",
      "Epoch 94, loss = 0.4560, time: 16.7751\n",
      "reconstruction loss = 0.0092, similarity loss: 0.2724\n",
      "Epoch 95, loss = 0.4196, time: 16.6779\n",
      "reconstruction loss = 0.0091, similarity loss: 0.2372\n",
      "Epoch 96, loss = 0.4749, time: 16.8290\n",
      "reconstruction loss = 0.0099, similarity loss: 0.2762\n",
      "Epoch 97, loss = 0.4160, time: 16.7271\n",
      "reconstruction loss = 0.0088, similarity loss: 0.2393\n",
      "Epoch 98, loss = 0.4914, time: 16.7901\n",
      "reconstruction loss = 0.0103, similarity loss: 0.2844\n",
      "Epoch 99, loss = 0.4036, time: 16.6894\n",
      "reconstruction loss = 0.0086, similarity loss: 0.2313\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.9885, val.loss = 1.7540, val.acc = 0.4214\n",
      "Epoch 1, loss = 1.6660, val.loss = 1.5889, val.acc = 0.4794\n",
      "Epoch 2, loss = 1.5385, val.loss = 1.4954, val.acc = 0.5100\n",
      "Epoch 3, loss = 1.4567, val.loss = 1.4309, val.acc = 0.5292\n",
      "Epoch 4, loss = 1.3969, val.loss = 1.3826, val.acc = 0.5448\n",
      "Epoch 5, loss = 1.3501, val.loss = 1.3445, val.acc = 0.5588\n",
      "Epoch 6, loss = 1.3121, val.loss = 1.3136, val.acc = 0.5696\n",
      "Epoch 7, loss = 1.2802, val.loss = 1.2877, val.acc = 0.5806\n",
      "Epoch 8, loss = 1.2528, val.loss = 1.2658, val.acc = 0.5892\n",
      "Epoch 9, loss = 1.2290, val.loss = 1.2469, val.acc = 0.5944\n",
      "Epoch 10, loss = 1.2078, val.loss = 1.2304, val.acc = 0.5976\n",
      "Epoch 11, loss = 1.1889, val.loss = 1.2157, val.acc = 0.6022\n",
      "Epoch 12, loss = 1.1717, val.loss = 1.2027, val.acc = 0.6068\n",
      "Epoch 13, loss = 1.1560, val.loss = 1.1911, val.acc = 0.6084\n",
      "Epoch 14, loss = 1.1416, val.loss = 1.1805, val.acc = 0.6110\n",
      "Epoch 15, loss = 1.1282, val.loss = 1.1709, val.acc = 0.6136\n",
      "Epoch 16, loss = 1.1158, val.loss = 1.1621, val.acc = 0.6174\n",
      "Epoch 17, loss = 1.1041, val.loss = 1.1540, val.acc = 0.6186\n",
      "Epoch 18, loss = 1.0932, val.loss = 1.1465, val.acc = 0.6196\n",
      "Epoch 19, loss = 1.0828, val.loss = 1.1396, val.acc = 0.6210\n",
      "Epoch 20, loss = 1.0730, val.loss = 1.1332, val.acc = 0.6228\n",
      "Epoch 21, loss = 1.0637, val.loss = 1.1272, val.acc = 0.6246\n",
      "Epoch 22, loss = 1.0548, val.loss = 1.1216, val.acc = 0.6282\n",
      "Epoch 23, loss = 1.0464, val.loss = 1.1163, val.acc = 0.6296\n",
      "Epoch 24, loss = 1.0383, val.loss = 1.1114, val.acc = 0.6300\n",
      "Epoch 25, loss = 1.0305, val.loss = 1.1067, val.acc = 0.6312\n",
      "Epoch 26, loss = 1.0230, val.loss = 1.1024, val.acc = 0.6334\n",
      "Epoch 27, loss = 1.0158, val.loss = 1.0982, val.acc = 0.6348\n",
      "Epoch 28, loss = 1.0089, val.loss = 1.0943, val.acc = 0.6366\n",
      "Epoch 29, loss = 1.0022, val.loss = 1.0906, val.acc = 0.6374\n",
      "Epoch 30, loss = 0.9957, val.loss = 1.0871, val.acc = 0.6400\n",
      "Epoch 31, loss = 0.9894, val.loss = 1.0837, val.acc = 0.6408\n",
      "Epoch 32, loss = 0.9833, val.loss = 1.0805, val.acc = 0.6424\n",
      "Epoch 33, loss = 0.9774, val.loss = 1.0775, val.acc = 0.6432\n",
      "Epoch 34, loss = 0.9717, val.loss = 1.0746, val.acc = 0.6444\n",
      "Epoch 35, loss = 0.9661, val.loss = 1.0718, val.acc = 0.6466\n",
      "Epoch 36, loss = 0.9607, val.loss = 1.0692, val.acc = 0.6482\n",
      "Epoch 37, loss = 0.9554, val.loss = 1.0667, val.acc = 0.6490\n",
      "Epoch 38, loss = 0.9502, val.loss = 1.0642, val.acc = 0.6496\n",
      "Epoch 39, loss = 0.9452, val.loss = 1.0619, val.acc = 0.6510\n",
      "Epoch 40, loss = 0.9403, val.loss = 1.0597, val.acc = 0.6520\n",
      "Epoch 41, loss = 0.9355, val.loss = 1.0576, val.acc = 0.6528\n",
      "Epoch 42, loss = 0.9308, val.loss = 1.0555, val.acc = 0.6540\n",
      "Epoch 43, loss = 0.9263, val.loss = 1.0535, val.acc = 0.6540\n",
      "Epoch 44, loss = 0.9218, val.loss = 1.0516, val.acc = 0.6552\n",
      "Epoch 45, loss = 0.9174, val.loss = 1.0498, val.acc = 0.6552\n",
      "Epoch 46, loss = 0.9131, val.loss = 1.0481, val.acc = 0.6560\n",
      "Epoch 47, loss = 0.9089, val.loss = 1.0464, val.acc = 0.6568\n",
      "Epoch 48, loss = 0.9047, val.loss = 1.0448, val.acc = 0.6566\n",
      "Epoch 49, loss = 0.9007, val.loss = 1.0432, val.acc = 0.6572\n",
      "Epoch 50, loss = 0.8967, val.loss = 1.0417, val.acc = 0.6582\n",
      "Epoch 51, loss = 0.8928, val.loss = 1.0403, val.acc = 0.6588\n",
      "Epoch 52, loss = 0.8890, val.loss = 1.0389, val.acc = 0.6596\n",
      "Epoch 53, loss = 0.8852, val.loss = 1.0375, val.acc = 0.6606\n",
      "Epoch 54, loss = 0.8815, val.loss = 1.0362, val.acc = 0.6620\n",
      "Epoch 55, loss = 0.8779, val.loss = 1.0350, val.acc = 0.6616\n",
      "Epoch 56, loss = 0.8743, val.loss = 1.0338, val.acc = 0.6612\n",
      "Epoch 57, loss = 0.8708, val.loss = 1.0326, val.acc = 0.6620\n",
      "Epoch 58, loss = 0.8673, val.loss = 1.0314, val.acc = 0.6618\n",
      "Epoch 59, loss = 0.8639, val.loss = 1.0304, val.acc = 0.6628\n",
      "Epoch 60, loss = 0.8606, val.loss = 1.0293, val.acc = 0.6630\n",
      "Epoch 61, loss = 0.8573, val.loss = 1.0283, val.acc = 0.6642\n",
      "Epoch 62, loss = 0.8540, val.loss = 1.0273, val.acc = 0.6642\n",
      "Epoch 63, loss = 0.8508, val.loss = 1.0264, val.acc = 0.6646\n",
      "Epoch 64, loss = 0.8476, val.loss = 1.0254, val.acc = 0.6650\n",
      "Epoch 65, loss = 0.8445, val.loss = 1.0245, val.acc = 0.6648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.8414, val.loss = 1.0237, val.acc = 0.6650\n",
      "Epoch 67, loss = 0.8384, val.loss = 1.0229, val.acc = 0.6648\n",
      "Epoch 68, loss = 0.8354, val.loss = 1.0221, val.acc = 0.6658\n",
      "Epoch 69, loss = 0.8325, val.loss = 1.0213, val.acc = 0.6664\n",
      "Epoch 70, loss = 0.8296, val.loss = 1.0205, val.acc = 0.6658\n",
      "Epoch 71, loss = 0.8267, val.loss = 1.0198, val.acc = 0.6674\n",
      "Epoch 72, loss = 0.8238, val.loss = 1.0191, val.acc = 0.6678\n",
      "Epoch 73, loss = 0.8210, val.loss = 1.0185, val.acc = 0.6682\n",
      "Epoch 74, loss = 0.8183, val.loss = 1.0178, val.acc = 0.6684\n",
      "Epoch 75, loss = 0.8155, val.loss = 1.0172, val.acc = 0.6682\n",
      "Epoch 76, loss = 0.8128, val.loss = 1.0166, val.acc = 0.6678\n",
      "Epoch 77, loss = 0.8102, val.loss = 1.0160, val.acc = 0.6676\n",
      "Epoch 78, loss = 0.8076, val.loss = 1.0154, val.acc = 0.6680\n",
      "Epoch 79, loss = 0.8049, val.loss = 1.0149, val.acc = 0.6680\n",
      "Epoch 80, loss = 0.8024, val.loss = 1.0143, val.acc = 0.6690\n",
      "Epoch 81, loss = 0.7998, val.loss = 1.0138, val.acc = 0.6684\n",
      "Epoch 82, loss = 0.7973, val.loss = 1.0133, val.acc = 0.6682\n",
      "Epoch 83, loss = 0.7948, val.loss = 1.0129, val.acc = 0.6686\n",
      "Epoch 84, loss = 0.7924, val.loss = 1.0124, val.acc = 0.6688\n",
      "Epoch 85, loss = 0.7899, val.loss = 1.0120, val.acc = 0.6692\n",
      "Epoch 86, loss = 0.7875, val.loss = 1.0115, val.acc = 0.6690\n",
      "Epoch 87, loss = 0.7851, val.loss = 1.0111, val.acc = 0.6694\n",
      "Epoch 88, loss = 0.7828, val.loss = 1.0107, val.acc = 0.6692\n",
      "Epoch 89, loss = 0.7804, val.loss = 1.0104, val.acc = 0.6694\n",
      "Epoch 90, loss = 0.7781, val.loss = 1.0100, val.acc = 0.6694\n",
      "Epoch 91, loss = 0.7759, val.loss = 1.0097, val.acc = 0.6694\n",
      "Epoch 92, loss = 0.7736, val.loss = 1.0093, val.acc = 0.6694\n",
      "Epoch 93, loss = 0.7713, val.loss = 1.0090, val.acc = 0.6692\n",
      "Epoch 94, loss = 0.7691, val.loss = 1.0087, val.acc = 0.6692\n",
      "Epoch 95, loss = 0.7669, val.loss = 1.0084, val.acc = 0.6690\n",
      "Epoch 96, loss = 0.7648, val.loss = 1.0081, val.acc = 0.6690\n",
      "Epoch 97, loss = 0.7626, val.loss = 1.0078, val.acc = 0.6688\n",
      "Epoch 98, loss = 0.7605, val.loss = 1.0076, val.acc = 0.6688\n",
      "Epoch 99, loss = 0.7584, val.loss = 1.0073, val.acc = 0.6688\n",
      "Epoch 100, loss = 0.7563, val.loss = 1.0071, val.acc = 0.6680\n",
      "Epoch 101, loss = 0.7542, val.loss = 1.0069, val.acc = 0.6676\n",
      "Epoch 102, loss = 0.7521, val.loss = 1.0067, val.acc = 0.6676\n",
      "Epoch 103, loss = 0.7501, val.loss = 1.0064, val.acc = 0.6680\n",
      "Epoch 104, loss = 0.7481, val.loss = 1.0063, val.acc = 0.6682\n",
      "Epoch 105, loss = 0.7461, val.loss = 1.0061, val.acc = 0.6682\n",
      "Epoch 106, loss = 0.7441, val.loss = 1.0059, val.acc = 0.6680\n",
      "Epoch 107, loss = 0.7421, val.loss = 1.0057, val.acc = 0.6678\n",
      "Epoch 108, loss = 0.7402, val.loss = 1.0056, val.acc = 0.6670\n",
      "Epoch 109, loss = 0.7382, val.loss = 1.0054, val.acc = 0.6672\n",
      "Epoch 110, loss = 0.7363, val.loss = 1.0053, val.acc = 0.6678\n",
      "Epoch 111, loss = 0.7344, val.loss = 1.0051, val.acc = 0.6678\n",
      "Epoch 112, loss = 0.7325, val.loss = 1.0050, val.acc = 0.6680\n",
      "Epoch 113, loss = 0.7306, val.loss = 1.0049, val.acc = 0.6678\n",
      "Epoch 114, loss = 0.7288, val.loss = 1.0048, val.acc = 0.6678\n",
      "Epoch 115, loss = 0.7269, val.loss = 1.0047, val.acc = 0.6682\n",
      "Epoch 116, loss = 0.7251, val.loss = 1.0046, val.acc = 0.6682\n",
      "Epoch 117, loss = 0.7233, val.loss = 1.0046, val.acc = 0.6684\n",
      "Epoch 118, loss = 0.7215, val.loss = 1.0045, val.acc = 0.6688\n",
      "Epoch 119, loss = 0.7197, val.loss = 1.0044, val.acc = 0.6692\n",
      "Epoch 120, loss = 0.7180, val.loss = 1.0044, val.acc = 0.6698\n",
      "Epoch 121, loss = 0.7162, val.loss = 1.0043, val.acc = 0.6698\n",
      "Epoch 122, loss = 0.7145, val.loss = 1.0043, val.acc = 0.6698\n",
      "Epoch 123, loss = 0.7127, val.loss = 1.0042, val.acc = 0.6700\n",
      "Epoch 124, loss = 0.7110, val.loss = 1.0042, val.acc = 0.6696\n",
      "Epoch 125, loss = 0.7093, val.loss = 1.0042, val.acc = 0.6696\n",
      "Epoch 126, loss = 0.7076, val.loss = 1.0042, val.acc = 0.6700\n",
      "Epoch 127, loss = 0.7059, val.loss = 1.0042, val.acc = 0.6700\n",
      "Epoch 128, loss = 0.7043, val.loss = 1.0042, val.acc = 0.6694\n",
      "Epoch 129, loss = 0.7026, val.loss = 1.0042, val.acc = 0.6690\n",
      "Epoch 130, loss = 0.7010, val.loss = 1.0042, val.acc = 0.6686\n",
      "Epoch 131, loss = 0.6994, val.loss = 1.0042, val.acc = 0.6686\n",
      "Epoch 132, loss = 0.6977, val.loss = 1.0042, val.acc = 0.6686\n",
      "Epoch 133, loss = 0.6961, val.loss = 1.0042, val.acc = 0.6690\n",
      "Epoch 134, loss = 0.6945, val.loss = 1.0043, val.acc = 0.6688\n",
      "Epoch 135, loss = 0.6929, val.loss = 1.0043, val.acc = 0.6688\n",
      "Epoch 136, loss = 0.6914, val.loss = 1.0044, val.acc = 0.6690\n",
      "Epoch 137, loss = 0.6898, val.loss = 1.0044, val.acc = 0.6686\n",
      "Epoch 138, loss = 0.6883, val.loss = 1.0045, val.acc = 0.6682\n",
      "Epoch 139, loss = 0.6867, val.loss = 1.0045, val.acc = 0.6682\n",
      "Epoch 140, loss = 0.6852, val.loss = 1.0046, val.acc = 0.6678\n",
      "Epoch 141, loss = 0.6837, val.loss = 1.0047, val.acc = 0.6668\n",
      "Epoch 142, loss = 0.6821, val.loss = 1.0047, val.acc = 0.6668\n",
      "Epoch 143, loss = 0.6807, val.loss = 1.0048, val.acc = 0.6670\n",
      "Epoch 144, loss = 0.6792, val.loss = 1.0049, val.acc = 0.6666\n",
      "Epoch 145, loss = 0.6777, val.loss = 1.0050, val.acc = 0.6662\n",
      "Epoch 146, loss = 0.6762, val.loss = 1.0051, val.acc = 0.6662\n",
      "Epoch 147, loss = 0.6747, val.loss = 1.0052, val.acc = 0.6660\n",
      "Epoch 148, loss = 0.6733, val.loss = 1.0053, val.acc = 0.6656\n",
      "Epoch 149, loss = 0.6718, val.loss = 1.0054, val.acc = 0.6654\n",
      "Rep: 1, te.acc = 0.6418\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6418]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 20\n",
    "vis = visdom.Visdom(port=8097,env='ae_2l_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T08:16:20.372346Z",
     "start_time": "2022-04-02T07:44:32.312997Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_3/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_50_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(3, 32, 32))\n",
      "    (deconv): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 3.2900, time: 16.3727\n",
      "reconstruction loss = 0.0523, similarity loss: 0.6757\n",
      "Epoch 1, loss = 2.8233, time: 16.0326\n",
      "reconstruction loss = 0.0441, similarity loss: 0.6162\n",
      "Epoch 2, loss = 2.6831, time: 16.0326\n",
      "reconstruction loss = 0.0393, similarity loss: 0.7159\n",
      "Epoch 3, loss = 2.3664, time: 16.0858\n",
      "reconstruction loss = 0.0363, similarity loss: 0.5528\n",
      "Epoch 4, loss = 2.4452, time: 16.1287\n",
      "reconstruction loss = 0.0357, similarity loss: 0.6612\n",
      "Epoch 5, loss = 2.2819, time: 16.2778\n",
      "reconstruction loss = 0.0356, similarity loss: 0.4994\n",
      "Epoch 6, loss = 1.7618, time: 16.1140\n",
      "reconstruction loss = 0.0243, similarity loss: 0.5485\n",
      "Epoch 7, loss = 1.3610, time: 16.0930\n",
      "reconstruction loss = 0.0166, similarity loss: 0.5321\n",
      "Epoch 8, loss = 1.4775, time: 16.0525\n",
      "reconstruction loss = 0.0165, similarity loss: 0.6527\n",
      "Epoch 9, loss = 1.2019, time: 16.1469\n",
      "reconstruction loss = 0.0136, similarity loss: 0.5221\n",
      "Epoch 10, loss = 1.3023, time: 16.1232\n",
      "reconstruction loss = 0.0137, similarity loss: 0.6174\n",
      "Epoch 11, loss = 1.2000, time: 16.0230\n",
      "reconstruction loss = 0.0138, similarity loss: 0.5110\n",
      "Epoch 12, loss = 1.0459, time: 16.1386\n",
      "reconstruction loss = 0.0115, similarity loss: 0.4724\n",
      "Epoch 13, loss = 1.2442, time: 16.1291\n",
      "reconstruction loss = 0.0148, similarity loss: 0.5027\n",
      "Epoch 14, loss = 1.0434, time: 16.1424\n",
      "reconstruction loss = 0.0115, similarity loss: 0.4698\n",
      "Epoch 15, loss = 1.0235, time: 16.1459\n",
      "reconstruction loss = 0.0114, similarity loss: 0.4526\n",
      "Epoch 16, loss = 0.9374, time: 16.7258\n",
      "reconstruction loss = 0.0099, similarity loss: 0.4412\n",
      "Epoch 17, loss = 0.9226, time: 16.7443\n",
      "reconstruction loss = 0.0106, similarity loss: 0.3925\n",
      "Epoch 18, loss = 0.8795, time: 16.6668\n",
      "reconstruction loss = 0.0097, similarity loss: 0.3925\n",
      "Epoch 19, loss = 0.9093, time: 16.8448\n",
      "reconstruction loss = 0.0106, similarity loss: 0.3771\n",
      "Epoch 20, loss = 0.9934, time: 16.6142\n",
      "reconstruction loss = 0.0111, similarity loss: 0.4408\n",
      "Epoch 21, loss = 0.8346, time: 16.6774\n",
      "reconstruction loss = 0.0091, similarity loss: 0.3808\n",
      "Epoch 22, loss = 0.9547, time: 16.7159\n",
      "reconstruction loss = 0.0112, similarity loss: 0.3951\n",
      "Epoch 23, loss = 0.8339, time: 16.7547\n",
      "reconstruction loss = 0.0089, similarity loss: 0.3907\n",
      "Epoch 24, loss = 0.8287, time: 16.6672\n",
      "reconstruction loss = 0.0099, similarity loss: 0.3355\n",
      "Epoch 25, loss = 0.7921, time: 16.7931\n",
      "reconstruction loss = 0.0088, similarity loss: 0.3520\n",
      "Epoch 26, loss = 0.8521, time: 16.8139\n",
      "reconstruction loss = 0.0099, similarity loss: 0.3556\n",
      "Epoch 27, loss = 0.8020, time: 16.7840\n",
      "reconstruction loss = 0.0093, similarity loss: 0.3388\n",
      "Epoch 28, loss = 0.8093, time: 16.7067\n",
      "reconstruction loss = 0.0089, similarity loss: 0.3650\n",
      "Epoch 29, loss = 0.7618, time: 16.6637\n",
      "reconstruction loss = 0.0089, similarity loss: 0.3145\n",
      "Epoch 30, loss = 0.8539, time: 16.8605\n",
      "reconstruction loss = 0.0096, similarity loss: 0.3714\n",
      "Epoch 31, loss = 0.7667, time: 16.7458\n",
      "reconstruction loss = 0.0088, similarity loss: 0.3257\n",
      "Epoch 32, loss = 0.8445, time: 16.6735\n",
      "reconstruction loss = 0.0092, similarity loss: 0.3847\n",
      "Epoch 33, loss = 0.7919, time: 16.6880\n",
      "reconstruction loss = 0.0090, similarity loss: 0.3417\n",
      "Epoch 34, loss = 0.7556, time: 16.7360\n",
      "reconstruction loss = 0.0078, similarity loss: 0.3650\n",
      "Epoch 35, loss = 0.7306, time: 16.8117\n",
      "reconstruction loss = 0.0078, similarity loss: 0.3384\n",
      "Epoch 36, loss = 0.7864, time: 16.6795\n",
      "reconstruction loss = 0.0082, similarity loss: 0.3750\n",
      "Epoch 37, loss = 0.7948, time: 16.7406\n",
      "reconstruction loss = 0.0088, similarity loss: 0.3552\n",
      "Epoch 38, loss = 0.7955, time: 16.6169\n",
      "reconstruction loss = 0.0090, similarity loss: 0.3468\n",
      "Epoch 39, loss = 0.7328, time: 16.7513\n",
      "reconstruction loss = 0.0077, similarity loss: 0.3484\n",
      "Epoch 40, loss = 0.7372, time: 16.6564\n",
      "reconstruction loss = 0.0082, similarity loss: 0.3260\n",
      "Epoch 41, loss = 0.8212, time: 16.6610\n",
      "reconstruction loss = 0.0094, similarity loss: 0.3511\n",
      "Epoch 42, loss = 0.7249, time: 16.6811\n",
      "reconstruction loss = 0.0080, similarity loss: 0.3233\n",
      "Epoch 43, loss = 0.7780, time: 16.7659\n",
      "reconstruction loss = 0.0089, similarity loss: 0.3334\n",
      "Epoch 44, loss = 0.7583, time: 16.6299\n",
      "reconstruction loss = 0.0078, similarity loss: 0.3699\n",
      "Epoch 45, loss = 0.7575, time: 17.3019\n",
      "reconstruction loss = 0.0079, similarity loss: 0.3600\n",
      "Epoch 46, loss = 0.7333, time: 16.9277\n",
      "reconstruction loss = 0.0072, similarity loss: 0.3709\n",
      "Epoch 47, loss = 0.7186, time: 16.6795\n",
      "reconstruction loss = 0.0082, similarity loss: 0.3100\n",
      "Epoch 48, loss = 0.6980, time: 16.7249\n",
      "reconstruction loss = 0.0079, similarity loss: 0.3019\n",
      "Epoch 49, loss = 0.8082, time: 16.6592\n",
      "reconstruction loss = 0.0095, similarity loss: 0.3318\n",
      "Epoch 50, loss = 0.7196, time: 16.6126\n",
      "reconstruction loss = 0.0079, similarity loss: 0.3251\n",
      "Epoch 51, loss = 0.6360, time: 16.4924\n",
      "reconstruction loss = 0.0069, similarity loss: 0.2888\n",
      "Epoch 52, loss = 0.6249, time: 16.0363\n",
      "reconstruction loss = 0.0069, similarity loss: 0.2784\n",
      "Epoch 53, loss = 0.7113, time: 16.0778\n",
      "reconstruction loss = 0.0076, similarity loss: 0.3292\n",
      "Epoch 54, loss = 0.7198, time: 16.1064\n",
      "reconstruction loss = 0.0083, similarity loss: 0.3034\n",
      "Epoch 55, loss = 0.7426, time: 16.1640\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3737\n",
      "Epoch 56, loss = 0.6886, time: 16.0716\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3188\n",
      "Epoch 57, loss = 0.6535, time: 16.0480\n",
      "reconstruction loss = 0.0076, similarity loss: 0.2737\n",
      "Epoch 58, loss = 0.7582, time: 16.1718\n",
      "reconstruction loss = 0.0088, similarity loss: 0.3164\n",
      "Epoch 59, loss = 0.6992, time: 16.1461\n",
      "reconstruction loss = 0.0079, similarity loss: 0.3028\n",
      "Epoch 60, loss = 0.6301, time: 16.2311\n",
      "reconstruction loss = 0.0067, similarity loss: 0.2950\n",
      "Epoch 61, loss = 0.6136, time: 16.2191\n",
      "reconstruction loss = 0.0067, similarity loss: 0.2784\n",
      "Epoch 62, loss = 0.7024, time: 16.1769\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3347\n",
      "Epoch 63, loss = 0.6929, time: 16.1317\n",
      "reconstruction loss = 0.0083, similarity loss: 0.2774\n",
      "Epoch 64, loss = 0.7003, time: 16.1442\n",
      "reconstruction loss = 0.0075, similarity loss: 0.3263\n",
      "Epoch 65, loss = 0.6961, time: 16.1008\n",
      "reconstruction loss = 0.0077, similarity loss: 0.3110\n",
      "Epoch 66, loss = 0.6889, time: 16.1879\n",
      "reconstruction loss = 0.0079, similarity loss: 0.2938\n",
      "Epoch 67, loss = 0.6713, time: 16.1315\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 0.6764, time: 16.0646\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3067\n",
      "Epoch 69, loss = 0.7019, time: 16.0585\n",
      "reconstruction loss = 0.0073, similarity loss: 0.3346\n",
      "Epoch 70, loss = 0.6754, time: 16.5289\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3210\n",
      "Epoch 71, loss = 0.5955, time: 16.6419\n",
      "reconstruction loss = 0.0067, similarity loss: 0.2614\n",
      "Epoch 72, loss = 0.6001, time: 16.7998\n",
      "reconstruction loss = 0.0067, similarity loss: 0.2645\n",
      "Epoch 73, loss = 0.7929, time: 17.0554\n",
      "reconstruction loss = 0.0087, similarity loss: 0.3600\n",
      "Epoch 74, loss = 0.6887, time: 16.8708\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3184\n",
      "Epoch 75, loss = 0.6083, time: 16.7328\n",
      "reconstruction loss = 0.0063, similarity loss: 0.2935\n",
      "Epoch 76, loss = 0.7361, time: 16.6994\n",
      "reconstruction loss = 0.0087, similarity loss: 0.3023\n",
      "Epoch 77, loss = 0.7158, time: 16.8373\n",
      "reconstruction loss = 0.0073, similarity loss: 0.3503\n",
      "Epoch 78, loss = 0.6891, time: 16.7180\n",
      "reconstruction loss = 0.0069, similarity loss: 0.3463\n",
      "Epoch 79, loss = 0.6479, time: 16.7342\n",
      "reconstruction loss = 0.0069, similarity loss: 0.3047\n",
      "Epoch 80, loss = 0.6560, time: 16.8163\n",
      "reconstruction loss = 0.0067, similarity loss: 0.3193\n",
      "Epoch 81, loss = 0.6314, time: 16.8283\n",
      "reconstruction loss = 0.0067, similarity loss: 0.2967\n",
      "Epoch 82, loss = 0.5772, time: 16.7233\n",
      "reconstruction loss = 0.0061, similarity loss: 0.2742\n",
      "Epoch 83, loss = 1.0112, time: 16.7635\n",
      "reconstruction loss = 0.0115, similarity loss: 0.4379\n",
      "Epoch 84, loss = 0.6814, time: 16.7546\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3277\n",
      "Epoch 85, loss = 0.6435, time: 16.7285\n",
      "reconstruction loss = 0.0073, similarity loss: 0.2789\n",
      "Epoch 86, loss = 0.6502, time: 16.6447\n",
      "reconstruction loss = 0.0070, similarity loss: 0.3022\n",
      "Epoch 87, loss = 0.6714, time: 16.6937\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3169\n",
      "Epoch 88, loss = 0.6340, time: 16.7997\n",
      "reconstruction loss = 0.0067, similarity loss: 0.3006\n",
      "Epoch 89, loss = 0.5798, time: 16.9560\n",
      "reconstruction loss = 0.0061, similarity loss: 0.2728\n",
      "Epoch 90, loss = 0.6398, time: 16.6719\n",
      "reconstruction loss = 0.0072, similarity loss: 0.2776\n",
      "Epoch 91, loss = 0.5995, time: 16.7806\n",
      "reconstruction loss = 0.0063, similarity loss: 0.2855\n",
      "Epoch 92, loss = 0.8527, time: 16.8308\n",
      "reconstruction loss = 0.0101, similarity loss: 0.3478\n",
      "Epoch 93, loss = 0.7112, time: 16.8476\n",
      "reconstruction loss = 0.0076, similarity loss: 0.3307\n",
      "Epoch 94, loss = 0.6064, time: 16.6500\n",
      "reconstruction loss = 0.0063, similarity loss: 0.2934\n",
      "Epoch 95, loss = 0.5841, time: 16.7473\n",
      "reconstruction loss = 0.0063, similarity loss: 0.2711\n",
      "Epoch 96, loss = 0.6043, time: 16.8372\n",
      "reconstruction loss = 0.0072, similarity loss: 0.2437\n",
      "Epoch 97, loss = 0.6552, time: 16.8720\n",
      "reconstruction loss = 0.0065, similarity loss: 0.3280\n",
      "Epoch 98, loss = 0.5479, time: 16.6695\n",
      "reconstruction loss = 0.0061, similarity loss: 0.2421\n",
      "Epoch 99, loss = 0.6670, time: 16.8066\n",
      "reconstruction loss = 0.0072, similarity loss: 0.3074\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.9777, val.loss = 1.7447, val.acc = 0.4252\n",
      "Epoch 1, loss = 1.6564, val.loss = 1.5898, val.acc = 0.4780\n",
      "Epoch 2, loss = 1.5388, val.loss = 1.5048, val.acc = 0.5094\n",
      "Epoch 3, loss = 1.4651, val.loss = 1.4465, val.acc = 0.5304\n",
      "Epoch 4, loss = 1.4116, val.loss = 1.4029, val.acc = 0.5430\n",
      "Epoch 5, loss = 1.3699, val.loss = 1.3684, val.acc = 0.5500\n",
      "Epoch 6, loss = 1.3359, val.loss = 1.3402, val.acc = 0.5578\n",
      "Epoch 7, loss = 1.3072, val.loss = 1.3165, val.acc = 0.5628\n",
      "Epoch 8, loss = 1.2825, val.loss = 1.2963, val.acc = 0.5688\n",
      "Epoch 9, loss = 1.2609, val.loss = 1.2786, val.acc = 0.5740\n",
      "Epoch 10, loss = 1.2416, val.loss = 1.2630, val.acc = 0.5780\n",
      "Epoch 11, loss = 1.2243, val.loss = 1.2491, val.acc = 0.5814\n",
      "Epoch 12, loss = 1.2085, val.loss = 1.2366, val.acc = 0.5848\n",
      "Epoch 13, loss = 1.1940, val.loss = 1.2253, val.acc = 0.5892\n",
      "Epoch 14, loss = 1.1806, val.loss = 1.2149, val.acc = 0.5932\n",
      "Epoch 15, loss = 1.1681, val.loss = 1.2054, val.acc = 0.5954\n",
      "Epoch 16, loss = 1.1565, val.loss = 1.1966, val.acc = 0.6006\n",
      "Epoch 17, loss = 1.1456, val.loss = 1.1884, val.acc = 0.6018\n",
      "Epoch 18, loss = 1.1352, val.loss = 1.1808, val.acc = 0.6040\n",
      "Epoch 19, loss = 1.1255, val.loss = 1.1737, val.acc = 0.6070\n",
      "Epoch 20, loss = 1.1162, val.loss = 1.1671, val.acc = 0.6084\n",
      "Epoch 21, loss = 1.1074, val.loss = 1.1608, val.acc = 0.6108\n",
      "Epoch 22, loss = 1.0990, val.loss = 1.1549, val.acc = 0.6126\n",
      "Epoch 23, loss = 1.0910, val.loss = 1.1492, val.acc = 0.6140\n",
      "Epoch 24, loss = 1.0833, val.loss = 1.1439, val.acc = 0.6154\n",
      "Epoch 25, loss = 1.0758, val.loss = 1.1389, val.acc = 0.6190\n",
      "Epoch 26, loss = 1.0687, val.loss = 1.1341, val.acc = 0.6200\n",
      "Epoch 27, loss = 1.0618, val.loss = 1.1295, val.acc = 0.6210\n",
      "Epoch 28, loss = 1.0552, val.loss = 1.1252, val.acc = 0.6236\n",
      "Epoch 29, loss = 1.0488, val.loss = 1.1210, val.acc = 0.6242\n",
      "Epoch 30, loss = 1.0426, val.loss = 1.1170, val.acc = 0.6266\n",
      "Epoch 31, loss = 1.0366, val.loss = 1.1132, val.acc = 0.6284\n",
      "Epoch 32, loss = 1.0308, val.loss = 1.1095, val.acc = 0.6300\n",
      "Epoch 33, loss = 1.0251, val.loss = 1.1060, val.acc = 0.6320\n",
      "Epoch 34, loss = 1.0196, val.loss = 1.1026, val.acc = 0.6338\n",
      "Epoch 35, loss = 1.0142, val.loss = 1.0993, val.acc = 0.6350\n",
      "Epoch 36, loss = 1.0090, val.loss = 1.0962, val.acc = 0.6360\n",
      "Epoch 37, loss = 1.0039, val.loss = 1.0931, val.acc = 0.6372\n",
      "Epoch 38, loss = 0.9990, val.loss = 1.0902, val.acc = 0.6376\n",
      "Epoch 39, loss = 0.9942, val.loss = 1.0874, val.acc = 0.6378\n",
      "Epoch 40, loss = 0.9894, val.loss = 1.0847, val.acc = 0.6384\n",
      "Epoch 41, loss = 0.9848, val.loss = 1.0821, val.acc = 0.6390\n",
      "Epoch 42, loss = 0.9803, val.loss = 1.0795, val.acc = 0.6400\n",
      "Epoch 43, loss = 0.9759, val.loss = 1.0770, val.acc = 0.6398\n",
      "Epoch 44, loss = 0.9716, val.loss = 1.0747, val.acc = 0.6416\n",
      "Epoch 45, loss = 0.9674, val.loss = 1.0724, val.acc = 0.6428\n",
      "Epoch 46, loss = 0.9632, val.loss = 1.0701, val.acc = 0.6424\n",
      "Epoch 47, loss = 0.9592, val.loss = 1.0679, val.acc = 0.6442\n",
      "Epoch 48, loss = 0.9552, val.loss = 1.0658, val.acc = 0.6436\n",
      "Epoch 49, loss = 0.9513, val.loss = 1.0638, val.acc = 0.6436\n",
      "Epoch 50, loss = 0.9475, val.loss = 1.0618, val.acc = 0.6448\n",
      "Epoch 51, loss = 0.9437, val.loss = 1.0599, val.acc = 0.6454\n",
      "Epoch 52, loss = 0.9400, val.loss = 1.0580, val.acc = 0.6472\n",
      "Epoch 53, loss = 0.9364, val.loss = 1.0562, val.acc = 0.6482\n",
      "Epoch 54, loss = 0.9328, val.loss = 1.0545, val.acc = 0.6498\n",
      "Epoch 55, loss = 0.9293, val.loss = 1.0527, val.acc = 0.6506\n",
      "Epoch 56, loss = 0.9259, val.loss = 1.0511, val.acc = 0.6526\n",
      "Epoch 57, loss = 0.9225, val.loss = 1.0495, val.acc = 0.6528\n",
      "Epoch 58, loss = 0.9192, val.loss = 1.0479, val.acc = 0.6532\n",
      "Epoch 59, loss = 0.9159, val.loss = 1.0463, val.acc = 0.6542\n",
      "Epoch 60, loss = 0.9127, val.loss = 1.0448, val.acc = 0.6550\n",
      "Epoch 61, loss = 0.9095, val.loss = 1.0434, val.acc = 0.6554\n",
      "Epoch 62, loss = 0.9063, val.loss = 1.0420, val.acc = 0.6564\n",
      "Epoch 63, loss = 0.9033, val.loss = 1.0406, val.acc = 0.6568\n",
      "Epoch 64, loss = 0.9002, val.loss = 1.0392, val.acc = 0.6568\n",
      "Epoch 65, loss = 0.8972, val.loss = 1.0379, val.acc = 0.6580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.8943, val.loss = 1.0366, val.acc = 0.6580\n",
      "Epoch 67, loss = 0.8914, val.loss = 1.0354, val.acc = 0.6580\n",
      "Epoch 68, loss = 0.8885, val.loss = 1.0342, val.acc = 0.6584\n",
      "Epoch 69, loss = 0.8856, val.loss = 1.0330, val.acc = 0.6592\n",
      "Epoch 70, loss = 0.8829, val.loss = 1.0318, val.acc = 0.6596\n",
      "Epoch 71, loss = 0.8801, val.loss = 1.0307, val.acc = 0.6598\n",
      "Epoch 72, loss = 0.8774, val.loss = 1.0296, val.acc = 0.6604\n",
      "Epoch 73, loss = 0.8747, val.loss = 1.0285, val.acc = 0.6604\n",
      "Epoch 74, loss = 0.8720, val.loss = 1.0275, val.acc = 0.6616\n",
      "Epoch 75, loss = 0.8694, val.loss = 1.0265, val.acc = 0.6616\n",
      "Epoch 76, loss = 0.8668, val.loss = 1.0255, val.acc = 0.6620\n",
      "Epoch 77, loss = 0.8643, val.loss = 1.0245, val.acc = 0.6610\n",
      "Epoch 78, loss = 0.8617, val.loss = 1.0235, val.acc = 0.6606\n",
      "Epoch 79, loss = 0.8592, val.loss = 1.0226, val.acc = 0.6606\n",
      "Epoch 80, loss = 0.8568, val.loss = 1.0217, val.acc = 0.6606\n",
      "Epoch 81, loss = 0.8543, val.loss = 1.0208, val.acc = 0.6604\n",
      "Epoch 82, loss = 0.8519, val.loss = 1.0199, val.acc = 0.6612\n",
      "Epoch 83, loss = 0.8495, val.loss = 1.0191, val.acc = 0.6612\n",
      "Epoch 84, loss = 0.8472, val.loss = 1.0183, val.acc = 0.6614\n",
      "Epoch 85, loss = 0.8448, val.loss = 1.0174, val.acc = 0.6610\n",
      "Epoch 86, loss = 0.8425, val.loss = 1.0167, val.acc = 0.6618\n",
      "Epoch 87, loss = 0.8402, val.loss = 1.0159, val.acc = 0.6626\n",
      "Epoch 88, loss = 0.8380, val.loss = 1.0151, val.acc = 0.6632\n",
      "Epoch 89, loss = 0.8358, val.loss = 1.0144, val.acc = 0.6630\n",
      "Epoch 90, loss = 0.8335, val.loss = 1.0137, val.acc = 0.6632\n",
      "Epoch 91, loss = 0.8314, val.loss = 1.0130, val.acc = 0.6632\n",
      "Epoch 92, loss = 0.8292, val.loss = 1.0123, val.acc = 0.6640\n",
      "Epoch 93, loss = 0.8270, val.loss = 1.0116, val.acc = 0.6642\n",
      "Epoch 94, loss = 0.8249, val.loss = 1.0109, val.acc = 0.6644\n",
      "Epoch 95, loss = 0.8228, val.loss = 1.0103, val.acc = 0.6642\n",
      "Epoch 96, loss = 0.8207, val.loss = 1.0097, val.acc = 0.6640\n",
      "Epoch 97, loss = 0.8187, val.loss = 1.0090, val.acc = 0.6638\n",
      "Epoch 98, loss = 0.8166, val.loss = 1.0084, val.acc = 0.6636\n",
      "Epoch 99, loss = 0.8146, val.loss = 1.0078, val.acc = 0.6636\n",
      "Epoch 100, loss = 0.8126, val.loss = 1.0073, val.acc = 0.6642\n",
      "Epoch 101, loss = 0.8106, val.loss = 1.0067, val.acc = 0.6638\n",
      "Epoch 102, loss = 0.8087, val.loss = 1.0061, val.acc = 0.6640\n",
      "Epoch 103, loss = 0.8067, val.loss = 1.0056, val.acc = 0.6640\n",
      "Epoch 104, loss = 0.8048, val.loss = 1.0051, val.acc = 0.6642\n",
      "Epoch 105, loss = 0.8029, val.loss = 1.0046, val.acc = 0.6646\n",
      "Epoch 106, loss = 0.8010, val.loss = 1.0041, val.acc = 0.6646\n",
      "Epoch 107, loss = 0.7991, val.loss = 1.0036, val.acc = 0.6646\n",
      "Epoch 108, loss = 0.7972, val.loss = 1.0031, val.acc = 0.6652\n",
      "Epoch 109, loss = 0.7954, val.loss = 1.0026, val.acc = 0.6656\n",
      "Epoch 110, loss = 0.7935, val.loss = 1.0021, val.acc = 0.6660\n",
      "Epoch 111, loss = 0.7917, val.loss = 1.0017, val.acc = 0.6660\n",
      "Epoch 112, loss = 0.7899, val.loss = 1.0013, val.acc = 0.6656\n",
      "Epoch 113, loss = 0.7881, val.loss = 1.0008, val.acc = 0.6662\n",
      "Epoch 114, loss = 0.7864, val.loss = 1.0004, val.acc = 0.6662\n",
      "Epoch 115, loss = 0.7846, val.loss = 1.0000, val.acc = 0.6662\n",
      "Epoch 116, loss = 0.7829, val.loss = 0.9996, val.acc = 0.6664\n",
      "Epoch 117, loss = 0.7811, val.loss = 0.9992, val.acc = 0.6666\n",
      "Epoch 118, loss = 0.7794, val.loss = 0.9988, val.acc = 0.6670\n",
      "Epoch 119, loss = 0.7777, val.loss = 0.9984, val.acc = 0.6664\n",
      "Epoch 120, loss = 0.7760, val.loss = 0.9981, val.acc = 0.6664\n",
      "Epoch 121, loss = 0.7744, val.loss = 0.9977, val.acc = 0.6664\n",
      "Epoch 122, loss = 0.7727, val.loss = 0.9973, val.acc = 0.6670\n",
      "Epoch 123, loss = 0.7710, val.loss = 0.9970, val.acc = 0.6668\n",
      "Epoch 124, loss = 0.7694, val.loss = 0.9967, val.acc = 0.6662\n",
      "Epoch 125, loss = 0.7678, val.loss = 0.9963, val.acc = 0.6662\n",
      "Epoch 126, loss = 0.7662, val.loss = 0.9960, val.acc = 0.6666\n",
      "Epoch 127, loss = 0.7646, val.loss = 0.9957, val.acc = 0.6670\n",
      "Epoch 128, loss = 0.7630, val.loss = 0.9954, val.acc = 0.6670\n",
      "Epoch 129, loss = 0.7614, val.loss = 0.9951, val.acc = 0.6664\n",
      "Epoch 130, loss = 0.7598, val.loss = 0.9948, val.acc = 0.6666\n",
      "Epoch 131, loss = 0.7583, val.loss = 0.9945, val.acc = 0.6662\n",
      "Epoch 132, loss = 0.7567, val.loss = 0.9942, val.acc = 0.6660\n",
      "Epoch 133, loss = 0.7552, val.loss = 0.9940, val.acc = 0.6662\n",
      "Epoch 134, loss = 0.7537, val.loss = 0.9937, val.acc = 0.6662\n",
      "Epoch 135, loss = 0.7522, val.loss = 0.9934, val.acc = 0.6660\n",
      "Epoch 136, loss = 0.7507, val.loss = 0.9932, val.acc = 0.6664\n",
      "Epoch 137, loss = 0.7492, val.loss = 0.9929, val.acc = 0.6660\n",
      "Epoch 138, loss = 0.7477, val.loss = 0.9927, val.acc = 0.6662\n",
      "Epoch 139, loss = 0.7462, val.loss = 0.9925, val.acc = 0.6660\n",
      "Epoch 140, loss = 0.7447, val.loss = 0.9922, val.acc = 0.6662\n",
      "Epoch 141, loss = 0.7433, val.loss = 0.9920, val.acc = 0.6664\n",
      "Epoch 142, loss = 0.7419, val.loss = 0.9918, val.acc = 0.6672\n",
      "Epoch 143, loss = 0.7404, val.loss = 0.9916, val.acc = 0.6674\n",
      "Epoch 144, loss = 0.7390, val.loss = 0.9914, val.acc = 0.6678\n",
      "Epoch 145, loss = 0.7376, val.loss = 0.9912, val.acc = 0.6676\n",
      "Epoch 146, loss = 0.7362, val.loss = 0.9910, val.acc = 0.6678\n",
      "Epoch 147, loss = 0.7348, val.loss = 0.9908, val.acc = 0.6674\n",
      "Epoch 148, loss = 0.7334, val.loss = 0.9906, val.acc = 0.6672\n",
      "Epoch 149, loss = 0.7320, val.loss = 0.9904, val.acc = 0.6676\n",
      "Rep: 1, te.acc = 0.6555\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6555]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 50\n",
    "vis = visdom.Visdom(port=8097, env='ae_2l_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-02T08:48:09.365031Z",
     "start_time": "2022-04-02T08:16:20.373346Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/channel_3/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_100_CLF_Cifar10_Adam_LR_5e-05_Epochs_150\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=3072, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(3, 32, 32))\n",
      "    (deconv): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 5.9762, time: 16.2447\n",
      "reconstruction loss = 0.0534, similarity loss: 0.6359\n",
      "Epoch 1, loss = 4.0300, time: 16.1329\n",
      "reconstruction loss = 0.0320, similarity loss: 0.8309\n",
      "Epoch 2, loss = 2.7281, time: 16.0106\n",
      "reconstruction loss = 0.0203, similarity loss: 0.6936\n",
      "Epoch 3, loss = 2.3199, time: 16.1637\n",
      "reconstruction loss = 0.0174, similarity loss: 0.5755\n",
      "Epoch 4, loss = 2.2182, time: 16.1561\n",
      "reconstruction loss = 0.0141, similarity loss: 0.8097\n",
      "Epoch 5, loss = 2.0868, time: 16.2397\n",
      "reconstruction loss = 0.0131, similarity loss: 0.7752\n",
      "Epoch 6, loss = 2.0567, time: 16.1888\n",
      "reconstruction loss = 0.0133, similarity loss: 0.7273\n",
      "Epoch 7, loss = 1.9396, time: 16.2165\n",
      "reconstruction loss = 0.0125, similarity loss: 0.6862\n",
      "Epoch 8, loss = 1.7463, time: 16.1717\n",
      "reconstruction loss = 0.0120, similarity loss: 0.5438\n",
      "Epoch 9, loss = 1.8136, time: 16.5660\n",
      "reconstruction loss = 0.0111, similarity loss: 0.7053\n",
      "Epoch 10, loss = 1.6730, time: 16.7286\n",
      "reconstruction loss = 0.0105, similarity loss: 0.6232\n",
      "Epoch 11, loss = 1.6651, time: 16.8048\n",
      "reconstruction loss = 0.0108, similarity loss: 0.5806\n",
      "Epoch 12, loss = 1.5134, time: 16.7298\n",
      "reconstruction loss = 0.0098, similarity loss: 0.5324\n",
      "Epoch 13, loss = 1.5484, time: 16.7809\n",
      "reconstruction loss = 0.0092, similarity loss: 0.6263\n",
      "Epoch 14, loss = 1.5629, time: 16.8193\n",
      "reconstruction loss = 0.0098, similarity loss: 0.5802\n",
      "Epoch 15, loss = 1.3589, time: 16.7471\n",
      "reconstruction loss = 0.0085, similarity loss: 0.5058\n",
      "Epoch 16, loss = 1.4944, time: 16.6542\n",
      "reconstruction loss = 0.0092, similarity loss: 0.5704\n",
      "Epoch 17, loss = 1.3606, time: 16.6757\n",
      "reconstruction loss = 0.0080, similarity loss: 0.5593\n",
      "Epoch 18, loss = 1.3534, time: 16.6789\n",
      "reconstruction loss = 0.0087, similarity loss: 0.4855\n",
      "Epoch 19, loss = 1.3930, time: 16.5985\n",
      "reconstruction loss = 0.0090, similarity loss: 0.4934\n",
      "Epoch 20, loss = 1.3388, time: 16.7671\n",
      "reconstruction loss = 0.0082, similarity loss: 0.5173\n",
      "Epoch 21, loss = 1.3484, time: 16.7998\n",
      "reconstruction loss = 0.0083, similarity loss: 0.5214\n",
      "Epoch 22, loss = 1.3523, time: 16.6296\n",
      "reconstruction loss = 0.0083, similarity loss: 0.5266\n",
      "Epoch 23, loss = 1.2994, time: 16.6290\n",
      "reconstruction loss = 0.0083, similarity loss: 0.4732\n",
      "Epoch 24, loss = 1.2369, time: 16.8041\n",
      "reconstruction loss = 0.0077, similarity loss: 0.4676\n",
      "Epoch 25, loss = 1.3498, time: 16.6948\n",
      "reconstruction loss = 0.0082, similarity loss: 0.5278\n",
      "Epoch 26, loss = 1.2308, time: 16.7608\n",
      "reconstruction loss = 0.0081, similarity loss: 0.4195\n",
      "Epoch 27, loss = 1.2459, time: 16.6856\n",
      "reconstruction loss = 0.0082, similarity loss: 0.4227\n",
      "Epoch 28, loss = 1.2555, time: 16.7137\n",
      "reconstruction loss = 0.0083, similarity loss: 0.4297\n",
      "Epoch 29, loss = 1.2105, time: 16.7708\n",
      "reconstruction loss = 0.0075, similarity loss: 0.4577\n",
      "Epoch 30, loss = 1.1499, time: 16.6136\n",
      "reconstruction loss = 0.0074, similarity loss: 0.4084\n",
      "Epoch 31, loss = 1.2561, time: 16.6618\n",
      "reconstruction loss = 0.0084, similarity loss: 0.4163\n",
      "Epoch 32, loss = 1.3797, time: 16.7238\n",
      "reconstruction loss = 0.0086, similarity loss: 0.5202\n",
      "Epoch 33, loss = 1.2139, time: 16.7972\n",
      "reconstruction loss = 0.0077, similarity loss: 0.4455\n",
      "Epoch 34, loss = 1.2425, time: 16.6341\n",
      "reconstruction loss = 0.0079, similarity loss: 0.4557\n",
      "Epoch 35, loss = 1.0541, time: 16.7597\n",
      "reconstruction loss = 0.0070, similarity loss: 0.3514\n",
      "Epoch 36, loss = 1.2825, time: 16.6908\n",
      "reconstruction loss = 0.0086, similarity loss: 0.4214\n",
      "Epoch 37, loss = 1.2080, time: 16.7008\n",
      "reconstruction loss = 0.0075, similarity loss: 0.4535\n",
      "Epoch 38, loss = 1.1646, time: 16.6748\n",
      "reconstruction loss = 0.0072, similarity loss: 0.4412\n",
      "Epoch 39, loss = 1.0664, time: 16.7701\n",
      "reconstruction loss = 0.0070, similarity loss: 0.3707\n",
      "Epoch 40, loss = 1.1668, time: 16.6889\n",
      "reconstruction loss = 0.0080, similarity loss: 0.3670\n",
      "Epoch 41, loss = 1.0757, time: 16.6967\n",
      "reconstruction loss = 0.0073, similarity loss: 0.3483\n",
      "Epoch 42, loss = 1.1499, time: 16.6980\n",
      "reconstruction loss = 0.0076, similarity loss: 0.3882\n",
      "Epoch 43, loss = 1.0755, time: 16.6398\n",
      "reconstruction loss = 0.0072, similarity loss: 0.3557\n",
      "Epoch 44, loss = 1.0981, time: 16.7350\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3912\n",
      "Epoch 45, loss = 1.1376, time: 16.1228\n",
      "reconstruction loss = 0.0075, similarity loss: 0.3908\n",
      "Epoch 46, loss = 1.1629, time: 16.2060\n",
      "reconstruction loss = 0.0078, similarity loss: 0.3870\n",
      "Epoch 47, loss = 1.1745, time: 16.0486\n",
      "reconstruction loss = 0.0076, similarity loss: 0.4193\n",
      "Epoch 48, loss = 1.0811, time: 16.1310\n",
      "reconstruction loss = 0.0068, similarity loss: 0.4000\n",
      "Epoch 49, loss = 1.0797, time: 16.1453\n",
      "reconstruction loss = 0.0067, similarity loss: 0.4053\n",
      "Epoch 50, loss = 1.1821, time: 16.1173\n",
      "reconstruction loss = 0.0076, similarity loss: 0.4182\n",
      "Epoch 51, loss = 1.1211, time: 16.0428\n",
      "reconstruction loss = 0.0075, similarity loss: 0.3720\n",
      "Epoch 52, loss = 1.1257, time: 16.2018\n",
      "reconstruction loss = 0.0073, similarity loss: 0.3952\n",
      "Epoch 53, loss = 1.0698, time: 16.1729\n",
      "reconstruction loss = 0.0068, similarity loss: 0.3929\n",
      "Epoch 54, loss = 1.0519, time: 16.1384\n",
      "reconstruction loss = 0.0068, similarity loss: 0.3694\n",
      "Epoch 55, loss = 1.0996, time: 16.1067\n",
      "reconstruction loss = 0.0072, similarity loss: 0.3783\n",
      "Epoch 56, loss = 1.0837, time: 16.2090\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3476\n",
      "Epoch 57, loss = 0.9897, time: 16.1761\n",
      "reconstruction loss = 0.0065, similarity loss: 0.3372\n",
      "Epoch 58, loss = 1.1516, time: 16.0704\n",
      "reconstruction loss = 0.0074, similarity loss: 0.4128\n",
      "Epoch 59, loss = 0.9676, time: 16.0538\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3299\n",
      "Epoch 60, loss = 1.0260, time: 16.2060\n",
      "reconstruction loss = 0.0067, similarity loss: 0.3570\n",
      "Epoch 61, loss = 1.0014, time: 16.1544\n",
      "reconstruction loss = 0.0066, similarity loss: 0.3410\n",
      "Epoch 62, loss = 1.0341, time: 16.1332\n",
      "reconstruction loss = 0.0068, similarity loss: 0.3503\n",
      "Epoch 63, loss = 1.0160, time: 16.2655\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3785\n",
      "Epoch 64, loss = 1.1426, time: 16.7558\n",
      "reconstruction loss = 0.0079, similarity loss: 0.3537\n",
      "Epoch 65, loss = 1.1052, time: 16.6849\n",
      "reconstruction loss = 0.0071, similarity loss: 0.3904\n",
      "Epoch 66, loss = 0.9885, time: 16.5794\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3442\n",
      "Epoch 67, loss = 1.0552, time: 16.8063\n",
      "reconstruction loss = 0.0069, similarity loss: 0.3645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68, loss = 1.1802, time: 16.8945\n",
      "reconstruction loss = 0.0077, similarity loss: 0.4120\n",
      "Epoch 69, loss = 1.0338, time: 16.6420\n",
      "reconstruction loss = 0.0068, similarity loss: 0.3539\n",
      "Epoch 70, loss = 0.9970, time: 16.7258\n",
      "reconstruction loss = 0.0066, similarity loss: 0.3331\n",
      "Epoch 71, loss = 1.2304, time: 16.6273\n",
      "reconstruction loss = 0.0077, similarity loss: 0.4588\n",
      "Epoch 72, loss = 1.0437, time: 16.6713\n",
      "reconstruction loss = 0.0068, similarity loss: 0.3613\n",
      "Epoch 73, loss = 0.9357, time: 16.5396\n",
      "reconstruction loss = 0.0065, similarity loss: 0.2820\n",
      "Epoch 74, loss = 1.0259, time: 16.7328\n",
      "reconstruction loss = 0.0063, similarity loss: 0.3953\n",
      "Epoch 75, loss = 0.9448, time: 16.7868\n",
      "reconstruction loss = 0.0068, similarity loss: 0.2653\n",
      "Epoch 76, loss = 0.9420, time: 16.7043\n",
      "reconstruction loss = 0.0063, similarity loss: 0.3110\n",
      "Epoch 77, loss = 0.9565, time: 16.7678\n",
      "reconstruction loss = 0.0062, similarity loss: 0.3343\n",
      "Epoch 78, loss = 0.9670, time: 16.6238\n",
      "reconstruction loss = 0.0065, similarity loss: 0.3174\n",
      "Epoch 79, loss = 1.4068, time: 16.7838\n",
      "reconstruction loss = 0.0089, similarity loss: 0.5180\n",
      "Epoch 80, loss = 1.1209, time: 16.7501\n",
      "reconstruction loss = 0.0074, similarity loss: 0.3772\n",
      "Epoch 81, loss = 1.0251, time: 16.7170\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3871\n",
      "Epoch 82, loss = 0.9869, time: 16.7256\n",
      "reconstruction loss = 0.0061, similarity loss: 0.3725\n",
      "Epoch 83, loss = 0.9190, time: 16.7619\n",
      "reconstruction loss = 0.0061, similarity loss: 0.3096\n",
      "Epoch 84, loss = 1.0050, time: 16.7686\n",
      "reconstruction loss = 0.0067, similarity loss: 0.3356\n",
      "Epoch 85, loss = 0.9753, time: 16.6995\n",
      "reconstruction loss = 0.0068, similarity loss: 0.2973\n",
      "Epoch 86, loss = 0.9558, time: 16.7542\n",
      "reconstruction loss = 0.0064, similarity loss: 0.3131\n",
      "Epoch 87, loss = 0.9183, time: 16.7415\n",
      "reconstruction loss = 0.0061, similarity loss: 0.3038\n",
      "Epoch 88, loss = 0.8661, time: 16.7008\n",
      "reconstruction loss = 0.0056, similarity loss: 0.3034\n",
      "Epoch 89, loss = 1.0194, time: 16.7627\n",
      "reconstruction loss = 0.0063, similarity loss: 0.3906\n",
      "Epoch 90, loss = 0.8725, time: 16.7978\n",
      "reconstruction loss = 0.0057, similarity loss: 0.3051\n",
      "Epoch 91, loss = 0.8494, time: 16.8094\n",
      "reconstruction loss = 0.0054, similarity loss: 0.3125\n",
      "Epoch 92, loss = 0.9473, time: 16.8636\n",
      "reconstruction loss = 0.0062, similarity loss: 0.3279\n",
      "Epoch 93, loss = 0.9094, time: 16.6840\n",
      "reconstruction loss = 0.0058, similarity loss: 0.3307\n",
      "Epoch 94, loss = 0.8868, time: 16.7797\n",
      "reconstruction loss = 0.0060, similarity loss: 0.2908\n",
      "Epoch 95, loss = 1.0499, time: 16.6512\n",
      "reconstruction loss = 0.0067, similarity loss: 0.3789\n",
      "Epoch 96, loss = 0.9857, time: 16.6920\n",
      "reconstruction loss = 0.0066, similarity loss: 0.3225\n",
      "Epoch 97, loss = 0.9053, time: 16.6311\n",
      "reconstruction loss = 0.0056, similarity loss: 0.3449\n",
      "Epoch 98, loss = 0.8776, time: 16.7120\n",
      "reconstruction loss = 0.0058, similarity loss: 0.2948\n",
      "Epoch 99, loss = 0.9874, time: 16.5713\n",
      "reconstruction loss = 0.0063, similarity loss: 0.3588\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.9754, val.loss = 1.7637, val.acc = 0.4156\n",
      "Epoch 1, loss = 1.6839, val.loss = 1.6216, val.acc = 0.4560\n",
      "Epoch 2, loss = 1.5741, val.loss = 1.5419, val.acc = 0.4842\n",
      "Epoch 3, loss = 1.5037, val.loss = 1.4858, val.acc = 0.5088\n",
      "Epoch 4, loss = 1.4515, val.loss = 1.4430, val.acc = 0.5230\n",
      "Epoch 5, loss = 1.4103, val.loss = 1.4086, val.acc = 0.5344\n",
      "Epoch 6, loss = 1.3763, val.loss = 1.3800, val.acc = 0.5452\n",
      "Epoch 7, loss = 1.3476, val.loss = 1.3558, val.acc = 0.5538\n",
      "Epoch 8, loss = 1.3227, val.loss = 1.3349, val.acc = 0.5608\n",
      "Epoch 9, loss = 1.3008, val.loss = 1.3165, val.acc = 0.5660\n",
      "Epoch 10, loss = 1.2812, val.loss = 1.3002, val.acc = 0.5714\n",
      "Epoch 11, loss = 1.2636, val.loss = 1.2855, val.acc = 0.5760\n",
      "Epoch 12, loss = 1.2476, val.loss = 1.2723, val.acc = 0.5794\n",
      "Epoch 13, loss = 1.2330, val.loss = 1.2603, val.acc = 0.5844\n",
      "Epoch 14, loss = 1.2195, val.loss = 1.2493, val.acc = 0.5894\n",
      "Epoch 15, loss = 1.2069, val.loss = 1.2391, val.acc = 0.5880\n",
      "Epoch 16, loss = 1.1952, val.loss = 1.2298, val.acc = 0.5896\n",
      "Epoch 17, loss = 1.1843, val.loss = 1.2210, val.acc = 0.5916\n",
      "Epoch 18, loss = 1.1740, val.loss = 1.2129, val.acc = 0.5948\n",
      "Epoch 19, loss = 1.1642, val.loss = 1.2053, val.acc = 0.5972\n",
      "Epoch 20, loss = 1.1550, val.loss = 1.1982, val.acc = 0.5982\n",
      "Epoch 21, loss = 1.1463, val.loss = 1.1914, val.acc = 0.5994\n",
      "Epoch 22, loss = 1.1380, val.loss = 1.1851, val.acc = 0.6010\n",
      "Epoch 23, loss = 1.1300, val.loss = 1.1791, val.acc = 0.6020\n",
      "Epoch 24, loss = 1.1224, val.loss = 1.1734, val.acc = 0.6040\n",
      "Epoch 25, loss = 1.1152, val.loss = 1.1680, val.acc = 0.6052\n",
      "Epoch 26, loss = 1.1082, val.loss = 1.1629, val.acc = 0.6068\n",
      "Epoch 27, loss = 1.1015, val.loss = 1.1580, val.acc = 0.6080\n",
      "Epoch 28, loss = 1.0950, val.loss = 1.1533, val.acc = 0.6102\n",
      "Epoch 29, loss = 1.0887, val.loss = 1.1488, val.acc = 0.6112\n",
      "Epoch 30, loss = 1.0827, val.loss = 1.1445, val.acc = 0.6122\n",
      "Epoch 31, loss = 1.0768, val.loss = 1.1404, val.acc = 0.6144\n",
      "Epoch 32, loss = 1.0712, val.loss = 1.1365, val.acc = 0.6154\n",
      "Epoch 33, loss = 1.0657, val.loss = 1.1327, val.acc = 0.6162\n",
      "Epoch 34, loss = 1.0604, val.loss = 1.1291, val.acc = 0.6182\n",
      "Epoch 35, loss = 1.0552, val.loss = 1.1256, val.acc = 0.6182\n",
      "Epoch 36, loss = 1.0502, val.loss = 1.1222, val.acc = 0.6200\n",
      "Epoch 37, loss = 1.0453, val.loss = 1.1189, val.acc = 0.6218\n",
      "Epoch 38, loss = 1.0405, val.loss = 1.1158, val.acc = 0.6234\n",
      "Epoch 39, loss = 1.0359, val.loss = 1.1128, val.acc = 0.6250\n",
      "Epoch 40, loss = 1.0314, val.loss = 1.1098, val.acc = 0.6260\n",
      "Epoch 41, loss = 1.0270, val.loss = 1.1070, val.acc = 0.6278\n",
      "Epoch 42, loss = 1.0227, val.loss = 1.1043, val.acc = 0.6288\n",
      "Epoch 43, loss = 1.0184, val.loss = 1.1016, val.acc = 0.6302\n",
      "Epoch 44, loss = 1.0143, val.loss = 1.0990, val.acc = 0.6304\n",
      "Epoch 45, loss = 1.0103, val.loss = 1.0965, val.acc = 0.6320\n",
      "Epoch 46, loss = 1.0063, val.loss = 1.0941, val.acc = 0.6332\n",
      "Epoch 47, loss = 1.0025, val.loss = 1.0918, val.acc = 0.6336\n",
      "Epoch 48, loss = 0.9987, val.loss = 1.0895, val.acc = 0.6336\n",
      "Epoch 49, loss = 0.9950, val.loss = 1.0873, val.acc = 0.6350\n",
      "Epoch 50, loss = 0.9914, val.loss = 1.0851, val.acc = 0.6354\n",
      "Epoch 51, loss = 0.9878, val.loss = 1.0830, val.acc = 0.6366\n",
      "Epoch 52, loss = 0.9843, val.loss = 1.0810, val.acc = 0.6378\n",
      "Epoch 53, loss = 0.9809, val.loss = 1.0790, val.acc = 0.6380\n",
      "Epoch 54, loss = 0.9775, val.loss = 1.0771, val.acc = 0.6388\n",
      "Epoch 55, loss = 0.9742, val.loss = 1.0752, val.acc = 0.6396\n",
      "Epoch 56, loss = 0.9709, val.loss = 1.0733, val.acc = 0.6402\n",
      "Epoch 57, loss = 0.9677, val.loss = 1.0716, val.acc = 0.6418\n",
      "Epoch 58, loss = 0.9645, val.loss = 1.0698, val.acc = 0.6420\n",
      "Epoch 59, loss = 0.9614, val.loss = 1.0681, val.acc = 0.6430\n",
      "Epoch 60, loss = 0.9584, val.loss = 1.0665, val.acc = 0.6430\n",
      "Epoch 61, loss = 0.9554, val.loss = 1.0648, val.acc = 0.6436\n",
      "Epoch 62, loss = 0.9524, val.loss = 1.0633, val.acc = 0.6448\n",
      "Epoch 63, loss = 0.9495, val.loss = 1.0617, val.acc = 0.6462\n",
      "Epoch 64, loss = 0.9467, val.loss = 1.0602, val.acc = 0.6466\n",
      "Epoch 65, loss = 0.9438, val.loss = 1.0588, val.acc = 0.6474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66, loss = 0.9411, val.loss = 1.0573, val.acc = 0.6474\n",
      "Epoch 67, loss = 0.9383, val.loss = 1.0559, val.acc = 0.6480\n",
      "Epoch 68, loss = 0.9356, val.loss = 1.0546, val.acc = 0.6482\n",
      "Epoch 69, loss = 0.9329, val.loss = 1.0532, val.acc = 0.6494\n",
      "Epoch 70, loss = 0.9303, val.loss = 1.0519, val.acc = 0.6498\n",
      "Epoch 71, loss = 0.9277, val.loss = 1.0506, val.acc = 0.6498\n",
      "Epoch 72, loss = 0.9252, val.loss = 1.0494, val.acc = 0.6500\n",
      "Epoch 73, loss = 0.9226, val.loss = 1.0481, val.acc = 0.6506\n",
      "Epoch 74, loss = 0.9201, val.loss = 1.0469, val.acc = 0.6510\n",
      "Epoch 75, loss = 0.9177, val.loss = 1.0458, val.acc = 0.6522\n",
      "Epoch 76, loss = 0.9152, val.loss = 1.0446, val.acc = 0.6528\n",
      "Epoch 77, loss = 0.9128, val.loss = 1.0435, val.acc = 0.6538\n",
      "Epoch 78, loss = 0.9105, val.loss = 1.0424, val.acc = 0.6540\n",
      "Epoch 79, loss = 0.9081, val.loss = 1.0413, val.acc = 0.6538\n",
      "Epoch 80, loss = 0.9058, val.loss = 1.0402, val.acc = 0.6534\n",
      "Epoch 81, loss = 0.9035, val.loss = 1.0392, val.acc = 0.6538\n",
      "Epoch 82, loss = 0.9012, val.loss = 1.0382, val.acc = 0.6546\n",
      "Epoch 83, loss = 0.8990, val.loss = 1.0372, val.acc = 0.6550\n",
      "Epoch 84, loss = 0.8968, val.loss = 1.0362, val.acc = 0.6552\n",
      "Epoch 85, loss = 0.8946, val.loss = 1.0353, val.acc = 0.6556\n",
      "Epoch 86, loss = 0.8924, val.loss = 1.0343, val.acc = 0.6560\n",
      "Epoch 87, loss = 0.8903, val.loss = 1.0334, val.acc = 0.6552\n",
      "Epoch 88, loss = 0.8882, val.loss = 1.0325, val.acc = 0.6552\n",
      "Epoch 89, loss = 0.8861, val.loss = 1.0316, val.acc = 0.6556\n",
      "Epoch 90, loss = 0.8840, val.loss = 1.0307, val.acc = 0.6564\n",
      "Epoch 91, loss = 0.8819, val.loss = 1.0299, val.acc = 0.6568\n",
      "Epoch 92, loss = 0.8799, val.loss = 1.0290, val.acc = 0.6570\n",
      "Epoch 93, loss = 0.8779, val.loss = 1.0282, val.acc = 0.6572\n",
      "Epoch 94, loss = 0.8759, val.loss = 1.0274, val.acc = 0.6572\n",
      "Epoch 95, loss = 0.8739, val.loss = 1.0266, val.acc = 0.6572\n",
      "Epoch 96, loss = 0.8720, val.loss = 1.0258, val.acc = 0.6578\n",
      "Epoch 97, loss = 0.8700, val.loss = 1.0251, val.acc = 0.6582\n",
      "Epoch 98, loss = 0.8681, val.loss = 1.0243, val.acc = 0.6580\n",
      "Epoch 99, loss = 0.8662, val.loss = 1.0236, val.acc = 0.6582\n",
      "Epoch 100, loss = 0.8643, val.loss = 1.0229, val.acc = 0.6580\n",
      "Epoch 101, loss = 0.8625, val.loss = 1.0222, val.acc = 0.6582\n",
      "Epoch 102, loss = 0.8606, val.loss = 1.0215, val.acc = 0.6586\n",
      "Epoch 103, loss = 0.8588, val.loss = 1.0208, val.acc = 0.6592\n",
      "Epoch 104, loss = 0.8570, val.loss = 1.0201, val.acc = 0.6596\n",
      "Epoch 105, loss = 0.8552, val.loss = 1.0195, val.acc = 0.6606\n",
      "Epoch 106, loss = 0.8534, val.loss = 1.0188, val.acc = 0.6618\n",
      "Epoch 107, loss = 0.8516, val.loss = 1.0182, val.acc = 0.6624\n",
      "Epoch 108, loss = 0.8499, val.loss = 1.0176, val.acc = 0.6626\n",
      "Epoch 109, loss = 0.8482, val.loss = 1.0170, val.acc = 0.6622\n",
      "Epoch 110, loss = 0.8464, val.loss = 1.0164, val.acc = 0.6624\n",
      "Epoch 111, loss = 0.8447, val.loss = 1.0158, val.acc = 0.6624\n",
      "Epoch 112, loss = 0.8430, val.loss = 1.0152, val.acc = 0.6626\n",
      "Epoch 113, loss = 0.8414, val.loss = 1.0146, val.acc = 0.6630\n",
      "Epoch 114, loss = 0.8397, val.loss = 1.0140, val.acc = 0.6628\n",
      "Epoch 115, loss = 0.8380, val.loss = 1.0135, val.acc = 0.6632\n",
      "Epoch 116, loss = 0.8364, val.loss = 1.0130, val.acc = 0.6632\n",
      "Epoch 117, loss = 0.8348, val.loss = 1.0124, val.acc = 0.6632\n",
      "Epoch 118, loss = 0.8332, val.loss = 1.0119, val.acc = 0.6634\n",
      "Epoch 119, loss = 0.8316, val.loss = 1.0114, val.acc = 0.6640\n",
      "Epoch 120, loss = 0.8300, val.loss = 1.0109, val.acc = 0.6644\n",
      "Epoch 121, loss = 0.8284, val.loss = 1.0104, val.acc = 0.6648\n",
      "Epoch 122, loss = 0.8268, val.loss = 1.0099, val.acc = 0.6652\n",
      "Epoch 123, loss = 0.8253, val.loss = 1.0094, val.acc = 0.6654\n",
      "Epoch 124, loss = 0.8237, val.loss = 1.0089, val.acc = 0.6656\n",
      "Epoch 125, loss = 0.8222, val.loss = 1.0085, val.acc = 0.6654\n",
      "Epoch 126, loss = 0.8207, val.loss = 1.0080, val.acc = 0.6652\n",
      "Epoch 127, loss = 0.8192, val.loss = 1.0076, val.acc = 0.6652\n",
      "Epoch 128, loss = 0.8177, val.loss = 1.0071, val.acc = 0.6656\n",
      "Epoch 129, loss = 0.8162, val.loss = 1.0067, val.acc = 0.6656\n",
      "Epoch 130, loss = 0.8147, val.loss = 1.0063, val.acc = 0.6662\n",
      "Epoch 131, loss = 0.8133, val.loss = 1.0058, val.acc = 0.6664\n",
      "Epoch 132, loss = 0.8118, val.loss = 1.0054, val.acc = 0.6670\n",
      "Epoch 133, loss = 0.8104, val.loss = 1.0050, val.acc = 0.6674\n",
      "Epoch 134, loss = 0.8089, val.loss = 1.0046, val.acc = 0.6678\n",
      "Epoch 135, loss = 0.8075, val.loss = 1.0042, val.acc = 0.6680\n",
      "Epoch 136, loss = 0.8061, val.loss = 1.0038, val.acc = 0.6676\n",
      "Epoch 137, loss = 0.8047, val.loss = 1.0035, val.acc = 0.6680\n",
      "Epoch 138, loss = 0.8033, val.loss = 1.0031, val.acc = 0.6682\n",
      "Epoch 139, loss = 0.8019, val.loss = 1.0027, val.acc = 0.6680\n",
      "Epoch 140, loss = 0.8005, val.loss = 1.0023, val.acc = 0.6684\n",
      "Epoch 141, loss = 0.7992, val.loss = 1.0020, val.acc = 0.6688\n",
      "Epoch 142, loss = 0.7978, val.loss = 1.0016, val.acc = 0.6692\n",
      "Epoch 143, loss = 0.7964, val.loss = 1.0013, val.acc = 0.6688\n",
      "Epoch 144, loss = 0.7951, val.loss = 1.0010, val.acc = 0.6684\n",
      "Epoch 145, loss = 0.7938, val.loss = 1.0006, val.acc = 0.6686\n",
      "Epoch 146, loss = 0.7924, val.loss = 1.0003, val.acc = 0.6694\n",
      "Epoch 147, loss = 0.7911, val.loss = 1.0000, val.acc = 0.6690\n",
      "Epoch 148, loss = 0.7898, val.loss = 0.9997, val.acc = 0.6696\n",
      "Epoch 149, loss = 0.7885, val.loss = 0.9994, val.acc = 0.6698\n",
      "Rep: 1, te.acc = 0.6485\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6485]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 100\n",
    "vis = visdom.Visdom(port=8097, env='ae_2l_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd034ed54560f0698c2946b7ca675e493afbd7ee3c0ecf162ae3deac3cf4477b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
