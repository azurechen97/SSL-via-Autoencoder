{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T22:59:00.864106Z",
     "start_time": "2022-02-24T22:59:00.845101Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "datadirs = ''\n",
    "sys.path.insert(1, datadirs)\n",
    "savepath = datadirs+'save/'\n",
    "datapath = datadirs+'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T22:59:02.566136Z",
     "start_time": "2022-02-24T22:59:01.090158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T22:59:02.678161Z",
     "start_time": "2022-02-24T22:59:02.567136Z"
    }
   },
   "outputs": [],
   "source": [
    "import visdom\n",
    "# python -m visdom.server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T22:59:02.694165Z",
     "start_time": "2022-02-24T22:59:02.679163Z"
    }
   },
   "outputs": [],
   "source": [
    "from pars import PARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T22:59:03.490349Z",
     "start_time": "2022-02-24T22:59:02.696165Z"
    }
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import *\n",
    "from setup_net import *\n",
    "from loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture: CONV6\n",
      "nonlinear: hardtanh\n",
      "batch_size: 500\n",
      "headsize: 64\n",
      "dataset: Cifar100\n",
      "loss: SimCLR\n",
      "OPT: Adam\n",
      "LR: 0.0005\n",
      "epochs: 100\n",
      "clf_dataset: Cifar10\n",
      "clf_loss: CE\n",
      "clf_opt: Adam\n",
      "clf_lr: 5e-05\n",
      "clf_epochs: 100\n",
      "repeat: 1\n",
      "device: cuda:0\n",
      "datapath: data/\n",
      "savepath: save/\n",
      "loadnet: True\n",
      "loadclf: True\n",
      "lam: 1\n",
      "clfnonlinear: None\n",
      "headnonlinear: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pars = PARS(device, datapath, savepath)\n",
    "pars.architecture = 'CONV6'\n",
    "pars.LR = 5e-4\n",
    "pars.clf_lr = 5e-5\n",
    "pars.epochs = 100\n",
    "pars.clf_epochs = 100\n",
    "pars.nonlinear = 'hardtanh'\n",
    "pars.repeat = 1\n",
    "pars.loadnet = True\n",
    "pars.loadclf = True\n",
    "print(pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_1_CLF_Cifar10_Adam_LR_5e-05_Epochs_100\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=8192, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(8, 32, 32))\n",
      "    (deconv): ConvTranspose2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 0.6565, time: 23.6734\n",
      "reconstruction loss = 0.0644, similarity loss: 0.5922\n",
      "Epoch 1, loss = 0.5520, time: 16.7908\n",
      "reconstruction loss = 0.0447, similarity loss: 0.5073\n",
      "Epoch 2, loss = 0.6107, time: 16.9299\n",
      "reconstruction loss = 0.0478, similarity loss: 0.5629\n",
      "Epoch 3, loss = 0.6538, time: 16.7180\n",
      "reconstruction loss = 0.0683, similarity loss: 0.5855\n",
      "Epoch 4, loss = 0.7372, time: 17.2876\n",
      "reconstruction loss = 0.0441, similarity loss: 0.6931\n",
      "Epoch 5, loss = 0.6453, time: 17.3197\n",
      "reconstruction loss = 0.0405, similarity loss: 0.6048\n",
      "Epoch 6, loss = 0.7481, time: 17.3032\n",
      "reconstruction loss = 0.0410, similarity loss: 0.7071\n",
      "Epoch 7, loss = 0.6278, time: 17.2375\n",
      "reconstruction loss = 0.0464, similarity loss: 0.5813\n",
      "Epoch 8, loss = 0.5910, time: 17.2436\n",
      "reconstruction loss = 0.0453, similarity loss: 0.5458\n",
      "Epoch 9, loss = 0.7441, time: 17.2785\n",
      "reconstruction loss = 0.0495, similarity loss: 0.6946\n",
      "Epoch 10, loss = 0.5162, time: 17.3168\n",
      "reconstruction loss = 0.0419, similarity loss: 0.4743\n",
      "Epoch 11, loss = 0.4389, time: 17.2990\n",
      "reconstruction loss = 0.0412, similarity loss: 0.3977\n",
      "Epoch 12, loss = 0.4476, time: 17.1728\n",
      "reconstruction loss = 0.0414, similarity loss: 0.4062\n",
      "Epoch 13, loss = 0.4458, time: 16.9896\n",
      "reconstruction loss = 0.0399, similarity loss: 0.4059\n",
      "Epoch 14, loss = 0.4121, time: 17.3462\n",
      "reconstruction loss = 0.0406, similarity loss: 0.3716\n",
      "Epoch 15, loss = 0.4210, time: 17.1915\n",
      "reconstruction loss = 0.0447, similarity loss: 0.3763\n",
      "Epoch 16, loss = 0.3488, time: 17.0311\n",
      "reconstruction loss = 0.0344, similarity loss: 0.3144\n",
      "Epoch 17, loss = 0.3484, time: 17.2061\n",
      "reconstruction loss = 0.0381, similarity loss: 0.3103\n",
      "Epoch 18, loss = 0.3633, time: 18.0392\n",
      "reconstruction loss = 0.0389, similarity loss: 0.3245\n",
      "Epoch 19, loss = 0.3599, time: 17.8556\n",
      "reconstruction loss = 0.0362, similarity loss: 0.3237\n",
      "Epoch 20, loss = 0.3337, time: 18.1668\n",
      "reconstruction loss = 0.0402, similarity loss: 0.2935\n",
      "Epoch 21, loss = 0.3044, time: 16.9861\n",
      "reconstruction loss = 0.0355, similarity loss: 0.2689\n",
      "Epoch 22, loss = 0.3306, time: 17.7148\n",
      "reconstruction loss = 0.0374, similarity loss: 0.2932\n",
      "Epoch 23, loss = 0.3149, time: 16.9924\n",
      "reconstruction loss = 0.0360, similarity loss: 0.2789\n",
      "Epoch 24, loss = 0.3372, time: 18.0075\n",
      "reconstruction loss = 0.0394, similarity loss: 0.2978\n",
      "Epoch 25, loss = 0.3365, time: 17.2895\n",
      "reconstruction loss = 0.0427, similarity loss: 0.2938\n",
      "Epoch 26, loss = 0.3083, time: 17.9593\n",
      "reconstruction loss = 0.0318, similarity loss: 0.2765\n",
      "Epoch 27, loss = 0.3465, time: 17.3281\n",
      "reconstruction loss = 0.0373, similarity loss: 0.3091\n",
      "Epoch 28, loss = 0.2786, time: 16.6975\n",
      "reconstruction loss = 0.0392, similarity loss: 0.2394\n",
      "Epoch 29, loss = 0.2841, time: 16.9101\n",
      "reconstruction loss = 0.0322, similarity loss: 0.2518\n",
      "Epoch 30, loss = 0.2886, time: 16.7250\n",
      "reconstruction loss = 0.0314, similarity loss: 0.2571\n",
      "Epoch 31, loss = 0.2999, time: 16.8664\n",
      "reconstruction loss = 0.0421, similarity loss: 0.2578\n",
      "Epoch 32, loss = 0.3125, time: 16.8088\n",
      "reconstruction loss = 0.0323, similarity loss: 0.2802\n",
      "Epoch 33, loss = 0.3399, time: 16.6168\n",
      "reconstruction loss = 0.0332, similarity loss: 0.3066\n",
      "Epoch 34, loss = 0.2635, time: 16.8544\n",
      "reconstruction loss = 0.0294, similarity loss: 0.2342\n",
      "Epoch 35, loss = 0.2763, time: 16.8432\n",
      "reconstruction loss = 0.0363, similarity loss: 0.2401\n",
      "Epoch 36, loss = 0.2988, time: 16.6976\n",
      "reconstruction loss = 0.0375, similarity loss: 0.2613\n",
      "Epoch 37, loss = 0.2858, time: 16.7574\n",
      "reconstruction loss = 0.0344, similarity loss: 0.2514\n",
      "Epoch 38, loss = 0.3033, time: 16.8654\n",
      "reconstruction loss = 0.0306, similarity loss: 0.2727\n",
      "Epoch 39, loss = 0.2457, time: 16.7876\n",
      "reconstruction loss = 0.0344, similarity loss: 0.2113\n",
      "Epoch 40, loss = 0.2973, time: 16.7508\n",
      "reconstruction loss = 0.0303, similarity loss: 0.2671\n",
      "Epoch 41, loss = 0.2840, time: 17.1190\n",
      "reconstruction loss = 0.0314, similarity loss: 0.2526\n",
      "Epoch 42, loss = 0.3174, time: 16.7421\n",
      "reconstruction loss = 0.0355, similarity loss: 0.2819\n",
      "Epoch 43, loss = 0.2460, time: 16.8088\n",
      "reconstruction loss = 0.0336, similarity loss: 0.2123\n",
      "Epoch 44, loss = 0.2735, time: 16.8322\n",
      "reconstruction loss = 0.0318, similarity loss: 0.2416\n",
      "Epoch 45, loss = 0.2713, time: 16.9269\n",
      "reconstruction loss = 0.0291, similarity loss: 0.2423\n",
      "Epoch 46, loss = 0.2866, time: 16.7026\n",
      "reconstruction loss = 0.0319, similarity loss: 0.2547\n",
      "Epoch 47, loss = 0.2703, time: 16.7241\n",
      "reconstruction loss = 0.0295, similarity loss: 0.2408\n",
      "Epoch 48, loss = 0.2931, time: 16.6908\n",
      "reconstruction loss = 0.0347, similarity loss: 0.2583\n",
      "Epoch 49, loss = 0.2862, time: 16.6703\n",
      "reconstruction loss = 0.0313, similarity loss: 0.2549\n",
      "Epoch 50, loss = 0.2956, time: 16.9959\n",
      "reconstruction loss = 0.0266, similarity loss: 0.2691\n",
      "Epoch 51, loss = 0.2920, time: 17.6231\n",
      "reconstruction loss = 0.0272, similarity loss: 0.2648\n",
      "Epoch 52, loss = 0.3027, time: 17.5090\n",
      "reconstruction loss = 0.0304, similarity loss: 0.2723\n",
      "Epoch 53, loss = 0.3193, time: 17.5299\n",
      "reconstruction loss = 0.0283, similarity loss: 0.2909\n",
      "Epoch 54, loss = 0.2703, time: 17.5330\n",
      "reconstruction loss = 0.0298, similarity loss: 0.2406\n",
      "Epoch 55, loss = 0.3142, time: 17.5027\n",
      "reconstruction loss = 0.0272, similarity loss: 0.2871\n",
      "Epoch 56, loss = 0.2679, time: 17.4391\n",
      "reconstruction loss = 0.0367, similarity loss: 0.2312\n",
      "Epoch 57, loss = 0.2702, time: 17.4453\n",
      "reconstruction loss = 0.0294, similarity loss: 0.2408\n",
      "Epoch 58, loss = 0.2614, time: 17.4965\n",
      "reconstruction loss = 0.0297, similarity loss: 0.2316\n",
      "Epoch 59, loss = 0.2862, time: 17.4210\n",
      "reconstruction loss = 0.0280, similarity loss: 0.2582\n",
      "Epoch 60, loss = 0.2713, time: 17.1629\n",
      "reconstruction loss = 0.0310, similarity loss: 0.2403\n",
      "Epoch 61, loss = 0.2716, time: 19.1970\n",
      "reconstruction loss = 0.0308, similarity loss: 0.2407\n",
      "Epoch 62, loss = 0.2781, time: 17.6530\n",
      "reconstruction loss = 0.0271, similarity loss: 0.2510\n",
      "Epoch 63, loss = 0.2832, time: 17.5015\n",
      "reconstruction loss = 0.0296, similarity loss: 0.2537\n",
      "Epoch 64, loss = 0.2985, time: 17.1861\n",
      "reconstruction loss = 0.0257, similarity loss: 0.2728\n",
      "Epoch 65, loss = 0.2449, time: 17.3524\n",
      "reconstruction loss = 0.0284, similarity loss: 0.2165\n",
      "Epoch 66, loss = 0.3011, time: 17.4563\n",
      "reconstruction loss = 0.0267, similarity loss: 0.2745\n",
      "Epoch 67, loss = 0.2688, time: 17.3626\n",
      "reconstruction loss = 0.0304, similarity loss: 0.2385\n",
      "Epoch 68, loss = 0.2784, time: 17.1111\n",
      "reconstruction loss = 0.0273, similarity loss: 0.2511\n",
      "Epoch 69, loss = 0.2506, time: 17.2671\n",
      "reconstruction loss = 0.0275, similarity loss: 0.2231\n",
      "Epoch 70, loss = 0.2514, time: 17.4045\n",
      "reconstruction loss = 0.0236, similarity loss: 0.2278\n",
      "Epoch 71, loss = 0.2746, time: 18.5688\n",
      "reconstruction loss = 0.0248, similarity loss: 0.2497\n",
      "Epoch 72, loss = 0.2393, time: 25.4392\n",
      "reconstruction loss = 0.0265, similarity loss: 0.2128\n",
      "Epoch 73, loss = 0.2860, time: 26.2085\n",
      "reconstruction loss = 0.0280, similarity loss: 0.2581\n",
      "Epoch 74, loss = 0.2815, time: 24.8889\n",
      "reconstruction loss = 0.0243, similarity loss: 0.2572\n",
      "Epoch 75, loss = 0.2513, time: 23.5388\n",
      "reconstruction loss = 0.0243, similarity loss: 0.2269\n",
      "Epoch 76, loss = 0.2654, time: 24.5616\n",
      "reconstruction loss = 0.0251, similarity loss: 0.2402\n",
      "Epoch 77, loss = 0.2702, time: 25.3023\n",
      "reconstruction loss = 0.0276, similarity loss: 0.2426\n",
      "Epoch 78, loss = 0.2540, time: 25.0381\n",
      "reconstruction loss = 0.0284, similarity loss: 0.2256\n",
      "Epoch 79, loss = 0.2583, time: 24.7414\n",
      "reconstruction loss = 0.0298, similarity loss: 0.2285\n",
      "Epoch 80, loss = 0.2527, time: 25.2596\n",
      "reconstruction loss = 0.0264, similarity loss: 0.2263\n",
      "Epoch 81, loss = 0.2680, time: 27.4214\n",
      "reconstruction loss = 0.0243, similarity loss: 0.2437\n",
      "Epoch 82, loss = 0.2619, time: 25.8264\n",
      "reconstruction loss = 0.0247, similarity loss: 0.2371\n",
      "Epoch 83, loss = 0.2730, time: 26.2037\n",
      "reconstruction loss = 0.0260, similarity loss: 0.2471\n",
      "Epoch 84, loss = 0.2893, time: 25.7439\n",
      "reconstruction loss = 0.0306, similarity loss: 0.2586\n",
      "Epoch 85, loss = 0.2444, time: 26.6456\n",
      "reconstruction loss = 0.0262, similarity loss: 0.2182\n",
      "Epoch 86, loss = 0.2423, time: 26.6478\n",
      "reconstruction loss = 0.0236, similarity loss: 0.2187\n",
      "Epoch 87, loss = 0.2586, time: 25.0184\n",
      "reconstruction loss = 0.0273, similarity loss: 0.2313\n",
      "Epoch 88, loss = 0.2592, time: 26.3464\n",
      "reconstruction loss = 0.0290, similarity loss: 0.2302\n",
      "Epoch 89, loss = 0.2543, time: 25.2722\n",
      "reconstruction loss = 0.0226, similarity loss: 0.2317\n",
      "Epoch 90, loss = 0.2595, time: 24.3867\n",
      "reconstruction loss = 0.0239, similarity loss: 0.2357\n",
      "Epoch 91, loss = 0.2600, time: 23.8083\n",
      "reconstruction loss = 0.0250, similarity loss: 0.2350\n",
      "Epoch 92, loss = 0.2539, time: 25.0567\n",
      "reconstruction loss = 0.0240, similarity loss: 0.2299\n",
      "Epoch 93, loss = 0.2408, time: 24.6284\n",
      "reconstruction loss = 0.0239, similarity loss: 0.2169\n",
      "Epoch 94, loss = 0.2378, time: 24.7376\n",
      "reconstruction loss = 0.0254, similarity loss: 0.2124\n",
      "Epoch 95, loss = 0.2516, time: 25.9278\n",
      "reconstruction loss = 0.0259, similarity loss: 0.2257\n",
      "Epoch 96, loss = 0.2370, time: 24.1818\n",
      "reconstruction loss = 0.0215, similarity loss: 0.2156\n",
      "Epoch 97, loss = 0.2498, time: 23.4076\n",
      "reconstruction loss = 0.0236, similarity loss: 0.2262\n",
      "Epoch 98, loss = 0.2620, time: 24.2247\n",
      "reconstruction loss = 0.0266, similarity loss: 0.2354\n",
      "Epoch 99, loss = 0.2575, time: 25.5204\n",
      "reconstruction loss = 0.0244, similarity loss: 0.2331\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 5e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 2.0240, val.loss = 1.7680, val.acc = 0.4348\n",
      "Epoch 1, loss = 1.6726, val.loss = 1.5798, val.acc = 0.4930\n",
      "Epoch 2, loss = 1.5312, val.loss = 1.4811, val.acc = 0.5158\n",
      "Epoch 3, loss = 1.4466, val.loss = 1.4182, val.acc = 0.5346\n",
      "Epoch 4, loss = 1.3879, val.loss = 1.3735, val.acc = 0.5476\n",
      "Epoch 5, loss = 1.3437, val.loss = 1.3395, val.acc = 0.5558\n",
      "Epoch 6, loss = 1.3083, val.loss = 1.3124, val.acc = 0.5668\n",
      "Epoch 7, loss = 1.2789, val.loss = 1.2900, val.acc = 0.5744\n",
      "Epoch 8, loss = 1.2538, val.loss = 1.2711, val.acc = 0.5808\n",
      "Epoch 9, loss = 1.2319, val.loss = 1.2548, val.acc = 0.5852\n",
      "Epoch 10, loss = 1.2125, val.loss = 1.2406, val.acc = 0.5912\n",
      "Epoch 11, loss = 1.1949, val.loss = 1.2280, val.acc = 0.5954\n",
      "Epoch 12, loss = 1.1789, val.loss = 1.2167, val.acc = 0.5976\n",
      "Epoch 13, loss = 1.1643, val.loss = 1.2065, val.acc = 0.6008\n",
      "Epoch 14, loss = 1.1507, val.loss = 1.1972, val.acc = 0.6038\n",
      "Epoch 15, loss = 1.1380, val.loss = 1.1887, val.acc = 0.6064\n",
      "Epoch 16, loss = 1.1262, val.loss = 1.1809, val.acc = 0.6090\n",
      "Epoch 17, loss = 1.1151, val.loss = 1.1737, val.acc = 0.6108\n",
      "Epoch 18, loss = 1.1046, val.loss = 1.1671, val.acc = 0.6128\n",
      "Epoch 19, loss = 1.0946, val.loss = 1.1608, val.acc = 0.6136\n",
      "Epoch 20, loss = 1.0851, val.loss = 1.1551, val.acc = 0.6164\n",
      "Epoch 21, loss = 1.0761, val.loss = 1.1496, val.acc = 0.6180\n",
      "Epoch 22, loss = 1.0675, val.loss = 1.1445, val.acc = 0.6202\n",
      "Epoch 23, loss = 1.0592, val.loss = 1.1398, val.acc = 0.6226\n",
      "Epoch 24, loss = 1.0513, val.loss = 1.1353, val.acc = 0.6242\n",
      "Epoch 25, loss = 1.0437, val.loss = 1.1310, val.acc = 0.6258\n",
      "Epoch 26, loss = 1.0363, val.loss = 1.1270, val.acc = 0.6288\n",
      "Epoch 27, loss = 1.0292, val.loss = 1.1232, val.acc = 0.6304\n",
      "Epoch 28, loss = 1.0224, val.loss = 1.1196, val.acc = 0.6314\n",
      "Epoch 29, loss = 1.0158, val.loss = 1.1162, val.acc = 0.6332\n",
      "Epoch 30, loss = 1.0094, val.loss = 1.1129, val.acc = 0.6342\n",
      "Epoch 31, loss = 1.0031, val.loss = 1.1098, val.acc = 0.6350\n",
      "Epoch 32, loss = 0.9971, val.loss = 1.1069, val.acc = 0.6360\n",
      "Epoch 33, loss = 0.9912, val.loss = 1.1040, val.acc = 0.6372\n",
      "Epoch 34, loss = 0.9855, val.loss = 1.1014, val.acc = 0.6400\n",
      "Epoch 35, loss = 0.9800, val.loss = 1.0988, val.acc = 0.6412\n",
      "Epoch 36, loss = 0.9746, val.loss = 1.0963, val.acc = 0.6424\n",
      "Epoch 37, loss = 0.9693, val.loss = 1.0940, val.acc = 0.6428\n",
      "Epoch 38, loss = 0.9641, val.loss = 1.0917, val.acc = 0.6424\n",
      "Epoch 39, loss = 0.9591, val.loss = 1.0895, val.acc = 0.6434\n",
      "Epoch 40, loss = 0.9542, val.loss = 1.0875, val.acc = 0.6434\n",
      "Epoch 41, loss = 0.9494, val.loss = 1.0855, val.acc = 0.6432\n",
      "Epoch 42, loss = 0.9447, val.loss = 1.0836, val.acc = 0.6436\n",
      "Epoch 43, loss = 0.9401, val.loss = 1.0817, val.acc = 0.6442\n",
      "Epoch 44, loss = 0.9356, val.loss = 1.0800, val.acc = 0.6450\n",
      "Epoch 45, loss = 0.9312, val.loss = 1.0783, val.acc = 0.6456\n",
      "Epoch 46, loss = 0.9268, val.loss = 1.0766, val.acc = 0.6456\n",
      "Epoch 47, loss = 0.9226, val.loss = 1.0751, val.acc = 0.6458\n",
      "Epoch 48, loss = 0.9184, val.loss = 1.0736, val.acc = 0.6458\n",
      "Epoch 49, loss = 0.9143, val.loss = 1.0721, val.acc = 0.6470\n",
      "Epoch 50, loss = 0.9103, val.loss = 1.0707, val.acc = 0.6470\n",
      "Epoch 51, loss = 0.9064, val.loss = 1.0693, val.acc = 0.6468\n",
      "Epoch 52, loss = 0.9025, val.loss = 1.0680, val.acc = 0.6476\n",
      "Epoch 53, loss = 0.8987, val.loss = 1.0668, val.acc = 0.6476\n",
      "Epoch 54, loss = 0.8950, val.loss = 1.0656, val.acc = 0.6490\n",
      "Epoch 55, loss = 0.8913, val.loss = 1.0644, val.acc = 0.6496\n",
      "Epoch 56, loss = 0.8876, val.loss = 1.0633, val.acc = 0.6498\n",
      "Epoch 57, loss = 0.8841, val.loss = 1.0622, val.acc = 0.6498\n",
      "Epoch 58, loss = 0.8806, val.loss = 1.0612, val.acc = 0.6498\n",
      "Epoch 59, loss = 0.8771, val.loss = 1.0602, val.acc = 0.6510\n",
      "Epoch 60, loss = 0.8737, val.loss = 1.0592, val.acc = 0.6518\n",
      "Epoch 61, loss = 0.8703, val.loss = 1.0582, val.acc = 0.6522\n",
      "Epoch 62, loss = 0.8670, val.loss = 1.0573, val.acc = 0.6524\n",
      "Epoch 63, loss = 0.8638, val.loss = 1.0565, val.acc = 0.6524\n",
      "Epoch 64, loss = 0.8606, val.loss = 1.0556, val.acc = 0.6512\n",
      "Epoch 65, loss = 0.8574, val.loss = 1.0548, val.acc = 0.6510\n",
      "Epoch 66, loss = 0.8543, val.loss = 1.0540, val.acc = 0.6514\n",
      "Epoch 67, loss = 0.8512, val.loss = 1.0533, val.acc = 0.6522\n",
      "Epoch 68, loss = 0.8481, val.loss = 1.0525, val.acc = 0.6520\n",
      "Epoch 69, loss = 0.8451, val.loss = 1.0518, val.acc = 0.6518\n",
      "Epoch 70, loss = 0.8422, val.loss = 1.0511, val.acc = 0.6522\n",
      "Epoch 71, loss = 0.8392, val.loss = 1.0505, val.acc = 0.6528\n",
      "Epoch 72, loss = 0.8363, val.loss = 1.0499, val.acc = 0.6524\n",
      "Epoch 73, loss = 0.8335, val.loss = 1.0493, val.acc = 0.6536\n",
      "Epoch 74, loss = 0.8307, val.loss = 1.0486, val.acc = 0.6536\n",
      "Epoch 75, loss = 0.8279, val.loss = 1.0481, val.acc = 0.6542\n",
      "Epoch 76, loss = 0.8251, val.loss = 1.0475, val.acc = 0.6548\n",
      "Epoch 77, loss = 0.8224, val.loss = 1.0470, val.acc = 0.6546\n",
      "Epoch 78, loss = 0.8197, val.loss = 1.0465, val.acc = 0.6546\n",
      "Epoch 79, loss = 0.8170, val.loss = 1.0461, val.acc = 0.6556\n",
      "Epoch 80, loss = 0.8144, val.loss = 1.0455, val.acc = 0.6556\n",
      "Epoch 81, loss = 0.8118, val.loss = 1.0451, val.acc = 0.6550\n",
      "Epoch 82, loss = 0.8093, val.loss = 1.0447, val.acc = 0.6566\n",
      "Epoch 83, loss = 0.8067, val.loss = 1.0443, val.acc = 0.6566\n",
      "Epoch 84, loss = 0.8042, val.loss = 1.0439, val.acc = 0.6568\n",
      "Epoch 85, loss = 0.8017, val.loss = 1.0435, val.acc = 0.6574\n",
      "Epoch 86, loss = 0.7993, val.loss = 1.0431, val.acc = 0.6574\n",
      "Epoch 87, loss = 0.7968, val.loss = 1.0428, val.acc = 0.6582\n",
      "Epoch 88, loss = 0.7944, val.loss = 1.0424, val.acc = 0.6586\n",
      "Epoch 89, loss = 0.7920, val.loss = 1.0421, val.acc = 0.6586\n",
      "Epoch 90, loss = 0.7897, val.loss = 1.0418, val.acc = 0.6584\n",
      "Epoch 91, loss = 0.7873, val.loss = 1.0415, val.acc = 0.6582\n",
      "Epoch 92, loss = 0.7850, val.loss = 1.0413, val.acc = 0.6586\n",
      "Epoch 93, loss = 0.7827, val.loss = 1.0410, val.acc = 0.6592\n",
      "Epoch 94, loss = 0.7805, val.loss = 1.0407, val.acc = 0.6590\n",
      "Epoch 95, loss = 0.7782, val.loss = 1.0405, val.acc = 0.6588\n",
      "Epoch 96, loss = 0.7760, val.loss = 1.0403, val.acc = 0.6588\n",
      "Epoch 97, loss = 0.7738, val.loss = 1.0400, val.acc = 0.6584\n",
      "Epoch 98, loss = 0.7716, val.loss = 1.0398, val.acc = 0.6592\n",
      "Epoch 99, loss = 0.7695, val.loss = 1.0397, val.acc = 0.6594\n",
      "Rep: 1, te.acc = 0.6365\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6365]\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 1\n",
    "vis = visdom.Visdom(port=8097,env='ae_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_1_CLF_Cifar10_Adam_LR_5e-05_Epochs_100\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=8192, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(8, 32, 32))\n",
      "    (deconv): ConvTranspose2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 0.6740, time: 23.6059\n",
      "reconstruction loss = 0.0707, similarity loss: 0.6033\n",
      "Epoch 1, loss = 0.7071, time: 23.3329\n",
      "reconstruction loss = 0.0875, similarity loss: 0.6197\n",
      "Epoch 2, loss = 0.7649, time: 23.3030\n",
      "reconstruction loss = 0.0677, similarity loss: 0.6972\n",
      "Epoch 3, loss = 0.6157, time: 24.6706\n",
      "reconstruction loss = 0.0682, similarity loss: 0.5474\n",
      "Epoch 4, loss = 0.6336, time: 23.9365\n",
      "reconstruction loss = 0.0667, similarity loss: 0.5670\n",
      "Epoch 5, loss = 0.6252, time: 25.1724\n",
      "reconstruction loss = 0.0676, similarity loss: 0.5575\n",
      "Epoch 6, loss = 0.5987, time: 24.5817\n",
      "reconstruction loss = 0.0684, similarity loss: 0.5303\n",
      "Epoch 7, loss = 0.6189, time: 25.4218\n",
      "reconstruction loss = 0.0665, similarity loss: 0.5524\n",
      "Epoch 8, loss = 0.6562, time: 25.2162\n",
      "reconstruction loss = 0.0655, similarity loss: 0.5907\n",
      "Epoch 9, loss = 0.5633, time: 25.4756\n",
      "reconstruction loss = 0.0666, similarity loss: 0.4967\n",
      "Epoch 10, loss = 0.5200, time: 25.4898\n",
      "reconstruction loss = 0.0656, similarity loss: 0.4544\n",
      "Epoch 11, loss = 0.6479, time: 24.0938\n",
      "reconstruction loss = 0.0642, similarity loss: 0.5838\n",
      "Epoch 12, loss = 0.6643, time: 25.4681\n",
      "reconstruction loss = 0.0675, similarity loss: 0.5968\n",
      "Epoch 13, loss = 0.6195, time: 25.4455\n",
      "reconstruction loss = 0.0664, similarity loss: 0.5531\n",
      "Epoch 14, loss = 0.5369, time: 25.4366\n",
      "reconstruction loss = 0.0642, similarity loss: 0.4727\n",
      "Epoch 15, loss = 0.4872, time: 25.5735\n",
      "reconstruction loss = 0.0655, similarity loss: 0.4218\n",
      "Epoch 16, loss = 0.4715, time: 25.3224\n",
      "reconstruction loss = 0.0619, similarity loss: 0.4096\n",
      "Epoch 17, loss = 0.3911, time: 25.3575\n",
      "reconstruction loss = 0.0678, similarity loss: 0.3232\n",
      "Epoch 18, loss = 0.4110, time: 25.5973\n",
      "reconstruction loss = 0.0660, similarity loss: 0.3449\n",
      "Epoch 19, loss = 0.3824, time: 25.3189\n",
      "reconstruction loss = 0.0635, similarity loss: 0.3190\n",
      "Epoch 20, loss = 0.3999, time: 25.4343\n",
      "reconstruction loss = 0.0642, similarity loss: 0.3357\n",
      "Epoch 21, loss = 0.4068, time: 25.6000\n",
      "reconstruction loss = 0.0641, similarity loss: 0.3427\n",
      "Epoch 22, loss = 0.3844, time: 25.8991\n",
      "reconstruction loss = 0.0647, similarity loss: 0.3196\n",
      "Epoch 23, loss = 0.3995, time: 25.6157\n",
      "reconstruction loss = 0.0660, similarity loss: 0.3335\n",
      "Epoch 24, loss = 0.3669, time: 25.3970\n",
      "reconstruction loss = 0.0640, similarity loss: 0.3029\n",
      "Epoch 25, loss = 0.3846, time: 25.3606\n",
      "reconstruction loss = 0.0659, similarity loss: 0.3187\n",
      "Epoch 26, loss = 0.3819, time: 25.2582\n",
      "reconstruction loss = 0.0625, similarity loss: 0.3194\n",
      "Epoch 27, loss = 0.3806, time: 25.3448\n",
      "reconstruction loss = 0.0634, similarity loss: 0.3171\n",
      "Epoch 28, loss = 0.3969, time: 25.4332\n",
      "reconstruction loss = 0.0654, similarity loss: 0.3315\n",
      "Epoch 29, loss = 0.3754, time: 24.5314\n",
      "reconstruction loss = 0.0654, similarity loss: 0.3100\n",
      "Epoch 30, loss = 0.3741, time: 23.3481\n",
      "reconstruction loss = 0.0633, similarity loss: 0.3108\n",
      "Epoch 31, loss = 0.3670, time: 23.4344\n",
      "reconstruction loss = 0.0636, similarity loss: 0.3034\n",
      "Epoch 32, loss = 0.3708, time: 23.4015\n",
      "reconstruction loss = 0.0699, similarity loss: 0.3009\n",
      "Epoch 33, loss = 0.3547, time: 23.2968\n",
      "reconstruction loss = 0.0652, similarity loss: 0.2895\n",
      "Epoch 34, loss = 0.3635, time: 23.4809\n",
      "reconstruction loss = 0.0654, similarity loss: 0.2981\n",
      "Epoch 35, loss = 0.3874, time: 23.4881\n",
      "reconstruction loss = 0.0663, similarity loss: 0.3211\n",
      "Epoch 36, loss = 0.3532, time: 23.3252\n",
      "reconstruction loss = 0.0621, similarity loss: 0.2911\n",
      "Epoch 37, loss = 0.3822, time: 23.5139\n",
      "reconstruction loss = 0.0666, similarity loss: 0.3156\n",
      "Epoch 38, loss = 0.3373, time: 23.2791\n",
      "reconstruction loss = 0.0659, similarity loss: 0.2714\n",
      "Epoch 39, loss = 0.3621, time: 23.2997\n",
      "reconstruction loss = 0.0620, similarity loss: 0.3001\n",
      "Epoch 40, loss = 0.3596, time: 23.4941\n",
      "reconstruction loss = 0.0659, similarity loss: 0.2937\n",
      "Epoch 41, loss = 0.3968, time: 23.4054\n",
      "reconstruction loss = 0.0674, similarity loss: 0.3294\n",
      "Epoch 42, loss = 0.3062, time: 23.3869\n",
      "reconstruction loss = 0.0652, similarity loss: 0.2410\n",
      "Epoch 43, loss = 0.3314, time: 23.5666\n",
      "reconstruction loss = 0.0633, similarity loss: 0.2681\n",
      "Epoch 44, loss = 0.3024, time: 23.4216\n",
      "reconstruction loss = 0.0652, similarity loss: 0.2372\n",
      "Epoch 45, loss = 0.3719, time: 23.6204\n",
      "reconstruction loss = 0.0662, similarity loss: 0.3057\n",
      "Epoch 46, loss = 0.3256, time: 23.4720\n",
      "reconstruction loss = 0.0633, similarity loss: 0.2623\n",
      "Epoch 47, loss = 0.3432, time: 23.4794\n",
      "reconstruction loss = 0.0668, similarity loss: 0.2763\n",
      "Epoch 48, loss = 0.3032, time: 23.3172\n",
      "reconstruction loss = 0.0643, similarity loss: 0.2389\n",
      "Epoch 49, loss = 0.3154, time: 23.4173\n",
      "reconstruction loss = 0.0656, similarity loss: 0.2498\n",
      "Epoch 50, loss = 0.3478, time: 23.4586\n",
      "reconstruction loss = 0.0650, similarity loss: 0.2827\n",
      "Epoch 51, loss = 0.3091, time: 23.3420\n",
      "reconstruction loss = 0.0649, similarity loss: 0.2443\n",
      "Epoch 52, loss = 0.3120, time: 23.3778\n",
      "reconstruction loss = 0.0660, similarity loss: 0.2461\n",
      "Epoch 53, loss = 0.3488, time: 23.3981\n",
      "reconstruction loss = 0.0657, similarity loss: 0.2832\n",
      "Epoch 54, loss = 0.3550, time: 23.3435\n",
      "reconstruction loss = 0.0627, similarity loss: 0.2923\n",
      "Epoch 55, loss = 0.3090, time: 23.5739\n",
      "reconstruction loss = 0.0676, similarity loss: 0.2414\n",
      "Epoch 56, loss = 0.3340, time: 23.5834\n",
      "reconstruction loss = 0.0643, similarity loss: 0.2697\n",
      "Epoch 57, loss = 0.3235, time: 23.4021\n",
      "reconstruction loss = 0.0634, similarity loss: 0.2601\n",
      "Epoch 58, loss = 0.2943, time: 23.9950\n",
      "reconstruction loss = 0.0639, similarity loss: 0.2304\n",
      "Epoch 59, loss = 0.3285, time: 25.2619\n",
      "reconstruction loss = 0.0661, similarity loss: 0.2624\n",
      "Epoch 60, loss = 0.3004, time: 25.4725\n",
      "reconstruction loss = 0.0623, similarity loss: 0.2381\n",
      "Epoch 61, loss = 0.3065, time: 25.3065\n",
      "reconstruction loss = 0.0667, similarity loss: 0.2397\n",
      "Epoch 62, loss = 0.2983, time: 25.5095\n",
      "reconstruction loss = 0.0659, similarity loss: 0.2324\n",
      "Epoch 63, loss = 0.3360, time: 25.3157\n",
      "reconstruction loss = 0.0662, similarity loss: 0.2699\n",
      "Epoch 64, loss = 0.3318, time: 25.2384\n",
      "reconstruction loss = 0.0670, similarity loss: 0.2648\n",
      "Epoch 65, loss = 0.3117, time: 25.3308\n",
      "reconstruction loss = 0.0636, similarity loss: 0.2481\n",
      "Epoch 66, loss = 0.2992, time: 25.4143\n",
      "reconstruction loss = 0.0639, similarity loss: 0.2353\n",
      "Epoch 67, loss = 0.3310, time: 25.2667\n",
      "reconstruction loss = 0.0640, similarity loss: 0.2670\n",
      "Epoch 68, loss = 0.3748, time: 25.1240\n",
      "reconstruction loss = 0.0645, similarity loss: 0.3102\n",
      "Epoch 69, loss = 0.3177, time: 25.1864\n",
      "reconstruction loss = 0.0629, similarity loss: 0.2548\n",
      "Epoch 70, loss = 0.3340, time: 25.3012\n",
      "reconstruction loss = 0.0616, similarity loss: 0.2724\n",
      "Epoch 71, loss = 0.3316, time: 26.3478\n",
      "reconstruction loss = 0.0647, similarity loss: 0.2669\n",
      "Epoch 72, loss = 0.3538, time: 25.4079\n",
      "reconstruction loss = 0.0675, similarity loss: 0.2863\n",
      "Epoch 73, loss = 0.3052, time: 25.3631\n",
      "reconstruction loss = 0.0642, similarity loss: 0.2410\n",
      "Epoch 74, loss = 0.3242, time: 25.3465\n",
      "reconstruction loss = 0.0630, similarity loss: 0.2611\n",
      "Epoch 75, loss = 0.3143, time: 25.6115\n",
      "reconstruction loss = 0.0634, similarity loss: 0.2509\n",
      "Epoch 76, loss = 0.3315, time: 25.1128\n",
      "reconstruction loss = 0.0633, similarity loss: 0.2682\n",
      "Epoch 77, loss = 0.3431, time: 26.4788\n",
      "reconstruction loss = 0.0677, similarity loss: 0.2753\n",
      "Epoch 78, loss = 0.3189, time: 25.6890\n",
      "reconstruction loss = 0.0662, similarity loss: 0.2527\n",
      "Epoch 79, loss = 0.3032, time: 25.8900\n",
      "reconstruction loss = 0.0656, similarity loss: 0.2376\n",
      "Epoch 80, loss = 0.3017, time: 25.5279\n",
      "reconstruction loss = 0.0639, similarity loss: 0.2378\n",
      "Epoch 81, loss = 0.3048, time: 23.9261\n",
      "reconstruction loss = 0.0629, similarity loss: 0.2419\n",
      "Epoch 82, loss = 0.3361, time: 25.6860\n",
      "reconstruction loss = 0.0681, similarity loss: 0.2679\n",
      "Epoch 83, loss = 0.2975, time: 25.9064\n",
      "reconstruction loss = 0.0634, similarity loss: 0.2341\n",
      "Epoch 84, loss = 0.3192, time: 26.2238\n",
      "reconstruction loss = 0.0640, similarity loss: 0.2552\n",
      "Epoch 85, loss = 0.2946, time: 25.6384\n",
      "reconstruction loss = 0.0655, similarity loss: 0.2291\n",
      "Epoch 86, loss = 0.3148, time: 25.3950\n",
      "reconstruction loss = 0.0655, similarity loss: 0.2492\n",
      "Epoch 87, loss = 0.2700, time: 25.4226\n",
      "reconstruction loss = 0.0636, similarity loss: 0.2065\n",
      "Epoch 88, loss = 0.2792, time: 25.4105\n",
      "reconstruction loss = 0.0651, similarity loss: 0.2141\n",
      "Epoch 89, loss = 0.3175, time: 26.7600\n",
      "reconstruction loss = 0.0643, similarity loss: 0.2532\n",
      "Epoch 90, loss = 0.2864, time: 25.7283\n",
      "reconstruction loss = 0.0615, similarity loss: 0.2249\n",
      "Epoch 91, loss = 0.3047, time: 25.2847\n",
      "reconstruction loss = 0.0656, similarity loss: 0.2391\n",
      "Epoch 92, loss = 0.3174, time: 25.4808\n",
      "reconstruction loss = 0.0648, similarity loss: 0.2526\n",
      "Epoch 93, loss = 0.3314, time: 25.6731\n",
      "reconstruction loss = 0.0663, similarity loss: 0.2651\n",
      "Epoch 94, loss = 0.3022, time: 25.5686\n",
      "reconstruction loss = 0.0646, similarity loss: 0.2376\n",
      "Epoch 95, loss = 0.2730, time: 25.6940\n",
      "reconstruction loss = 0.0648, similarity loss: 0.2081\n",
      "Epoch 96, loss = 0.2923, time: 25.6642\n",
      "reconstruction loss = 0.0656, similarity loss: 0.2267\n",
      "Epoch 97, loss = 0.3150, time: 25.6273\n",
      "reconstruction loss = 0.0666, similarity loss: 0.2484\n",
      "Epoch 98, loss = 0.3386, time: 25.7274\n",
      "reconstruction loss = 0.0627, similarity loss: 0.2759\n",
      "Epoch 99, loss = 0.3011, time: 25.8302\n",
      "reconstruction loss = 0.0627, similarity loss: 0.2385\n",
      "SGDClassifier(alpha=0.01, n_jobs=-1)\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "SGDClassifier(alpha=0.01, n_jobs=-1)\n",
      "loss = 12.6836, val.acc = 0.4024\n",
      "Rep: 1, te.acc = 0.3969\n",
      "\n",
      "All reps test.acc:\n",
      "[0.3969]\n"
     ]
    }
   ],
   "source": [
    "sklearn_classifier = SGDClassifier(n_jobs=-1, alpha=0.01)\n",
    "train_unsupervised_ae(pars,sklearn_classifier=sklearn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/\n",
      "hardtanh_Cifar100_Adam_LR_0.0005_Epochs_100_lam_5_CLF_Cifar10_Adam_LR_5e-05_Epochs_100\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Train Net\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=8192, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(8, 32, 32))\n",
      "    (deconv): ConvTranspose2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0005\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 0.9391, time: 25.7233\n",
      "reconstruction loss = 0.0523, similarity loss: 0.6776\n",
      "Epoch 1, loss = 0.8247, time: 25.2953\n",
      "reconstruction loss = 0.0416, similarity loss: 0.6167\n",
      "Epoch 2, loss = 0.8151, time: 25.4160\n",
      "reconstruction loss = 0.0445, similarity loss: 0.5924\n",
      "Epoch 3, loss = 0.8164, time: 25.5785\n",
      "reconstruction loss = 0.0432, similarity loss: 0.6002\n",
      "Epoch 4, loss = 0.6401, time: 25.5172\n",
      "reconstruction loss = 0.0359, similarity loss: 0.4604\n",
      "Epoch 5, loss = 0.5309, time: 25.4311\n",
      "reconstruction loss = 0.0345, similarity loss: 0.3584\n",
      "Epoch 6, loss = 0.5075, time: 25.5099\n",
      "reconstruction loss = 0.0328, similarity loss: 0.3436\n",
      "Epoch 7, loss = 0.5298, time: 25.8216\n",
      "reconstruction loss = 0.0325, similarity loss: 0.3675\n",
      "Epoch 8, loss = 0.4628, time: 25.5788\n",
      "reconstruction loss = 0.0309, similarity loss: 0.3081\n",
      "Epoch 9, loss = 0.4578, time: 25.6829\n",
      "reconstruction loss = 0.0287, similarity loss: 0.3145\n",
      "Epoch 10, loss = 0.4473, time: 25.7414\n",
      "reconstruction loss = 0.0276, similarity loss: 0.3092\n",
      "Epoch 11, loss = 0.4576, time: 25.5552\n",
      "reconstruction loss = 0.0305, similarity loss: 0.3053\n",
      "Epoch 12, loss = 0.4534, time: 26.4002\n",
      "reconstruction loss = 0.0270, similarity loss: 0.3183\n",
      "Epoch 13, loss = 0.4391, time: 26.3476\n",
      "reconstruction loss = 0.0252, similarity loss: 0.3132\n",
      "Epoch 14, loss = 0.4297, time: 25.3739\n",
      "reconstruction loss = 0.0263, similarity loss: 0.2981\n",
      "Epoch 15, loss = 0.4360, time: 25.5617\n",
      "reconstruction loss = 0.0266, similarity loss: 0.3031\n",
      "Epoch 16, loss = 0.4782, time: 25.9859\n",
      "reconstruction loss = 0.0302, similarity loss: 0.3271\n",
      "Epoch 17, loss = 0.4303, time: 25.6148\n",
      "reconstruction loss = 0.0236, similarity loss: 0.3125\n",
      "Epoch 18, loss = 0.4292, time: 25.4473\n",
      "reconstruction loss = 0.0267, similarity loss: 0.2955\n",
      "Epoch 19, loss = 0.3999, time: 25.7730\n",
      "reconstruction loss = 0.0249, similarity loss: 0.2753\n",
      "Epoch 20, loss = 0.4047, time: 25.7436\n",
      "reconstruction loss = 0.0265, similarity loss: 0.2725\n",
      "Epoch 21, loss = 0.3878, time: 25.7307\n",
      "reconstruction loss = 0.0232, similarity loss: 0.2716\n",
      "Epoch 22, loss = 0.4031, time: 25.5546\n",
      "reconstruction loss = 0.0254, similarity loss: 0.2763\n",
      "Epoch 23, loss = 0.4005, time: 25.4934\n",
      "reconstruction loss = 0.0227, similarity loss: 0.2870\n",
      "Epoch 24, loss = 0.4269, time: 25.6586\n",
      "reconstruction loss = 0.0236, similarity loss: 0.3090\n",
      "Epoch 25, loss = 0.4192, time: 25.4297\n",
      "reconstruction loss = 0.0261, similarity loss: 0.2886\n",
      "Epoch 26, loss = 0.3726, time: 25.5230\n",
      "reconstruction loss = 0.0244, similarity loss: 0.2505\n",
      "Epoch 27, loss = 0.3664, time: 25.5095\n",
      "reconstruction loss = 0.0246, similarity loss: 0.2435\n",
      "Epoch 28, loss = 0.3787, time: 25.6366\n",
      "reconstruction loss = 0.0207, similarity loss: 0.2750\n",
      "Epoch 29, loss = 0.4021, time: 25.7696\n",
      "reconstruction loss = 0.0208, similarity loss: 0.2982\n",
      "Epoch 30, loss = 0.3941, time: 25.5652\n",
      "reconstruction loss = 0.0240, similarity loss: 0.2741\n",
      "Epoch 31, loss = 0.3710, time: 25.4753\n",
      "reconstruction loss = 0.0215, similarity loss: 0.2633\n",
      "Epoch 32, loss = 0.3749, time: 25.3657\n",
      "reconstruction loss = 0.0217, similarity loss: 0.2661\n",
      "Epoch 33, loss = 0.3702, time: 25.4462\n",
      "reconstruction loss = 0.0224, similarity loss: 0.2582\n",
      "Epoch 34, loss = 0.3619, time: 25.5804\n",
      "reconstruction loss = 0.0201, similarity loss: 0.2613\n",
      "Epoch 35, loss = 0.3866, time: 25.4747\n",
      "reconstruction loss = 0.0234, similarity loss: 0.2698\n",
      "Epoch 36, loss = 0.3886, time: 25.4677\n",
      "reconstruction loss = 0.0200, similarity loss: 0.2885\n",
      "Epoch 37, loss = 0.3807, time: 25.2675\n",
      "reconstruction loss = 0.0183, similarity loss: 0.2893\n",
      "Epoch 38, loss = 0.4016, time: 25.3527\n",
      "reconstruction loss = 0.0203, similarity loss: 0.3003\n",
      "Epoch 39, loss = 0.3342, time: 25.7243\n",
      "reconstruction loss = 0.0191, similarity loss: 0.2388\n",
      "Epoch 40, loss = 0.3941, time: 25.6249\n",
      "reconstruction loss = 0.0209, similarity loss: 0.2897\n",
      "Epoch 41, loss = 0.3906, time: 25.5905\n",
      "reconstruction loss = 0.0221, similarity loss: 0.2800\n",
      "Epoch 42, loss = 0.3380, time: 25.5686\n",
      "reconstruction loss = 0.0196, similarity loss: 0.2401\n",
      "Epoch 43, loss = 0.3535, time: 25.5845\n",
      "reconstruction loss = 0.0207, similarity loss: 0.2498\n",
      "Epoch 44, loss = 0.3791, time: 25.4398\n",
      "reconstruction loss = 0.0212, similarity loss: 0.2733\n",
      "Epoch 45, loss = 0.3932, time: 25.6357\n",
      "reconstruction loss = 0.0186, similarity loss: 0.3001\n",
      "Epoch 46, loss = 0.3409, time: 25.5279\n",
      "reconstruction loss = 0.0180, similarity loss: 0.2508\n",
      "Epoch 47, loss = 0.3656, time: 25.6573\n",
      "reconstruction loss = 0.0197, similarity loss: 0.2671\n",
      "Epoch 48, loss = 0.3934, time: 25.5995\n",
      "reconstruction loss = 0.0219, similarity loss: 0.2841\n",
      "Epoch 49, loss = 0.3107, time: 25.5090\n",
      "reconstruction loss = 0.0179, similarity loss: 0.2214\n",
      "Epoch 50, loss = 0.3970, time: 25.6539\n",
      "reconstruction loss = 0.0210, similarity loss: 0.2921\n",
      "Epoch 51, loss = 0.3301, time: 25.2960\n",
      "reconstruction loss = 0.0179, similarity loss: 0.2405\n",
      "Epoch 52, loss = 0.3959, time: 23.6382\n",
      "reconstruction loss = 0.0225, similarity loss: 0.2834\n",
      "Epoch 53, loss = 0.3637, time: 24.1008\n",
      "reconstruction loss = 0.0181, similarity loss: 0.2733\n",
      "Epoch 54, loss = 0.3618, time: 24.2536\n",
      "reconstruction loss = 0.0181, similarity loss: 0.2711\n",
      "Epoch 55, loss = 0.2916, time: 23.8231\n",
      "reconstruction loss = 0.0166, similarity loss: 0.2087\n",
      "Epoch 56, loss = 0.3285, time: 24.4372\n",
      "reconstruction loss = 0.0153, similarity loss: 0.2519\n",
      "Epoch 57, loss = 0.3170, time: 25.4625\n",
      "reconstruction loss = 0.0167, similarity loss: 0.2336\n",
      "Epoch 58, loss = 0.3527, time: 25.4703\n",
      "reconstruction loss = 0.0172, similarity loss: 0.2665\n",
      "Epoch 59, loss = 0.3175, time: 25.5452\n",
      "reconstruction loss = 0.0176, similarity loss: 0.2294\n",
      "Epoch 60, loss = 0.3696, time: 25.5774\n",
      "reconstruction loss = 0.0198, similarity loss: 0.2707\n",
      "Epoch 61, loss = 0.3807, time: 24.1731\n",
      "reconstruction loss = 0.0172, similarity loss: 0.2949\n",
      "Epoch 62, loss = 0.3372, time: 24.7144\n",
      "reconstruction loss = 0.0173, similarity loss: 0.2509\n",
      "Epoch 63, loss = 0.3284, time: 24.2581\n",
      "reconstruction loss = 0.0148, similarity loss: 0.2543\n",
      "Epoch 64, loss = 0.3222, time: 24.1117\n",
      "reconstruction loss = 0.0175, similarity loss: 0.2349\n",
      "Epoch 65, loss = 0.3198, time: 23.8999\n",
      "reconstruction loss = 0.0145, similarity loss: 0.2475\n",
      "Epoch 66, loss = 0.3104, time: 23.8348\n",
      "reconstruction loss = 0.0138, similarity loss: 0.2416\n",
      "Epoch 67, loss = 0.3312, time: 24.7679\n",
      "reconstruction loss = 0.0151, similarity loss: 0.2555\n",
      "Epoch 68, loss = 0.3116, time: 25.1683\n",
      "reconstruction loss = 0.0134, similarity loss: 0.2445\n",
      "Epoch 69, loss = 0.3406, time: 25.0645\n",
      "reconstruction loss = 0.0159, similarity loss: 0.2609\n",
      "Epoch 70, loss = 0.3405, time: 24.5827\n",
      "reconstruction loss = 0.0143, similarity loss: 0.2688\n",
      "Epoch 71, loss = 0.3464, time: 24.3739\n",
      "reconstruction loss = 0.0146, similarity loss: 0.2732\n",
      "Epoch 72, loss = 0.3013, time: 24.4787\n",
      "reconstruction loss = 0.0150, similarity loss: 0.2263\n",
      "Epoch 73, loss = 0.3192, time: 24.4121\n",
      "reconstruction loss = 0.0142, similarity loss: 0.2482\n",
      "Epoch 74, loss = 0.3106, time: 24.4017\n",
      "reconstruction loss = 0.0122, similarity loss: 0.2496\n",
      "Epoch 75, loss = 0.3325, time: 24.1362\n",
      "reconstruction loss = 0.0147, similarity loss: 0.2588\n"
     ]
    }
   ],
   "source": [
    "pars.lam = 5\n",
    "vis = visdom.Visdom(port=8097,env='ae_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_classifier = SGDClassifier(n_jobs=-1, alpha=0.01)\n",
    "train_unsupervised_ae(pars,sklearn_classifier=sklearn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.lam = 10\n",
    "vis = visdom.Visdom(port=8097,env='ae_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_classifier = SGDClassifier(n_jobs=-1, alpha=0.01)\n",
    "train_unsupervised_ae(pars,sklearn_classifier=sklearn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.lam = 20\n",
    "vis = visdom.Visdom(port=8097,env='ae_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_classifier = SGDClassifier(n_jobs=-1, alpha=0.01)\n",
    "train_unsupervised_ae(pars,sklearn_classifier=sklearn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.lam = 50\n",
    "vis = visdom.Visdom(port=8097,env='ae_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_classifier = SGDClassifier(n_jobs=-1, alpha=0.01)\n",
    "train_unsupervised_ae(pars,sklearn_classifier=sklearn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.lam = 100\n",
    "vis = visdom.Visdom(port=8097,env='ae_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_classifier = SGDClassifier(n_jobs=-1, alpha=0.01)\n",
    "train_unsupervised_ae(pars,sklearn_classifier=sklearn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.lam = 200\n",
    "vis = visdom.Visdom(port=8097,env='ae_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_classifier = SGDClassifier(n_jobs=-1, alpha=0.01)\n",
    "train_unsupervised_ae(pars,sklearn_classifier=sklearn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.lam = 500\n",
    "vis = visdom.Visdom(port=8097,env='ae_lam_'+str(pars.lam))\n",
    "train_unsupervised_ae(pars, vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_classifier = SGDClassifier(n_jobs=-1, alpha=0.01)\n",
    "train_unsupervised_ae(pars,sklearn_classifier=sklearn_classifier)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd034ed54560f0698c2946b7ca675e493afbd7ee3c0ecf162ae3deac3cf4477b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
