{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "datadirs = ''\n",
    "sys.path.insert(1, datadirs)\n",
    "savepath = datadirs+'save/'\n",
    "datapath = datadirs+'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visdom\n",
    "# python -m visdom.server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pars import PARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from utils import *\n",
    "from setup_net import *\n",
    "from loss import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture: CONV6\n",
      "nonlinear: hardtanh\n",
      "batch_size: 500\n",
      "headsize: 64\n",
      "dataset: Cifar100\n",
      "loss: SimCLR\n",
      "OPT: Adam\n",
      "LR: 0.0001\n",
      "epochs: 300\n",
      "clf_dataset: Cifar10\n",
      "clf_loss: CE\n",
      "clf_opt: Adam\n",
      "clf_lr: 0.001\n",
      "clf_epochs: 100\n",
      "repeat: 1\n",
      "device: cuda:0\n",
      "datapath: data/\n",
      "savepath: save/\n",
      "loadnet: None\n",
      "loadclf: None\n",
      "lam: 1\n",
      "auxnonlinear: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pars = PARS(device, datapath, savepath)\n",
    "pars.architecture = 'CONV6'\n",
    "pars.LR = 0.0001\n",
    "pars.clf_lr = 0.001\n",
    "pars.epochs = 300\n",
    "pars.clf_epochs = 100\n",
    "pars.nonlinear = 'hardtanh'\n",
    "pars.repeat = 1\n",
    "pars.lam = 1 # proportion of the reconstruction loss\n",
    "print(pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/\n",
      "hardtanh_Cifar100_Adam_LR_0.0001_Epochs_300_CLF_Cifar10_Adam_LR_0.001_Epochs_100_lam_1\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxhead): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=8192, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(8, 32, 32))\n",
      "    (deconv): ConvTranspose2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=8192, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(8, 32, 32))\n",
      "    (deconv): ConvTranspose2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 0.0611, time: 27.1891\n",
      "reconstruction loss = 0.0611, similarity loss: 0.6008\n",
      "Epoch 1, loss = 0.0381, time: 18.2042\n",
      "reconstruction loss = 0.0381, similarity loss: 0.6163\n",
      "Epoch 2, loss = 0.0339, time: 17.7847\n",
      "reconstruction loss = 0.0339, similarity loss: 0.6055\n",
      "Epoch 3, loss = 0.0235, time: 18.2743\n",
      "reconstruction loss = 0.0235, similarity loss: 0.9526\n",
      "Epoch 4, loss = 0.0205, time: 17.3106\n",
      "reconstruction loss = 0.0205, similarity loss: 0.9595\n",
      "Epoch 5, loss = 0.0184, time: 17.6455\n",
      "reconstruction loss = 0.0184, similarity loss: 0.9196\n",
      "Epoch 6, loss = 0.0164, time: 18.0041\n",
      "reconstruction loss = 0.0164, similarity loss: 0.9268\n",
      "Epoch 7, loss = 0.0155, time: 17.5087\n",
      "reconstruction loss = 0.0155, similarity loss: 0.8803\n",
      "Epoch 8, loss = 0.0148, time: 18.1096\n",
      "reconstruction loss = 0.0148, similarity loss: 1.0271\n",
      "Epoch 9, loss = 0.0127, time: 17.9421\n",
      "reconstruction loss = 0.0127, similarity loss: 1.0903\n",
      "Epoch 10, loss = 0.0117, time: 18.0174\n",
      "reconstruction loss = 0.0117, similarity loss: 0.9774\n",
      "Epoch 11, loss = 0.0110, time: 17.6072\n",
      "reconstruction loss = 0.0110, similarity loss: 1.0239\n",
      "Epoch 12, loss = 0.0103, time: 17.3347\n",
      "reconstruction loss = 0.0103, similarity loss: 0.9991\n",
      "Epoch 13, loss = 0.0101, time: 17.3532\n",
      "reconstruction loss = 0.0101, similarity loss: 1.0075\n",
      "Epoch 14, loss = 0.0099, time: 17.2136\n",
      "reconstruction loss = 0.0099, similarity loss: 0.9893\n",
      "Epoch 15, loss = 0.0091, time: 17.4273\n",
      "reconstruction loss = 0.0091, similarity loss: 0.9737\n",
      "Epoch 16, loss = 0.0101, time: 17.2992\n",
      "reconstruction loss = 0.0101, similarity loss: 0.9607\n",
      "Epoch 17, loss = 0.0085, time: 17.4965\n",
      "reconstruction loss = 0.0085, similarity loss: 0.9696\n",
      "Epoch 18, loss = 0.0081, time: 17.3089\n",
      "reconstruction loss = 0.0081, similarity loss: 0.9782\n",
      "Epoch 19, loss = 0.0085, time: 17.3796\n",
      "reconstruction loss = 0.0085, similarity loss: 0.9197\n",
      "Epoch 20, loss = 0.0084, time: 17.2488\n",
      "reconstruction loss = 0.0084, similarity loss: 0.9731\n",
      "Epoch 21, loss = 0.0079, time: 17.2417\n",
      "reconstruction loss = 0.0079, similarity loss: 0.9277\n",
      "Epoch 22, loss = 0.0077, time: 17.4910\n",
      "reconstruction loss = 0.0077, similarity loss: 1.0402\n",
      "Epoch 23, loss = 0.0076, time: 17.1980\n",
      "reconstruction loss = 0.0076, similarity loss: 1.0379\n",
      "Epoch 24, loss = 0.0072, time: 17.4004\n",
      "reconstruction loss = 0.0072, similarity loss: 1.0132\n",
      "Epoch 25, loss = 0.0071, time: 17.6278\n",
      "reconstruction loss = 0.0071, similarity loss: 0.9966\n",
      "Epoch 26, loss = 0.0074, time: 18.1974\n",
      "reconstruction loss = 0.0074, similarity loss: 1.0014\n",
      "Epoch 27, loss = 0.0072, time: 17.9196\n",
      "reconstruction loss = 0.0072, similarity loss: 0.9730\n",
      "Epoch 28, loss = 0.0068, time: 17.8686\n",
      "reconstruction loss = 0.0068, similarity loss: 1.0667\n",
      "Epoch 29, loss = 0.0069, time: 18.0182\n",
      "reconstruction loss = 0.0069, similarity loss: 1.0350\n",
      "Epoch 30, loss = 0.0067, time: 17.5102\n",
      "reconstruction loss = 0.0067, similarity loss: 0.8777\n",
      "Epoch 31, loss = 0.0065, time: 17.5557\n",
      "reconstruction loss = 0.0065, similarity loss: 1.0034\n",
      "Epoch 32, loss = 0.0064, time: 17.9652\n",
      "reconstruction loss = 0.0064, similarity loss: 0.9901\n",
      "Epoch 33, loss = 0.0064, time: 17.2887\n",
      "reconstruction loss = 0.0064, similarity loss: 0.9750\n",
      "Epoch 34, loss = 0.0065, time: 17.2520\n",
      "reconstruction loss = 0.0065, similarity loss: 0.9074\n",
      "Epoch 35, loss = 0.0066, time: 17.2130\n",
      "reconstruction loss = 0.0066, similarity loss: 0.9694\n",
      "Epoch 36, loss = 0.0062, time: 17.2043\n",
      "reconstruction loss = 0.0062, similarity loss: 1.0469\n",
      "Epoch 37, loss = 0.0063, time: 17.1809\n",
      "reconstruction loss = 0.0063, similarity loss: 1.0388\n",
      "Epoch 38, loss = 0.0066, time: 17.2917\n",
      "reconstruction loss = 0.0066, similarity loss: 0.9675\n",
      "Epoch 39, loss = 0.0066, time: 17.2265\n",
      "reconstruction loss = 0.0066, similarity loss: 0.9184\n",
      "Epoch 40, loss = 0.0064, time: 17.3044\n",
      "reconstruction loss = 0.0064, similarity loss: 0.9657\n",
      "Epoch 41, loss = 0.0058, time: 17.4254\n",
      "reconstruction loss = 0.0058, similarity loss: 0.9506\n",
      "Epoch 42, loss = 0.0058, time: 17.2460\n",
      "reconstruction loss = 0.0058, similarity loss: 0.9681\n",
      "Epoch 43, loss = 0.0056, time: 17.4292\n",
      "reconstruction loss = 0.0056, similarity loss: 1.0283\n",
      "Epoch 44, loss = 0.0062, time: 17.2853\n",
      "reconstruction loss = 0.0062, similarity loss: 0.9623\n",
      "Epoch 45, loss = 0.0056, time: 17.3150\n",
      "reconstruction loss = 0.0056, similarity loss: 0.9138\n",
      "Epoch 46, loss = 0.0060, time: 17.3034\n",
      "reconstruction loss = 0.0060, similarity loss: 0.9915\n",
      "Epoch 47, loss = 0.0056, time: 17.2929\n",
      "reconstruction loss = 0.0056, similarity loss: 1.0252\n",
      "Epoch 48, loss = 0.0057, time: 17.2266\n",
      "reconstruction loss = 0.0057, similarity loss: 1.0520\n",
      "Epoch 49, loss = 0.0058, time: 17.2304\n",
      "reconstruction loss = 0.0058, similarity loss: 0.9654\n",
      "Epoch 50, loss = 0.0058, time: 18.1696\n",
      "reconstruction loss = 0.0058, similarity loss: 0.9954\n",
      "Epoch 51, loss = 0.0055, time: 17.6571\n",
      "reconstruction loss = 0.0055, similarity loss: 1.0882\n",
      "Epoch 52, loss = 0.0056, time: 17.3326\n",
      "reconstruction loss = 0.0056, similarity loss: 1.0440\n",
      "Epoch 53, loss = 0.0053, time: 17.2315\n",
      "reconstruction loss = 0.0053, similarity loss: 1.0189\n",
      "Epoch 54, loss = 0.0057, time: 17.6675\n",
      "reconstruction loss = 0.0057, similarity loss: 1.0024\n",
      "Epoch 55, loss = 0.0048, time: 17.3108\n",
      "reconstruction loss = 0.0048, similarity loss: 1.0241\n",
      "Epoch 56, loss = 0.0059, time: 17.5567\n",
      "reconstruction loss = 0.0059, similarity loss: 1.1101\n",
      "Epoch 57, loss = 0.0057, time: 17.4158\n",
      "reconstruction loss = 0.0057, similarity loss: 0.9856\n",
      "Epoch 58, loss = 0.0053, time: 18.1327\n",
      "reconstruction loss = 0.0053, similarity loss: 1.1622\n",
      "Epoch 59, loss = 0.0053, time: 18.5547\n",
      "reconstruction loss = 0.0053, similarity loss: 1.1408\n",
      "Epoch 60, loss = 0.0053, time: 18.1399\n",
      "reconstruction loss = 0.0053, similarity loss: 1.0365\n",
      "Epoch 61, loss = 0.0055, time: 18.1582\n",
      "reconstruction loss = 0.0055, similarity loss: 0.9579\n",
      "Epoch 62, loss = 0.0054, time: 18.3419\n",
      "reconstruction loss = 0.0054, similarity loss: 1.0119\n",
      "Epoch 63, loss = 0.0050, time: 18.2895\n",
      "reconstruction loss = 0.0050, similarity loss: 0.9555\n",
      "Epoch 64, loss = 0.0057, time: 18.2173\n",
      "reconstruction loss = 0.0057, similarity loss: 0.9771\n",
      "Epoch 65, loss = 0.0052, time: 18.2203\n",
      "reconstruction loss = 0.0052, similarity loss: 1.1053\n",
      "Epoch 66, loss = 0.0055, time: 18.5493\n",
      "reconstruction loss = 0.0055, similarity loss: 1.0006\n",
      "Epoch 67, loss = 0.0053, time: 18.3307\n",
      "reconstruction loss = 0.0053, similarity loss: 1.0688\n",
      "Epoch 68, loss = 0.0049, time: 18.3351\n",
      "reconstruction loss = 0.0049, similarity loss: 1.1254\n",
      "Epoch 69, loss = 0.0049, time: 17.8959\n",
      "reconstruction loss = 0.0049, similarity loss: 0.9993\n",
      "Epoch 70, loss = 0.0050, time: 17.4655\n",
      "reconstruction loss = 0.0050, similarity loss: 0.9765\n",
      "Epoch 71, loss = 0.0051, time: 17.4979\n",
      "reconstruction loss = 0.0051, similarity loss: 0.9738\n",
      "Epoch 72, loss = 0.0049, time: 18.2060\n",
      "reconstruction loss = 0.0049, similarity loss: 1.1180\n",
      "Epoch 73, loss = 0.0044, time: 20.1045\n",
      "reconstruction loss = 0.0044, similarity loss: 1.0832\n",
      "Epoch 74, loss = 0.0051, time: 18.8653\n",
      "reconstruction loss = 0.0051, similarity loss: 1.0883\n",
      "Epoch 75, loss = 0.0046, time: 17.9954\n",
      "reconstruction loss = 0.0046, similarity loss: 1.0457\n",
      "Epoch 76, loss = 0.0051, time: 18.0900\n",
      "reconstruction loss = 0.0051, similarity loss: 0.9883\n",
      "Epoch 77, loss = 0.0050, time: 18.0008\n",
      "reconstruction loss = 0.0050, similarity loss: 1.0246\n",
      "Epoch 78, loss = 0.0046, time: 18.3275\n",
      "reconstruction loss = 0.0046, similarity loss: 1.0354\n",
      "Epoch 79, loss = 0.0049, time: 18.1812\n",
      "reconstruction loss = 0.0049, similarity loss: 1.0065\n",
      "Epoch 80, loss = 0.0049, time: 18.5550\n",
      "reconstruction loss = 0.0049, similarity loss: 1.0377\n",
      "Epoch 81, loss = 0.0046, time: 17.9516\n",
      "reconstruction loss = 0.0046, similarity loss: 0.9795\n",
      "Epoch 82, loss = 0.0045, time: 17.6262\n",
      "reconstruction loss = 0.0045, similarity loss: 1.0123\n",
      "Epoch 83, loss = 0.0046, time: 17.6443\n",
      "reconstruction loss = 0.0046, similarity loss: 1.1604\n",
      "Epoch 84, loss = 0.0052, time: 17.9852\n",
      "reconstruction loss = 0.0052, similarity loss: 1.0427\n",
      "Epoch 85, loss = 0.0050, time: 17.7915\n",
      "reconstruction loss = 0.0050, similarity loss: 1.1125\n",
      "Epoch 86, loss = 0.0046, time: 17.6616\n",
      "reconstruction loss = 0.0046, similarity loss: 1.0501\n",
      "Epoch 87, loss = 0.0049, time: 17.7280\n",
      "reconstruction loss = 0.0049, similarity loss: 0.9987\n",
      "Epoch 88, loss = 0.0048, time: 17.5601\n",
      "reconstruction loss = 0.0048, similarity loss: 0.9735\n",
      "Epoch 89, loss = 0.0049, time: 18.6574\n",
      "reconstruction loss = 0.0049, similarity loss: 1.0299\n",
      "Epoch 90, loss = 0.0045, time: 17.4206\n",
      "reconstruction loss = 0.0045, similarity loss: 1.0716\n",
      "Epoch 91, loss = 0.0048, time: 17.0053\n",
      "reconstruction loss = 0.0048, similarity loss: 1.0383\n",
      "Epoch 92, loss = 0.0044, time: 17.0230\n",
      "reconstruction loss = 0.0044, similarity loss: 1.0612\n",
      "Epoch 93, loss = 0.0043, time: 16.9317\n",
      "reconstruction loss = 0.0043, similarity loss: 1.0870\n",
      "Epoch 94, loss = 0.0047, time: 17.0928\n",
      "reconstruction loss = 0.0047, similarity loss: 1.1138\n",
      "Epoch 95, loss = 0.0048, time: 17.8433\n",
      "reconstruction loss = 0.0048, similarity loss: 1.0408\n",
      "Epoch 96, loss = 0.0044, time: 18.4546\n",
      "reconstruction loss = 0.0044, similarity loss: 1.0643\n",
      "Epoch 97, loss = 0.0042, time: 18.4726\n",
      "reconstruction loss = 0.0042, similarity loss: 1.1088\n",
      "Epoch 98, loss = 0.0042, time: 18.2652\n",
      "reconstruction loss = 0.0042, similarity loss: 1.1025\n",
      "Epoch 99, loss = 0.0049, time: 18.2790\n",
      "reconstruction loss = 0.0049, similarity loss: 1.0273\n",
      "Epoch 100, loss = 0.0046, time: 18.3037\n",
      "reconstruction loss = 0.0046, similarity loss: 1.0415\n",
      "Epoch 101, loss = 0.0046, time: 18.2804\n",
      "reconstruction loss = 0.0046, similarity loss: 1.0424\n",
      "Epoch 102, loss = 0.0042, time: 18.3910\n",
      "reconstruction loss = 0.0042, similarity loss: 1.1664\n",
      "Epoch 103, loss = 0.0046, time: 18.2506\n",
      "reconstruction loss = 0.0046, similarity loss: 1.0487\n",
      "Epoch 104, loss = 0.0040, time: 18.2829\n",
      "reconstruction loss = 0.0040, similarity loss: 0.9606\n",
      "Epoch 105, loss = 0.0043, time: 18.4972\n",
      "reconstruction loss = 0.0043, similarity loss: 1.1007\n",
      "Epoch 106, loss = 0.0050, time: 18.5788\n",
      "reconstruction loss = 0.0050, similarity loss: 1.0388\n",
      "Epoch 107, loss = 0.0040, time: 18.4797\n",
      "reconstruction loss = 0.0040, similarity loss: 1.0302\n",
      "Epoch 108, loss = 0.0045, time: 18.5885\n",
      "reconstruction loss = 0.0045, similarity loss: 0.9889\n",
      "Epoch 109, loss = 0.0044, time: 19.5698\n",
      "reconstruction loss = 0.0044, similarity loss: 1.0275\n",
      "Epoch 110, loss = 0.0044, time: 19.4120\n",
      "reconstruction loss = 0.0044, similarity loss: 1.0113\n",
      "Epoch 111, loss = 0.0043, time: 18.6234\n",
      "reconstruction loss = 0.0043, similarity loss: 1.1047\n",
      "Epoch 112, loss = 0.0040, time: 18.3690\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1205\n",
      "Epoch 113, loss = 0.0038, time: 18.2957\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0615\n",
      "Epoch 114, loss = 0.0040, time: 18.5635\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1372\n",
      "Epoch 115, loss = 0.0042, time: 18.3899\n",
      "reconstruction loss = 0.0042, similarity loss: 1.0802\n",
      "Epoch 116, loss = 0.0046, time: 18.4671\n",
      "reconstruction loss = 0.0046, similarity loss: 1.0529\n",
      "Epoch 117, loss = 0.0043, time: 18.2817\n",
      "reconstruction loss = 0.0043, similarity loss: 0.9963\n",
      "Epoch 118, loss = 0.0043, time: 18.1533\n",
      "reconstruction loss = 0.0043, similarity loss: 1.0743\n",
      "Epoch 119, loss = 0.0043, time: 18.5660\n",
      "reconstruction loss = 0.0043, similarity loss: 1.1230\n",
      "Epoch 120, loss = 0.0043, time: 17.4843\n",
      "reconstruction loss = 0.0043, similarity loss: 1.0324\n",
      "Epoch 121, loss = 0.0043, time: 18.2394\n",
      "reconstruction loss = 0.0043, similarity loss: 1.0266\n",
      "Epoch 122, loss = 0.0040, time: 18.1144\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1279\n",
      "Epoch 123, loss = 0.0041, time: 18.2811\n",
      "reconstruction loss = 0.0041, similarity loss: 1.1152\n",
      "Epoch 124, loss = 0.0045, time: 18.3122\n",
      "reconstruction loss = 0.0045, similarity loss: 1.1104\n",
      "Epoch 125, loss = 0.0043, time: 18.4122\n",
      "reconstruction loss = 0.0043, similarity loss: 1.0490\n",
      "Epoch 126, loss = 0.0039, time: 18.5143\n",
      "reconstruction loss = 0.0039, similarity loss: 1.1057\n",
      "Epoch 127, loss = 0.0040, time: 18.1795\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1062\n",
      "Epoch 128, loss = 0.0044, time: 18.3108\n",
      "reconstruction loss = 0.0044, similarity loss: 1.1228\n",
      "Epoch 129, loss = 0.0040, time: 18.1314\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1018\n",
      "Epoch 130, loss = 0.0041, time: 18.2418\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0749\n",
      "Epoch 131, loss = 0.0041, time: 18.2135\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0971\n",
      "Epoch 132, loss = 0.0041, time: 18.5193\n",
      "reconstruction loss = 0.0041, similarity loss: 1.1053\n",
      "Epoch 133, loss = 0.0045, time: 18.6513\n",
      "reconstruction loss = 0.0045, similarity loss: 1.0403\n",
      "Epoch 134, loss = 0.0040, time: 18.3737\n",
      "reconstruction loss = 0.0040, similarity loss: 1.0367\n",
      "Epoch 135, loss = 0.0042, time: 18.1179\n",
      "reconstruction loss = 0.0042, similarity loss: 0.9737\n",
      "Epoch 136, loss = 0.0038, time: 18.2300\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0989\n",
      "Epoch 137, loss = 0.0039, time: 18.2835\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0916\n",
      "Epoch 138, loss = 0.0041, time: 18.1852\n",
      "reconstruction loss = 0.0041, similarity loss: 1.1880\n",
      "Epoch 139, loss = 0.0039, time: 18.2004\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0785\n",
      "Epoch 140, loss = 0.0045, time: 18.1387\n",
      "reconstruction loss = 0.0045, similarity loss: 0.9782\n",
      "Epoch 141, loss = 0.0041, time: 18.2015\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0450\n",
      "Epoch 142, loss = 0.0041, time: 18.1962\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0785\n",
      "Epoch 143, loss = 0.0041, time: 18.1806\n",
      "reconstruction loss = 0.0041, similarity loss: 1.1475\n",
      "Epoch 144, loss = 0.0040, time: 18.4635\n",
      "reconstruction loss = 0.0040, similarity loss: 1.0899\n",
      "Epoch 145, loss = 0.0040, time: 18.0941\n",
      "reconstruction loss = 0.0040, similarity loss: 1.0577\n",
      "Epoch 146, loss = 0.0039, time: 18.1323\n",
      "reconstruction loss = 0.0039, similarity loss: 1.1233\n",
      "Epoch 147, loss = 0.0040, time: 18.1288\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1279\n",
      "Epoch 148, loss = 0.0041, time: 18.1144\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0546\n",
      "Epoch 149, loss = 0.0037, time: 18.6639\n",
      "reconstruction loss = 0.0037, similarity loss: 1.1460\n",
      "Epoch 150, loss = 0.0038, time: 18.8587\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0101\n",
      "Epoch 151, loss = 0.0040, time: 18.9659\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1306\n",
      "Epoch 152, loss = 0.0040, time: 19.0159\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1082\n",
      "Epoch 153, loss = 0.0042, time: 19.0512\n",
      "reconstruction loss = 0.0042, similarity loss: 1.0786\n",
      "Epoch 154, loss = 0.0039, time: 18.9261\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0945\n",
      "Epoch 155, loss = 0.0034, time: 18.9597\n",
      "reconstruction loss = 0.0034, similarity loss: 1.1440\n",
      "Epoch 156, loss = 0.0041, time: 18.8855\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0975\n",
      "Epoch 157, loss = 0.0039, time: 18.9613\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0035\n",
      "Epoch 158, loss = 0.0043, time: 18.9586\n",
      "reconstruction loss = 0.0043, similarity loss: 1.0729\n",
      "Epoch 159, loss = 0.0039, time: 19.0086\n",
      "reconstruction loss = 0.0039, similarity loss: 1.1205\n",
      "Epoch 160, loss = 0.0039, time: 19.0766\n",
      "reconstruction loss = 0.0039, similarity loss: 1.1452\n",
      "Epoch 161, loss = 0.0038, time: 19.1062\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0929\n",
      "Epoch 162, loss = 0.0039, time: 18.9335\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0830\n",
      "Epoch 163, loss = 0.0039, time: 19.1742\n",
      "reconstruction loss = 0.0039, similarity loss: 1.1057\n",
      "Epoch 164, loss = 0.0040, time: 18.9469\n",
      "reconstruction loss = 0.0040, similarity loss: 1.0922\n",
      "Epoch 165, loss = 0.0038, time: 19.0261\n",
      "reconstruction loss = 0.0038, similarity loss: 1.1128\n",
      "Epoch 166, loss = 0.0040, time: 19.0384\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1736\n",
      "Epoch 167, loss = 0.0037, time: 18.9166\n",
      "reconstruction loss = 0.0037, similarity loss: 1.0872\n",
      "Epoch 168, loss = 0.0039, time: 18.9331\n",
      "reconstruction loss = 0.0039, similarity loss: 0.9905\n",
      "Epoch 169, loss = 0.0043, time: 17.9220\n",
      "reconstruction loss = 0.0043, similarity loss: 1.0750\n",
      "Epoch 170, loss = 0.0043, time: 17.5250\n",
      "reconstruction loss = 0.0043, similarity loss: 1.0737\n",
      "Epoch 171, loss = 0.0042, time: 17.3766\n",
      "reconstruction loss = 0.0042, similarity loss: 1.1283\n",
      "Epoch 172, loss = 0.0040, time: 17.6716\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1174\n",
      "Epoch 173, loss = 0.0038, time: 18.1234\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0839\n",
      "Epoch 174, loss = 0.0039, time: 18.3200\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0807\n",
      "Epoch 175, loss = 0.0039, time: 17.2544\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0963\n",
      "Epoch 176, loss = 0.0038, time: 17.2415\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0539\n",
      "Epoch 177, loss = 0.0040, time: 17.1500\n",
      "reconstruction loss = 0.0040, similarity loss: 1.0570\n",
      "Epoch 178, loss = 0.0040, time: 17.3303\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1693\n",
      "Epoch 179, loss = 0.0037, time: 17.4820\n",
      "reconstruction loss = 0.0037, similarity loss: 0.9524\n",
      "Epoch 180, loss = 0.0036, time: 17.5339\n",
      "reconstruction loss = 0.0036, similarity loss: 1.0400\n",
      "Epoch 181, loss = 0.0042, time: 17.3559\n",
      "reconstruction loss = 0.0042, similarity loss: 1.0687\n",
      "Epoch 182, loss = 0.0037, time: 16.8819\n",
      "reconstruction loss = 0.0037, similarity loss: 1.0420\n",
      "Epoch 183, loss = 0.0041, time: 17.0449\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0592\n",
      "Epoch 184, loss = 0.0035, time: 17.0301\n",
      "reconstruction loss = 0.0035, similarity loss: 1.1026\n",
      "Epoch 185, loss = 0.0039, time: 16.9437\n",
      "reconstruction loss = 0.0039, similarity loss: 0.9822\n",
      "Epoch 186, loss = 0.0039, time: 17.0284\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0249\n",
      "Epoch 187, loss = 0.0035, time: 16.9597\n",
      "reconstruction loss = 0.0035, similarity loss: 1.0153\n",
      "Epoch 188, loss = 0.0041, time: 16.9330\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0017\n",
      "Epoch 189, loss = 0.0039, time: 16.9933\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0325\n",
      "Epoch 190, loss = 0.0040, time: 17.1042\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1235\n",
      "Epoch 191, loss = 0.0039, time: 17.1730\n",
      "reconstruction loss = 0.0039, similarity loss: 1.1296\n",
      "Epoch 192, loss = 0.0037, time: 16.9340\n",
      "reconstruction loss = 0.0037, similarity loss: 1.0339\n",
      "Epoch 193, loss = 0.0039, time: 17.8210\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0589\n",
      "Epoch 194, loss = 0.0042, time: 17.5969\n",
      "reconstruction loss = 0.0042, similarity loss: 1.0491\n",
      "Epoch 195, loss = 0.0043, time: 17.7483\n",
      "reconstruction loss = 0.0043, similarity loss: 1.0689\n",
      "Epoch 196, loss = 0.0041, time: 17.5133\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0829\n",
      "Epoch 197, loss = 0.0038, time: 17.5403\n",
      "reconstruction loss = 0.0038, similarity loss: 0.9511\n",
      "Epoch 198, loss = 0.0040, time: 17.6150\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1059\n",
      "Epoch 199, loss = 0.0041, time: 17.4694\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0169\n",
      "Epoch 200, loss = 0.0041, time: 17.6608\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0868\n",
      "Epoch 201, loss = 0.0039, time: 17.5567\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0285\n",
      "Epoch 202, loss = 0.0038, time: 17.5918\n",
      "reconstruction loss = 0.0038, similarity loss: 1.1209\n",
      "Epoch 203, loss = 0.0035, time: 17.5654\n",
      "reconstruction loss = 0.0035, similarity loss: 1.1176\n",
      "Epoch 204, loss = 0.0038, time: 17.5347\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0530\n",
      "Epoch 205, loss = 0.0043, time: 17.5654\n",
      "reconstruction loss = 0.0043, similarity loss: 1.0883\n",
      "Epoch 206, loss = 0.0039, time: 17.5705\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0883\n",
      "Epoch 207, loss = 0.0035, time: 17.9072\n",
      "reconstruction loss = 0.0035, similarity loss: 1.0771\n",
      "Epoch 208, loss = 0.0037, time: 18.1673\n",
      "reconstruction loss = 0.0037, similarity loss: 1.0926\n",
      "Epoch 209, loss = 0.0037, time: 18.4327\n",
      "reconstruction loss = 0.0037, similarity loss: 1.0901\n",
      "Epoch 210, loss = 0.0040, time: 18.5407\n",
      "reconstruction loss = 0.0040, similarity loss: 1.0188\n",
      "Epoch 211, loss = 0.0041, time: 18.3358\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0712\n",
      "Epoch 212, loss = 0.0041, time: 18.4631\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0285\n",
      "Epoch 213, loss = 0.0039, time: 18.3265\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0403\n",
      "Epoch 214, loss = 0.0035, time: 18.2107\n",
      "reconstruction loss = 0.0035, similarity loss: 1.0820\n",
      "Epoch 215, loss = 0.0038, time: 18.2826\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0665\n",
      "Epoch 216, loss = 0.0040, time: 18.5333\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1726\n",
      "Epoch 217, loss = 0.0036, time: 18.2349\n",
      "reconstruction loss = 0.0036, similarity loss: 1.0651\n",
      "Epoch 218, loss = 0.0036, time: 18.2967\n",
      "reconstruction loss = 0.0036, similarity loss: 1.1234\n",
      "Epoch 219, loss = 0.0037, time: 17.2558\n",
      "reconstruction loss = 0.0037, similarity loss: 1.1368\n",
      "Epoch 220, loss = 0.0039, time: 17.1824\n",
      "reconstruction loss = 0.0039, similarity loss: 1.1076\n",
      "Epoch 221, loss = 0.0039, time: 16.9223\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0277\n",
      "Epoch 222, loss = 0.0036, time: 17.0315\n",
      "reconstruction loss = 0.0036, similarity loss: 1.1021\n",
      "Epoch 223, loss = 0.0039, time: 16.9297\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0828\n",
      "Epoch 224, loss = 0.0039, time: 17.3479\n",
      "reconstruction loss = 0.0039, similarity loss: 1.1683\n",
      "Epoch 225, loss = 0.0034, time: 17.2502\n",
      "reconstruction loss = 0.0034, similarity loss: 1.1730\n",
      "Epoch 226, loss = 0.0040, time: 17.1886\n",
      "reconstruction loss = 0.0040, similarity loss: 1.0795\n",
      "Epoch 227, loss = 0.0036, time: 17.4926\n",
      "reconstruction loss = 0.0036, similarity loss: 1.1173\n",
      "Epoch 228, loss = 0.0039, time: 17.3338\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0881\n",
      "Epoch 229, loss = 0.0040, time: 17.0657\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1170\n",
      "Epoch 230, loss = 0.0038, time: 17.0662\n",
      "reconstruction loss = 0.0038, similarity loss: 1.1009\n",
      "Epoch 231, loss = 0.0039, time: 17.0440\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0648\n",
      "Epoch 232, loss = 0.0038, time: 17.1223\n",
      "reconstruction loss = 0.0038, similarity loss: 1.1324\n",
      "Epoch 233, loss = 0.0039, time: 17.0228\n",
      "reconstruction loss = 0.0039, similarity loss: 1.2026\n",
      "Epoch 234, loss = 0.0035, time: 16.9629\n",
      "reconstruction loss = 0.0035, similarity loss: 1.0957\n",
      "Epoch 235, loss = 0.0037, time: 16.9673\n",
      "reconstruction loss = 0.0037, similarity loss: 1.1274\n",
      "Epoch 236, loss = 0.0037, time: 16.9865\n",
      "reconstruction loss = 0.0037, similarity loss: 1.0757\n",
      "Epoch 237, loss = 0.0039, time: 17.0153\n",
      "reconstruction loss = 0.0039, similarity loss: 1.1426\n",
      "Epoch 238, loss = 0.0038, time: 17.1849\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0783\n",
      "Epoch 239, loss = 0.0037, time: 16.8303\n",
      "reconstruction loss = 0.0037, similarity loss: 1.0543\n",
      "Epoch 240, loss = 0.0035, time: 16.9341\n",
      "reconstruction loss = 0.0035, similarity loss: 1.0392\n",
      "Epoch 241, loss = 0.0037, time: 16.9869\n",
      "reconstruction loss = 0.0037, similarity loss: 1.1213\n",
      "Epoch 242, loss = 0.0039, time: 16.9381\n",
      "reconstruction loss = 0.0039, similarity loss: 1.1120\n",
      "Epoch 243, loss = 0.0038, time: 16.8298\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0291\n",
      "Epoch 244, loss = 0.0043, time: 17.3734\n",
      "reconstruction loss = 0.0043, similarity loss: 1.0783\n",
      "Epoch 245, loss = 0.0039, time: 17.4839\n",
      "reconstruction loss = 0.0039, similarity loss: 1.1254\n",
      "Epoch 246, loss = 0.0039, time: 18.2805\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0649\n",
      "Epoch 247, loss = 0.0038, time: 18.2391\n",
      "reconstruction loss = 0.0038, similarity loss: 1.1265\n",
      "Epoch 248, loss = 0.0038, time: 19.3101\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0997\n",
      "Epoch 249, loss = 0.0039, time: 19.3703\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0100\n",
      "Epoch 250, loss = 0.0038, time: 19.3096\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0890\n",
      "Epoch 251, loss = 0.0036, time: 19.2414\n",
      "reconstruction loss = 0.0036, similarity loss: 1.0796\n",
      "Epoch 252, loss = 0.0037, time: 19.1381\n",
      "reconstruction loss = 0.0037, similarity loss: 1.0503\n",
      "Epoch 253, loss = 0.0038, time: 19.2898\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0508\n",
      "Epoch 254, loss = 0.0037, time: 19.0566\n",
      "reconstruction loss = 0.0037, similarity loss: 1.0412\n",
      "Epoch 255, loss = 0.0036, time: 19.1656\n",
      "reconstruction loss = 0.0036, similarity loss: 1.0625\n",
      "Epoch 256, loss = 0.0038, time: 19.1551\n",
      "reconstruction loss = 0.0038, similarity loss: 1.1095\n",
      "Epoch 257, loss = 0.0037, time: 19.3708\n",
      "reconstruction loss = 0.0037, similarity loss: 1.0413\n",
      "Epoch 258, loss = 0.0039, time: 19.2074\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0740\n",
      "Epoch 259, loss = 0.0034, time: 19.2112\n",
      "reconstruction loss = 0.0034, similarity loss: 1.0883\n",
      "Epoch 260, loss = 0.0043, time: 19.2818\n",
      "reconstruction loss = 0.0043, similarity loss: 1.1292\n",
      "Epoch 261, loss = 0.0041, time: 19.4697\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0244\n",
      "Epoch 262, loss = 0.0038, time: 19.3054\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0669\n",
      "Epoch 263, loss = 0.0038, time: 20.2513\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0061\n",
      "Epoch 264, loss = 0.0039, time: 20.4851\n",
      "reconstruction loss = 0.0039, similarity loss: 1.1133\n",
      "Epoch 265, loss = 0.0039, time: 20.3064\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0758\n",
      "Epoch 266, loss = 0.0039, time: 20.3586\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0561\n",
      "Epoch 267, loss = 0.0037, time: 20.1109\n",
      "reconstruction loss = 0.0037, similarity loss: 1.1045\n",
      "Epoch 268, loss = 0.0042, time: 20.2635\n",
      "reconstruction loss = 0.0042, similarity loss: 1.1704\n",
      "Epoch 269, loss = 0.0035, time: 20.1024\n",
      "reconstruction loss = 0.0035, similarity loss: 1.0099\n",
      "Epoch 270, loss = 0.0037, time: 20.2897\n",
      "reconstruction loss = 0.0037, similarity loss: 1.1056\n",
      "Epoch 271, loss = 0.0034, time: 20.1215\n",
      "reconstruction loss = 0.0034, similarity loss: 1.1171\n",
      "Epoch 272, loss = 0.0036, time: 20.0738\n",
      "reconstruction loss = 0.0036, similarity loss: 1.0440\n",
      "Epoch 273, loss = 0.0040, time: 20.2012\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1039\n",
      "Epoch 274, loss = 0.0040, time: 20.2104\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1411\n",
      "Epoch 275, loss = 0.0038, time: 20.3685\n",
      "reconstruction loss = 0.0038, similarity loss: 1.2160\n",
      "Epoch 276, loss = 0.0036, time: 19.8342\n",
      "reconstruction loss = 0.0036, similarity loss: 1.1105\n",
      "Epoch 277, loss = 0.0041, time: 19.1247\n",
      "reconstruction loss = 0.0041, similarity loss: 1.0774\n",
      "Epoch 278, loss = 0.0037, time: 19.0391\n",
      "reconstruction loss = 0.0037, similarity loss: 1.1166\n",
      "Epoch 279, loss = 0.0039, time: 19.0783\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0901\n",
      "Epoch 280, loss = 0.0037, time: 19.2575\n",
      "reconstruction loss = 0.0037, similarity loss: 1.0977\n",
      "Epoch 281, loss = 0.0035, time: 19.1342\n",
      "reconstruction loss = 0.0035, similarity loss: 1.0187\n",
      "Epoch 282, loss = 0.0036, time: 19.1489\n",
      "reconstruction loss = 0.0036, similarity loss: 1.0763\n",
      "Epoch 283, loss = 0.0038, time: 19.4657\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0656\n",
      "Epoch 284, loss = 0.0036, time: 19.4952\n",
      "reconstruction loss = 0.0036, similarity loss: 1.0623\n",
      "Epoch 285, loss = 0.0033, time: 17.9834\n",
      "reconstruction loss = 0.0033, similarity loss: 1.1868\n",
      "Epoch 286, loss = 0.0037, time: 17.6743\n",
      "reconstruction loss = 0.0037, similarity loss: 1.1215\n",
      "Epoch 287, loss = 0.0038, time: 18.5366\n",
      "reconstruction loss = 0.0038, similarity loss: 0.9994\n",
      "Epoch 288, loss = 0.0037, time: 18.6545\n",
      "reconstruction loss = 0.0037, similarity loss: 1.1854\n",
      "Epoch 289, loss = 0.0038, time: 18.7122\n",
      "reconstruction loss = 0.0038, similarity loss: 1.0938\n",
      "Epoch 290, loss = 0.0035, time: 18.6011\n",
      "reconstruction loss = 0.0035, similarity loss: 1.1252\n",
      "Epoch 291, loss = 0.0037, time: 18.5946\n",
      "reconstruction loss = 0.0037, similarity loss: 1.0222\n",
      "Epoch 292, loss = 0.0042, time: 18.7091\n",
      "reconstruction loss = 0.0042, similarity loss: 1.0242\n",
      "Epoch 293, loss = 0.0039, time: 19.2444\n",
      "reconstruction loss = 0.0039, similarity loss: 1.1272\n",
      "Epoch 294, loss = 0.0035, time: 18.4139\n",
      "reconstruction loss = 0.0035, similarity loss: 1.0993\n",
      "Epoch 295, loss = 0.0039, time: 18.6385\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0605\n",
      "Epoch 296, loss = 0.0039, time: 18.4562\n",
      "reconstruction loss = 0.0039, similarity loss: 1.0218\n",
      "Epoch 297, loss = 0.0036, time: 18.5117\n",
      "reconstruction loss = 0.0036, similarity loss: 1.0599\n",
      "Epoch 298, loss = 0.0040, time: 18.4533\n",
      "reconstruction loss = 0.0040, similarity loss: 1.1485\n",
      "Epoch 299, loss = 0.0033, time: 18.5032\n",
      "reconstruction loss = 0.0033, similarity loss: 1.0891\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.8735, val.acc = 0.4796\n",
      "Epoch 1, loss = 1.4418, val.acc = 0.5102\n",
      "Epoch 2, loss = 1.3664, val.acc = 0.5206\n",
      "Epoch 3, loss = 1.3182, val.acc = 0.5270\n",
      "Epoch 4, loss = 1.2819, val.acc = 0.5312\n",
      "Epoch 5, loss = 1.2526, val.acc = 0.5414\n",
      "Epoch 6, loss = 1.2279, val.acc = 0.5460\n",
      "Epoch 7, loss = 1.2064, val.acc = 0.5524\n",
      "Epoch 8, loss = 1.1874, val.acc = 0.5562\n",
      "Epoch 9, loss = 1.1702, val.acc = 0.5600\n",
      "Epoch 10, loss = 1.1547, val.acc = 0.5638\n",
      "Epoch 11, loss = 1.1404, val.acc = 0.5662\n",
      "Epoch 12, loss = 1.1272, val.acc = 0.5688\n",
      "Epoch 13, loss = 1.1150, val.acc = 0.5704\n",
      "Epoch 14, loss = 1.1035, val.acc = 0.5738\n",
      "Epoch 15, loss = 1.0928, val.acc = 0.5760\n",
      "Epoch 16, loss = 1.0826, val.acc = 0.5774\n",
      "Epoch 17, loss = 1.0730, val.acc = 0.5780\n",
      "Epoch 18, loss = 1.0639, val.acc = 0.5796\n",
      "Epoch 19, loss = 1.0552, val.acc = 0.5808\n",
      "Epoch 20, loss = 1.0469, val.acc = 0.5824\n",
      "Epoch 21, loss = 1.0390, val.acc = 0.5834\n",
      "Epoch 22, loss = 1.0314, val.acc = 0.5838\n",
      "Epoch 23, loss = 1.0241, val.acc = 0.5852\n",
      "Epoch 24, loss = 1.0171, val.acc = 0.5872\n",
      "Epoch 25, loss = 1.0103, val.acc = 0.5876\n",
      "Epoch 26, loss = 1.0037, val.acc = 0.5888\n",
      "Epoch 27, loss = 0.9974, val.acc = 0.5884\n",
      "Epoch 28, loss = 0.9913, val.acc = 0.5896\n",
      "Epoch 29, loss = 0.9853, val.acc = 0.5892\n",
      "Epoch 30, loss = 0.9796, val.acc = 0.5914\n",
      "Epoch 31, loss = 0.9740, val.acc = 0.5922\n",
      "Epoch 32, loss = 0.9685, val.acc = 0.5926\n",
      "Epoch 33, loss = 0.9633, val.acc = 0.5924\n",
      "Epoch 34, loss = 0.9581, val.acc = 0.5942\n",
      "Epoch 35, loss = 0.9532, val.acc = 0.5944\n",
      "Epoch 36, loss = 0.9482, val.acc = 0.5964\n",
      "Epoch 37, loss = 0.9435, val.acc = 0.5974\n",
      "Epoch 38, loss = 0.9388, val.acc = 0.5972\n",
      "Epoch 39, loss = 0.9343, val.acc = 0.5980\n",
      "Epoch 40, loss = 0.9299, val.acc = 0.5990\n",
      "Epoch 41, loss = 0.9256, val.acc = 0.5990\n",
      "Epoch 42, loss = 0.9214, val.acc = 0.5988\n",
      "Epoch 43, loss = 0.9173, val.acc = 0.5994\n",
      "Epoch 44, loss = 0.9134, val.acc = 0.5980\n",
      "Epoch 45, loss = 0.9096, val.acc = 0.5978\n",
      "Epoch 46, loss = 0.9059, val.acc = 0.5982\n",
      "Epoch 47, loss = 0.9024, val.acc = 0.5976\n",
      "Epoch 48, loss = 0.8991, val.acc = 0.5968\n",
      "Epoch 49, loss = 0.8961, val.acc = 0.5964\n",
      "Epoch 50, loss = 0.8934, val.acc = 0.5958\n",
      "Epoch 51, loss = 0.8911, val.acc = 0.5934\n",
      "Epoch 52, loss = 0.8895, val.acc = 0.5942\n",
      "Epoch 53, loss = 0.8891, val.acc = 0.5958\n",
      "Epoch 54, loss = 0.8899, val.acc = 0.6006\n",
      "Epoch 55, loss = 0.8882, val.acc = 0.6022\n",
      "Epoch 56, loss = 0.8819, val.acc = 0.6018\n",
      "Epoch 57, loss = 0.8756, val.acc = 0.6018\n",
      "Epoch 58, loss = 0.8706, val.acc = 0.6020\n",
      "Epoch 59, loss = 0.8662, val.acc = 0.6020\n",
      "Epoch 60, loss = 0.8622, val.acc = 0.6024\n",
      "Epoch 61, loss = 0.8586, val.acc = 0.6020\n",
      "Epoch 62, loss = 0.8551, val.acc = 0.6012\n",
      "Epoch 63, loss = 0.8519, val.acc = 0.6024\n",
      "Epoch 64, loss = 0.8486, val.acc = 0.6024\n",
      "Epoch 65, loss = 0.8456, val.acc = 0.6026\n",
      "Epoch 66, loss = 0.8428, val.acc = 0.6028\n",
      "Epoch 67, loss = 0.8399, val.acc = 0.6028\n",
      "Epoch 68, loss = 0.8372, val.acc = 0.6014\n",
      "Epoch 69, loss = 0.8346, val.acc = 0.6008\n",
      "Epoch 70, loss = 0.8320, val.acc = 0.6016\n",
      "Epoch 71, loss = 0.8295, val.acc = 0.6026\n",
      "Epoch 72, loss = 0.8270, val.acc = 0.6038\n",
      "Epoch 73, loss = 0.8246, val.acc = 0.6026\n",
      "Epoch 74, loss = 0.8223, val.acc = 0.6018\n",
      "Epoch 75, loss = 0.8199, val.acc = 0.6022\n",
      "Epoch 76, loss = 0.8177, val.acc = 0.6008\n",
      "Epoch 77, loss = 0.8156, val.acc = 0.6012\n",
      "Epoch 78, loss = 0.8134, val.acc = 0.6012\n",
      "Epoch 79, loss = 0.8114, val.acc = 0.6030\n",
      "Epoch 80, loss = 0.8094, val.acc = 0.6044\n",
      "Epoch 81, loss = 0.8073, val.acc = 0.6046\n",
      "Epoch 82, loss = 0.8049, val.acc = 0.6036\n",
      "Epoch 83, loss = 0.8023, val.acc = 0.6032\n",
      "Epoch 84, loss = 0.7996, val.acc = 0.6036\n",
      "Epoch 85, loss = 0.7967, val.acc = 0.6042\n",
      "Epoch 86, loss = 0.7938, val.acc = 0.6042\n",
      "Epoch 87, loss = 0.7910, val.acc = 0.6052\n",
      "Epoch 88, loss = 0.7882, val.acc = 0.6064\n",
      "Epoch 89, loss = 0.7854, val.acc = 0.6068\n",
      "Epoch 90, loss = 0.7826, val.acc = 0.6076\n",
      "Epoch 91, loss = 0.7799, val.acc = 0.6070\n",
      "Epoch 92, loss = 0.7772, val.acc = 0.6064\n",
      "Epoch 93, loss = 0.7746, val.acc = 0.6058\n",
      "Epoch 94, loss = 0.7720, val.acc = 0.6050\n",
      "Epoch 95, loss = 0.7695, val.acc = 0.6054\n",
      "Epoch 96, loss = 0.7670, val.acc = 0.6060\n",
      "Epoch 97, loss = 0.7645, val.acc = 0.6048\n",
      "Epoch 98, loss = 0.7621, val.acc = 0.6038\n",
      "Epoch 99, loss = 0.7597, val.acc = 0.6030\n",
      "Rep: 1, te.acc = 0.6018\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6018]\n"
     ]
    }
   ],
   "source": [
    "vis = visdom.Visdom(port=8097,env='lam_1')\n",
    "train_unsupervised_ae(pars,vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = PARS(device, datapath, savepath)\n",
    "pars.architecture = 'CONV6'\n",
    "pars.LR = 0.0001\n",
    "pars.clf_lr = 0.001\n",
    "pars.epochs = 300\n",
    "pars.clf_epochs = 100\n",
    "pars.nonlinear = 'hardtanh'\n",
    "pars.repeat = 1\n",
    "pars.lam = 0\n",
    "print(pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = visdom.Visdom(port=8097,env='lam_0')\n",
    "train_unsupervised_ae(pars,vis=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture: CONV6\n",
      "nonlinear: hardtanh\n",
      "batch_size: 500\n",
      "headsize: 64\n",
      "dataset: Cifar100\n",
      "loss: SimCLR\n",
      "OPT: Adam\n",
      "LR: 0.0001\n",
      "epochs: 300\n",
      "clf_dataset: Cifar10\n",
      "clf_loss: CE\n",
      "clf_opt: Adam\n",
      "clf_lr: 0.001\n",
      "clf_epochs: 100\n",
      "repeat: 1\n",
      "device: cuda:0\n",
      "datapath: data/\n",
      "savepath: save/\n",
      "loadnet: None\n",
      "loadclf: None\n",
      "lam: 0.5\n",
      "auxnonlinear: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pars = PARS(device, datapath, savepath)\n",
    "pars.architecture = 'CONV6'\n",
    "pars.LR = 0.0001\n",
    "pars.clf_lr = 0.001\n",
    "pars.epochs = 300\n",
    "pars.clf_epochs = 100\n",
    "pars.nonlinear = 'hardtanh'\n",
    "pars.repeat = 1\n",
    "pars.lam = 0.5\n",
    "print(pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save/CONV6/AE/\n",
      "hardtanh_Cifar100_Adam_LR_0.0001_Epochs_300_CLF_Cifar10_Adam_LR_0.001_Epochs_100_lam_0.5\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Rep 1\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxhead): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=8192, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(8, 32, 32))\n",
      "    (deconv): ConvTranspose2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Sequential()\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (layer0): Sequential(\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer1): Sequential(\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (auxhead): Sequential(\n",
      "      (0): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc): Linear(in_features=8192, out_features=64, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (auxdecoder): Sequential(\n",
      "    (fc): Linear(in_features=64, out_features=8192, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (unflatten): Unflatten(dim=1, unflattened_size=(8, 32, 32))\n",
      "    (deconv): ConvTranspose2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "MSELoss()\n",
      "TwinMSELoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 0.3043, time: 18.0409\n",
      "reconstruction loss = 0.0670, similarity loss: 0.5417\n",
      "Epoch 1, loss = 0.3214, time: 17.9409\n",
      "reconstruction loss = 0.0689, similarity loss: 0.5740\n",
      "Epoch 2, loss = 0.2887, time: 17.8862\n",
      "reconstruction loss = 0.0681, similarity loss: 0.5092\n",
      "Epoch 3, loss = 0.2055, time: 17.8758\n",
      "reconstruction loss = 0.0674, similarity loss: 0.3436\n",
      "Epoch 4, loss = 0.2393, time: 17.8589\n",
      "reconstruction loss = 0.0623, similarity loss: 0.4163\n",
      "Epoch 5, loss = 0.2154, time: 18.1332\n",
      "reconstruction loss = 0.0673, similarity loss: 0.3636\n",
      "Epoch 6, loss = 0.2026, time: 17.9210\n",
      "reconstruction loss = 0.0632, similarity loss: 0.3421\n",
      "Epoch 7, loss = 0.1853, time: 17.6460\n",
      "reconstruction loss = 0.0680, similarity loss: 0.3026\n",
      "Epoch 8, loss = 0.1816, time: 17.9004\n",
      "reconstruction loss = 0.0662, similarity loss: 0.2969\n",
      "Epoch 9, loss = 0.1901, time: 18.1267\n",
      "reconstruction loss = 0.0622, similarity loss: 0.3180\n",
      "Epoch 10, loss = 0.2029, time: 17.5112\n",
      "reconstruction loss = 0.0646, similarity loss: 0.3411\n",
      "Epoch 11, loss = 0.1861, time: 17.5526\n",
      "reconstruction loss = 0.0631, similarity loss: 0.3091\n",
      "Epoch 12, loss = 0.1740, time: 17.9162\n",
      "reconstruction loss = 0.0660, similarity loss: 0.2820\n",
      "Epoch 13, loss = 0.1758, time: 17.8910\n",
      "reconstruction loss = 0.0624, similarity loss: 0.2893\n",
      "Epoch 14, loss = 0.1637, time: 17.6519\n",
      "reconstruction loss = 0.0626, similarity loss: 0.2647\n",
      "Epoch 15, loss = 0.2015, time: 17.5547\n",
      "reconstruction loss = 0.0669, similarity loss: 0.3360\n",
      "Epoch 16, loss = 0.1724, time: 17.4001\n",
      "reconstruction loss = 0.0671, similarity loss: 0.2777\n",
      "Epoch 17, loss = 0.1912, time: 18.0589\n",
      "reconstruction loss = 0.0657, similarity loss: 0.3167\n",
      "Epoch 18, loss = 0.1668, time: 18.4145\n",
      "reconstruction loss = 0.0635, similarity loss: 0.2700\n",
      "Epoch 19, loss = 0.1736, time: 18.0900\n",
      "reconstruction loss = 0.0639, similarity loss: 0.2832\n",
      "Epoch 20, loss = 0.1599, time: 17.8354\n",
      "reconstruction loss = 0.0639, similarity loss: 0.2559\n",
      "Epoch 21, loss = 0.1728, time: 17.5767\n",
      "reconstruction loss = 0.0664, similarity loss: 0.2792\n",
      "Epoch 22, loss = 0.1782, time: 17.2975\n",
      "reconstruction loss = 0.0632, similarity loss: 0.2931\n",
      "Epoch 23, loss = 0.1579, time: 17.8099\n",
      "reconstruction loss = 0.0661, similarity loss: 0.2498\n",
      "Epoch 24, loss = 0.1586, time: 17.7425\n",
      "reconstruction loss = 0.0659, similarity loss: 0.2514\n",
      "Epoch 25, loss = 0.1673, time: 17.9854\n",
      "reconstruction loss = 0.0635, similarity loss: 0.2712\n",
      "Epoch 26, loss = 0.1675, time: 17.9464\n",
      "reconstruction loss = 0.0630, similarity loss: 0.2719\n",
      "Epoch 27, loss = 0.1707, time: 17.7463\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2761\n",
      "Epoch 28, loss = 0.1773, time: 17.7326\n",
      "reconstruction loss = 0.0666, similarity loss: 0.2880\n",
      "Epoch 29, loss = 0.1813, time: 17.8714\n",
      "reconstruction loss = 0.0638, similarity loss: 0.2987\n",
      "Epoch 30, loss = 0.1635, time: 17.8557\n",
      "reconstruction loss = 0.0646, similarity loss: 0.2624\n",
      "Epoch 31, loss = 0.1806, time: 18.0424\n",
      "reconstruction loss = 0.0693, similarity loss: 0.2919\n",
      "Epoch 32, loss = 0.1669, time: 17.7871\n",
      "reconstruction loss = 0.0658, similarity loss: 0.2680\n",
      "Epoch 33, loss = 0.1686, time: 17.9204\n",
      "reconstruction loss = 0.0657, similarity loss: 0.2716\n",
      "Epoch 34, loss = 0.1554, time: 17.8050\n",
      "reconstruction loss = 0.0640, similarity loss: 0.2467\n",
      "Epoch 35, loss = 0.1671, time: 17.8651\n",
      "reconstruction loss = 0.0645, similarity loss: 0.2698\n",
      "Epoch 36, loss = 0.1851, time: 17.8204\n",
      "reconstruction loss = 0.0666, similarity loss: 0.3036\n",
      "Epoch 37, loss = 0.1635, time: 17.8099\n",
      "reconstruction loss = 0.0627, similarity loss: 0.2643\n",
      "Epoch 38, loss = 0.1528, time: 17.8500\n",
      "reconstruction loss = 0.0662, similarity loss: 0.2395\n",
      "Epoch 39, loss = 0.1712, time: 18.2733\n",
      "reconstruction loss = 0.0651, similarity loss: 0.2774\n",
      "Epoch 40, loss = 0.1648, time: 19.1021\n",
      "reconstruction loss = 0.0649, similarity loss: 0.2647\n",
      "Epoch 41, loss = 0.1553, time: 18.5165\n",
      "reconstruction loss = 0.0649, similarity loss: 0.2458\n",
      "Epoch 42, loss = 0.1557, time: 18.5575\n",
      "reconstruction loss = 0.0605, similarity loss: 0.2509\n",
      "Epoch 43, loss = 0.1682, time: 18.6569\n",
      "reconstruction loss = 0.0676, similarity loss: 0.2688\n",
      "Epoch 44, loss = 0.1530, time: 18.5321\n",
      "reconstruction loss = 0.0673, similarity loss: 0.2387\n",
      "Epoch 45, loss = 0.1648, time: 18.5821\n",
      "reconstruction loss = 0.0668, similarity loss: 0.2628\n",
      "Epoch 46, loss = 0.1604, time: 18.5112\n",
      "reconstruction loss = 0.0640, similarity loss: 0.2568\n",
      "Epoch 47, loss = 0.1467, time: 18.6865\n",
      "reconstruction loss = 0.0678, similarity loss: 0.2255\n",
      "Epoch 48, loss = 0.1654, time: 18.5537\n",
      "reconstruction loss = 0.0642, similarity loss: 0.2666\n",
      "Epoch 49, loss = 0.1470, time: 18.6887\n",
      "reconstruction loss = 0.0668, similarity loss: 0.2272\n",
      "Epoch 50, loss = 0.1709, time: 18.7319\n",
      "reconstruction loss = 0.0647, similarity loss: 0.2771\n",
      "Epoch 51, loss = 0.1699, time: 18.5816\n",
      "reconstruction loss = 0.0619, similarity loss: 0.2779\n",
      "Epoch 52, loss = 0.1459, time: 18.4754\n",
      "reconstruction loss = 0.0609, similarity loss: 0.2309\n",
      "Epoch 53, loss = 0.1725, time: 18.6069\n",
      "reconstruction loss = 0.0662, similarity loss: 0.2788\n",
      "Epoch 54, loss = 0.1850, time: 18.5518\n",
      "reconstruction loss = 0.0674, similarity loss: 0.3026\n",
      "Epoch 55, loss = 0.1650, time: 18.5178\n",
      "reconstruction loss = 0.0650, similarity loss: 0.2649\n",
      "Epoch 56, loss = 0.1503, time: 18.4975\n",
      "reconstruction loss = 0.0636, similarity loss: 0.2371\n",
      "Epoch 57, loss = 0.1680, time: 18.4130\n",
      "reconstruction loss = 0.0649, similarity loss: 0.2710\n",
      "Epoch 58, loss = 0.1580, time: 18.4857\n",
      "reconstruction loss = 0.0647, similarity loss: 0.2512\n",
      "Epoch 59, loss = 0.1472, time: 18.8335\n",
      "reconstruction loss = 0.0625, similarity loss: 0.2318\n",
      "Epoch 60, loss = 0.1644, time: 18.5247\n",
      "reconstruction loss = 0.0604, similarity loss: 0.2685\n",
      "Epoch 61, loss = 0.1545, time: 18.5247\n",
      "reconstruction loss = 0.0654, similarity loss: 0.2435\n",
      "Epoch 62, loss = 0.1570, time: 18.5014\n",
      "reconstruction loss = 0.0636, similarity loss: 0.2503\n",
      "Epoch 63, loss = 0.1537, time: 18.4989\n",
      "reconstruction loss = 0.0635, similarity loss: 0.2439\n",
      "Epoch 64, loss = 0.1529, time: 18.5104\n",
      "reconstruction loss = 0.0658, similarity loss: 0.2401\n",
      "Epoch 65, loss = 0.1599, time: 18.6581\n",
      "reconstruction loss = 0.0648, similarity loss: 0.2549\n",
      "Epoch 66, loss = 0.1649, time: 18.5657\n",
      "reconstruction loss = 0.0612, similarity loss: 0.2687\n",
      "Epoch 67, loss = 0.1475, time: 18.6362\n",
      "reconstruction loss = 0.0622, similarity loss: 0.2329\n",
      "Epoch 68, loss = 0.1451, time: 18.5407\n",
      "reconstruction loss = 0.0641, similarity loss: 0.2261\n",
      "Epoch 69, loss = 0.1494, time: 18.7517\n",
      "reconstruction loss = 0.0645, similarity loss: 0.2343\n",
      "Epoch 70, loss = 0.1465, time: 18.6944\n",
      "reconstruction loss = 0.0661, similarity loss: 0.2269\n",
      "Epoch 71, loss = 0.1407, time: 18.2852\n",
      "reconstruction loss = 0.0646, similarity loss: 0.2168\n",
      "Epoch 72, loss = 0.1629, time: 17.8867\n",
      "reconstruction loss = 0.0656, similarity loss: 0.2602\n",
      "Epoch 73, loss = 0.1507, time: 17.7452\n",
      "reconstruction loss = 0.0647, similarity loss: 0.2367\n",
      "Epoch 74, loss = 0.1557, time: 17.6248\n",
      "reconstruction loss = 0.0678, similarity loss: 0.2437\n",
      "Epoch 75, loss = 0.1591, time: 16.7219\n",
      "reconstruction loss = 0.0633, similarity loss: 0.2548\n",
      "Epoch 76, loss = 0.1616, time: 16.8459\n",
      "reconstruction loss = 0.0643, similarity loss: 0.2589\n",
      "Epoch 77, loss = 0.1576, time: 16.8984\n",
      "reconstruction loss = 0.0637, similarity loss: 0.2514\n",
      "Epoch 78, loss = 0.1554, time: 16.7747\n",
      "reconstruction loss = 0.0634, similarity loss: 0.2475\n",
      "Epoch 79, loss = 0.1642, time: 16.7941\n",
      "reconstruction loss = 0.0667, similarity loss: 0.2618\n",
      "Epoch 80, loss = 0.1463, time: 16.6281\n",
      "reconstruction loss = 0.0667, similarity loss: 0.2259\n",
      "Epoch 81, loss = 0.1465, time: 16.6851\n",
      "reconstruction loss = 0.0667, similarity loss: 0.2263\n",
      "Epoch 82, loss = 0.1356, time: 16.6915\n",
      "reconstruction loss = 0.0638, similarity loss: 0.2074\n",
      "Epoch 83, loss = 0.1493, time: 16.7459\n",
      "reconstruction loss = 0.0632, similarity loss: 0.2354\n",
      "Epoch 84, loss = 0.1620, time: 16.7636\n",
      "reconstruction loss = 0.0648, similarity loss: 0.2592\n",
      "Epoch 85, loss = 0.1548, time: 16.8145\n",
      "reconstruction loss = 0.0650, similarity loss: 0.2445\n",
      "Epoch 86, loss = 0.1435, time: 16.7006\n",
      "reconstruction loss = 0.0625, similarity loss: 0.2245\n",
      "Epoch 87, loss = 0.1316, time: 16.7213\n",
      "reconstruction loss = 0.0655, similarity loss: 0.1977\n",
      "Epoch 88, loss = 0.1655, time: 16.6741\n",
      "reconstruction loss = 0.0626, similarity loss: 0.2683\n",
      "Epoch 89, loss = 0.1471, time: 16.7613\n",
      "reconstruction loss = 0.0663, similarity loss: 0.2278\n",
      "Epoch 90, loss = 0.1689, time: 16.9289\n",
      "reconstruction loss = 0.0664, similarity loss: 0.2714\n",
      "Epoch 91, loss = 0.1630, time: 16.8535\n",
      "reconstruction loss = 0.0646, similarity loss: 0.2613\n",
      "Epoch 92, loss = 0.1484, time: 16.6902\n",
      "reconstruction loss = 0.0663, similarity loss: 0.2304\n",
      "Epoch 93, loss = 0.1511, time: 16.5916\n",
      "reconstruction loss = 0.0650, similarity loss: 0.2372\n",
      "Epoch 94, loss = 0.1541, time: 16.7681\n",
      "reconstruction loss = 0.0654, similarity loss: 0.2427\n",
      "Epoch 95, loss = 0.1704, time: 16.8890\n",
      "reconstruction loss = 0.0650, similarity loss: 0.2757\n",
      "Epoch 96, loss = 0.1578, time: 16.8011\n",
      "reconstruction loss = 0.0675, similarity loss: 0.2480\n",
      "Epoch 97, loss = 0.1487, time: 16.8332\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2320\n",
      "Epoch 98, loss = 0.1502, time: 16.8357\n",
      "reconstruction loss = 0.0657, similarity loss: 0.2348\n",
      "Epoch 99, loss = 0.1540, time: 16.7330\n",
      "reconstruction loss = 0.0656, similarity loss: 0.2424\n",
      "Epoch 100, loss = 0.1503, time: 16.8327\n",
      "reconstruction loss = 0.0656, similarity loss: 0.2350\n",
      "Epoch 101, loss = 0.1597, time: 16.9134\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2540\n",
      "Epoch 102, loss = 0.1515, time: 16.8264\n",
      "reconstruction loss = 0.0613, similarity loss: 0.2418\n",
      "Epoch 103, loss = 0.1419, time: 16.8044\n",
      "reconstruction loss = 0.0661, similarity loss: 0.2177\n",
      "Epoch 104, loss = 0.1587, time: 17.0146\n",
      "reconstruction loss = 0.0643, similarity loss: 0.2531\n",
      "Epoch 105, loss = 0.1607, time: 17.2771\n",
      "reconstruction loss = 0.0655, similarity loss: 0.2560\n",
      "Epoch 106, loss = 0.1466, time: 17.3318\n",
      "reconstruction loss = 0.0626, similarity loss: 0.2307\n",
      "Epoch 107, loss = 0.1439, time: 17.3041\n",
      "reconstruction loss = 0.0636, similarity loss: 0.2242\n",
      "Epoch 108, loss = 0.1422, time: 17.3937\n",
      "reconstruction loss = 0.0651, similarity loss: 0.2192\n",
      "Epoch 109, loss = 0.1647, time: 17.4020\n",
      "reconstruction loss = 0.0642, similarity loss: 0.2652\n",
      "Epoch 110, loss = 0.1490, time: 17.4635\n",
      "reconstruction loss = 0.0617, similarity loss: 0.2363\n",
      "Epoch 111, loss = 0.1547, time: 17.4243\n",
      "reconstruction loss = 0.0622, similarity loss: 0.2472\n",
      "Epoch 112, loss = 0.1344, time: 17.4291\n",
      "reconstruction loss = 0.0659, similarity loss: 0.2028\n",
      "Epoch 113, loss = 0.1661, time: 17.3964\n",
      "reconstruction loss = 0.0667, similarity loss: 0.2656\n",
      "Epoch 114, loss = 0.1467, time: 17.2635\n",
      "reconstruction loss = 0.0636, similarity loss: 0.2299\n",
      "Epoch 115, loss = 0.1536, time: 17.3180\n",
      "reconstruction loss = 0.0657, similarity loss: 0.2414\n",
      "Epoch 116, loss = 0.1178, time: 17.2587\n",
      "reconstruction loss = 0.0625, similarity loss: 0.1731\n",
      "Epoch 117, loss = 0.1565, time: 17.2883\n",
      "reconstruction loss = 0.0642, similarity loss: 0.2487\n",
      "Epoch 118, loss = 0.1401, time: 17.2881\n",
      "reconstruction loss = 0.0654, similarity loss: 0.2147\n",
      "Epoch 119, loss = 0.1407, time: 17.2788\n",
      "reconstruction loss = 0.0606, similarity loss: 0.2208\n",
      "Epoch 120, loss = 0.1435, time: 17.3168\n",
      "reconstruction loss = 0.0642, similarity loss: 0.2229\n",
      "Epoch 121, loss = 0.1629, time: 17.3311\n",
      "reconstruction loss = 0.0610, similarity loss: 0.2648\n",
      "Epoch 122, loss = 0.1510, time: 17.4101\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2368\n",
      "Epoch 123, loss = 0.1368, time: 17.3045\n",
      "reconstruction loss = 0.0645, similarity loss: 0.2091\n",
      "Epoch 124, loss = 0.1540, time: 17.3434\n",
      "reconstruction loss = 0.0663, similarity loss: 0.2417\n",
      "Epoch 125, loss = 0.1487, time: 17.4142\n",
      "reconstruction loss = 0.0657, similarity loss: 0.2317\n",
      "Epoch 126, loss = 0.1460, time: 17.3268\n",
      "reconstruction loss = 0.0647, similarity loss: 0.2274\n",
      "Epoch 127, loss = 0.1542, time: 17.2937\n",
      "reconstruction loss = 0.0649, similarity loss: 0.2434\n",
      "Epoch 128, loss = 0.1476, time: 17.3279\n",
      "reconstruction loss = 0.0628, similarity loss: 0.2324\n",
      "Epoch 129, loss = 0.1420, time: 17.2722\n",
      "reconstruction loss = 0.0638, similarity loss: 0.2202\n",
      "Epoch 130, loss = 0.1462, time: 17.3220\n",
      "reconstruction loss = 0.0644, similarity loss: 0.2279\n",
      "Epoch 131, loss = 0.1505, time: 17.4027\n",
      "reconstruction loss = 0.0638, similarity loss: 0.2371\n",
      "Epoch 132, loss = 0.1340, time: 17.4304\n",
      "reconstruction loss = 0.0651, similarity loss: 0.2030\n",
      "Epoch 133, loss = 0.1498, time: 17.3823\n",
      "reconstruction loss = 0.0674, similarity loss: 0.2322\n",
      "Epoch 134, loss = 0.1531, time: 17.4707\n",
      "reconstruction loss = 0.0644, similarity loss: 0.2417\n",
      "Epoch 135, loss = 0.1532, time: 17.4177\n",
      "reconstruction loss = 0.0655, similarity loss: 0.2408\n",
      "Epoch 136, loss = 0.1475, time: 17.3313\n",
      "reconstruction loss = 0.0643, similarity loss: 0.2307\n",
      "Epoch 137, loss = 0.1502, time: 17.2553\n",
      "reconstruction loss = 0.0635, similarity loss: 0.2369\n",
      "Epoch 138, loss = 0.1517, time: 17.3560\n",
      "reconstruction loss = 0.0660, similarity loss: 0.2375\n",
      "Epoch 139, loss = 0.1429, time: 16.7864\n",
      "reconstruction loss = 0.0652, similarity loss: 0.2207\n",
      "Epoch 140, loss = 0.1602, time: 16.7107\n",
      "reconstruction loss = 0.0662, similarity loss: 0.2542\n",
      "Epoch 141, loss = 0.1430, time: 16.6438\n",
      "reconstruction loss = 0.0613, similarity loss: 0.2247\n",
      "Epoch 142, loss = 0.1561, time: 16.7502\n",
      "reconstruction loss = 0.0644, similarity loss: 0.2478\n",
      "Epoch 143, loss = 0.1442, time: 16.8981\n",
      "reconstruction loss = 0.0698, similarity loss: 0.2185\n",
      "Epoch 144, loss = 0.1502, time: 16.7099\n",
      "reconstruction loss = 0.0655, similarity loss: 0.2349\n",
      "Epoch 145, loss = 0.1721, time: 16.5764\n",
      "reconstruction loss = 0.0662, similarity loss: 0.2780\n",
      "Epoch 146, loss = 0.1344, time: 16.7812\n",
      "reconstruction loss = 0.0618, similarity loss: 0.2070\n",
      "Epoch 147, loss = 0.1417, time: 16.6261\n",
      "reconstruction loss = 0.0662, similarity loss: 0.2171\n",
      "Epoch 148, loss = 0.1624, time: 16.5956\n",
      "reconstruction loss = 0.0635, similarity loss: 0.2613\n",
      "Epoch 149, loss = 0.1393, time: 16.6694\n",
      "reconstruction loss = 0.0625, similarity loss: 0.2161\n",
      "Epoch 150, loss = 0.1536, time: 16.7833\n",
      "reconstruction loss = 0.0624, similarity loss: 0.2448\n",
      "Epoch 151, loss = 0.1397, time: 16.7802\n",
      "reconstruction loss = 0.0652, similarity loss: 0.2141\n",
      "Epoch 152, loss = 0.1452, time: 16.8070\n",
      "reconstruction loss = 0.0655, similarity loss: 0.2250\n",
      "Epoch 153, loss = 0.1502, time: 16.7372\n",
      "reconstruction loss = 0.0655, similarity loss: 0.2350\n",
      "Epoch 154, loss = 0.1512, time: 16.8623\n",
      "reconstruction loss = 0.0663, similarity loss: 0.2361\n",
      "Epoch 155, loss = 0.1629, time: 16.7056\n",
      "reconstruction loss = 0.0653, similarity loss: 0.2605\n",
      "Epoch 156, loss = 0.1487, time: 16.6711\n",
      "reconstruction loss = 0.0614, similarity loss: 0.2359\n",
      "Epoch 157, loss = 0.1574, time: 17.2796\n",
      "reconstruction loss = 0.0643, similarity loss: 0.2505\n",
      "Epoch 158, loss = 0.1481, time: 17.3724\n",
      "reconstruction loss = 0.0664, similarity loss: 0.2298\n",
      "Epoch 159, loss = 0.1314, time: 17.3193\n",
      "reconstruction loss = 0.0636, similarity loss: 0.1992\n",
      "Epoch 160, loss = 0.1432, time: 17.3572\n",
      "reconstruction loss = 0.0628, similarity loss: 0.2235\n",
      "Epoch 161, loss = 0.1490, time: 17.3242\n",
      "reconstruction loss = 0.0641, similarity loss: 0.2340\n",
      "Epoch 162, loss = 0.1534, time: 17.4394\n",
      "reconstruction loss = 0.0681, similarity loss: 0.2388\n",
      "Epoch 163, loss = 0.1409, time: 17.3579\n",
      "reconstruction loss = 0.0625, similarity loss: 0.2193\n",
      "Epoch 164, loss = 0.1470, time: 17.4579\n",
      "reconstruction loss = 0.0658, similarity loss: 0.2281\n",
      "Epoch 165, loss = 0.1484, time: 17.3173\n",
      "reconstruction loss = 0.0656, similarity loss: 0.2312\n",
      "Epoch 166, loss = 0.1422, time: 17.3130\n",
      "reconstruction loss = 0.0632, similarity loss: 0.2212\n",
      "Epoch 167, loss = 0.1510, time: 17.1987\n",
      "reconstruction loss = 0.0632, similarity loss: 0.2388\n",
      "Epoch 168, loss = 0.1363, time: 17.3696\n",
      "reconstruction loss = 0.0656, similarity loss: 0.2070\n",
      "Epoch 169, loss = 0.1481, time: 17.2856\n",
      "reconstruction loss = 0.0656, similarity loss: 0.2306\n",
      "Epoch 170, loss = 0.1390, time: 17.2737\n",
      "reconstruction loss = 0.0651, similarity loss: 0.2129\n",
      "Epoch 171, loss = 0.1455, time: 17.3462\n",
      "reconstruction loss = 0.0641, similarity loss: 0.2269\n",
      "Epoch 172, loss = 0.1412, time: 17.3415\n",
      "reconstruction loss = 0.0641, similarity loss: 0.2182\n",
      "Epoch 173, loss = 0.1365, time: 17.3961\n",
      "reconstruction loss = 0.0604, similarity loss: 0.2125\n",
      "Epoch 174, loss = 0.1555, time: 17.3226\n",
      "reconstruction loss = 0.0665, similarity loss: 0.2446\n",
      "Epoch 175, loss = 0.1346, time: 17.4343\n",
      "reconstruction loss = 0.0665, similarity loss: 0.2027\n",
      "Epoch 176, loss = 0.1419, time: 17.3467\n",
      "reconstruction loss = 0.0598, similarity loss: 0.2240\n",
      "Epoch 177, loss = 0.1433, time: 17.3277\n",
      "reconstruction loss = 0.0632, similarity loss: 0.2234\n",
      "Epoch 178, loss = 0.1426, time: 17.3736\n",
      "reconstruction loss = 0.0662, similarity loss: 0.2190\n",
      "Epoch 179, loss = 0.1470, time: 17.2219\n",
      "reconstruction loss = 0.0648, similarity loss: 0.2291\n",
      "Epoch 180, loss = 0.1563, time: 17.3626\n",
      "reconstruction loss = 0.0661, similarity loss: 0.2464\n",
      "Epoch 181, loss = 0.1222, time: 17.4967\n",
      "reconstruction loss = 0.0650, similarity loss: 0.1795\n",
      "Epoch 182, loss = 0.1380, time: 17.3469\n",
      "reconstruction loss = 0.0630, similarity loss: 0.2130\n",
      "Epoch 183, loss = 0.1590, time: 17.2737\n",
      "reconstruction loss = 0.0636, similarity loss: 0.2543\n",
      "Epoch 184, loss = 0.1436, time: 17.2923\n",
      "reconstruction loss = 0.0680, similarity loss: 0.2191\n",
      "Epoch 185, loss = 0.1315, time: 17.4082\n",
      "reconstruction loss = 0.0610, similarity loss: 0.2020\n",
      "Epoch 186, loss = 0.1606, time: 17.5110\n",
      "reconstruction loss = 0.0623, similarity loss: 0.2590\n",
      "Epoch 187, loss = 0.1520, time: 17.3800\n",
      "reconstruction loss = 0.0638, similarity loss: 0.2401\n",
      "Epoch 188, loss = 0.1384, time: 17.3563\n",
      "reconstruction loss = 0.0635, similarity loss: 0.2134\n",
      "Epoch 189, loss = 0.1462, time: 17.3462\n",
      "reconstruction loss = 0.0635, similarity loss: 0.2289\n",
      "Epoch 190, loss = 0.1576, time: 17.5177\n",
      "reconstruction loss = 0.0639, similarity loss: 0.2514\n",
      "Epoch 191, loss = 0.1356, time: 17.3278\n",
      "reconstruction loss = 0.0654, similarity loss: 0.2058\n",
      "Epoch 192, loss = 0.1394, time: 17.3788\n",
      "reconstruction loss = 0.0648, similarity loss: 0.2141\n",
      "Epoch 193, loss = 0.1351, time: 17.3537\n",
      "reconstruction loss = 0.0618, similarity loss: 0.2083\n",
      "Epoch 194, loss = 0.1533, time: 17.3055\n",
      "reconstruction loss = 0.0652, similarity loss: 0.2414\n",
      "Epoch 195, loss = 0.1435, time: 17.5231\n",
      "reconstruction loss = 0.0643, similarity loss: 0.2226\n",
      "Epoch 196, loss = 0.1493, time: 17.4224\n",
      "reconstruction loss = 0.0638, similarity loss: 0.2347\n",
      "Epoch 197, loss = 0.1517, time: 17.3259\n",
      "reconstruction loss = 0.0643, similarity loss: 0.2391\n",
      "Epoch 198, loss = 0.1441, time: 17.3852\n",
      "reconstruction loss = 0.0623, similarity loss: 0.2258\n",
      "Epoch 199, loss = 0.1442, time: 17.2553\n",
      "reconstruction loss = 0.0637, similarity loss: 0.2246\n",
      "Epoch 200, loss = 0.1465, time: 17.4093\n",
      "reconstruction loss = 0.0606, similarity loss: 0.2324\n",
      "Epoch 201, loss = 0.1367, time: 17.4115\n",
      "reconstruction loss = 0.0624, similarity loss: 0.2110\n",
      "Epoch 202, loss = 0.1455, time: 17.2273\n",
      "reconstruction loss = 0.0620, similarity loss: 0.2289\n",
      "Epoch 203, loss = 0.1370, time: 17.2726\n",
      "reconstruction loss = 0.0626, similarity loss: 0.2115\n",
      "Epoch 204, loss = 0.1308, time: 17.3680\n",
      "reconstruction loss = 0.0614, similarity loss: 0.2001\n",
      "Epoch 205, loss = 0.1411, time: 17.2984\n",
      "reconstruction loss = 0.0600, similarity loss: 0.2223\n",
      "Epoch 206, loss = 0.1468, time: 17.3885\n",
      "reconstruction loss = 0.0624, similarity loss: 0.2311\n",
      "Epoch 207, loss = 0.1359, time: 17.3299\n",
      "reconstruction loss = 0.0629, similarity loss: 0.2090\n",
      "Epoch 208, loss = 0.1471, time: 17.2814\n",
      "reconstruction loss = 0.0618, similarity loss: 0.2325\n",
      "Epoch 209, loss = 0.1543, time: 16.9819\n",
      "reconstruction loss = 0.0609, similarity loss: 0.2477\n",
      "Epoch 210, loss = 0.1248, time: 16.7422\n",
      "reconstruction loss = 0.0597, similarity loss: 0.1898\n",
      "Epoch 211, loss = 0.1332, time: 16.6708\n",
      "reconstruction loss = 0.0600, similarity loss: 0.2064\n",
      "Epoch 212, loss = 0.1441, time: 16.9051\n",
      "reconstruction loss = 0.0566, similarity loss: 0.2316\n",
      "Epoch 213, loss = 0.1282, time: 16.7174\n",
      "reconstruction loss = 0.0519, similarity loss: 0.2044\n",
      "Epoch 214, loss = 0.1460, time: 16.7375\n",
      "reconstruction loss = 0.0487, similarity loss: 0.2433\n",
      "Epoch 215, loss = 0.1403, time: 16.7546\n",
      "reconstruction loss = 0.0468, similarity loss: 0.2339\n",
      "Epoch 216, loss = 0.1549, time: 16.8544\n",
      "reconstruction loss = 0.0436, similarity loss: 0.2663\n",
      "Epoch 217, loss = 0.1374, time: 16.9349\n",
      "reconstruction loss = 0.0432, similarity loss: 0.2316\n",
      "Epoch 218, loss = 0.1285, time: 16.6892\n",
      "reconstruction loss = 0.0415, similarity loss: 0.2155\n",
      "Epoch 219, loss = 0.1263, time: 16.7653\n",
      "reconstruction loss = 0.0425, similarity loss: 0.2102\n",
      "Epoch 220, loss = 0.1315, time: 16.6694\n",
      "reconstruction loss = 0.0421, similarity loss: 0.2209\n",
      "Epoch 221, loss = 0.1371, time: 16.7968\n",
      "reconstruction loss = 0.0402, similarity loss: 0.2341\n",
      "Epoch 222, loss = 0.1294, time: 16.8161\n",
      "reconstruction loss = 0.0398, similarity loss: 0.2191\n",
      "Epoch 223, loss = 0.1226, time: 16.7345\n",
      "reconstruction loss = 0.0391, similarity loss: 0.2060\n",
      "Epoch 224, loss = 0.1395, time: 16.7133\n",
      "reconstruction loss = 0.0392, similarity loss: 0.2398\n",
      "Epoch 225, loss = 0.1379, time: 16.7591\n",
      "reconstruction loss = 0.0367, similarity loss: 0.2390\n",
      "Epoch 226, loss = 0.1347, time: 16.6370\n",
      "reconstruction loss = 0.0405, similarity loss: 0.2290\n",
      "Epoch 227, loss = 0.1340, time: 16.7557\n",
      "reconstruction loss = 0.0381, similarity loss: 0.2299\n",
      "Epoch 228, loss = 0.1251, time: 16.9508\n",
      "reconstruction loss = 0.0376, similarity loss: 0.2126\n",
      "Epoch 229, loss = 0.1543, time: 16.6074\n",
      "reconstruction loss = 0.0384, similarity loss: 0.2703\n",
      "Epoch 230, loss = 0.1397, time: 16.6768\n",
      "reconstruction loss = 0.0376, similarity loss: 0.2417\n",
      "Epoch 231, loss = 0.1307, time: 16.6498\n",
      "reconstruction loss = 0.0388, similarity loss: 0.2225\n",
      "Epoch 232, loss = 0.1285, time: 16.7389\n",
      "reconstruction loss = 0.0404, similarity loss: 0.2165\n",
      "Epoch 233, loss = 0.1337, time: 16.7155\n",
      "reconstruction loss = 0.0390, similarity loss: 0.2284\n",
      "Epoch 234, loss = 0.1481, time: 16.8068\n",
      "reconstruction loss = 0.0385, similarity loss: 0.2577\n",
      "Epoch 235, loss = 0.1408, time: 16.6225\n",
      "reconstruction loss = 0.0404, similarity loss: 0.2412\n",
      "Epoch 236, loss = 0.1426, time: 16.6402\n",
      "reconstruction loss = 0.0391, similarity loss: 0.2462\n",
      "Epoch 237, loss = 0.1321, time: 16.8537\n",
      "reconstruction loss = 0.0377, similarity loss: 0.2265\n",
      "Epoch 238, loss = 0.1360, time: 16.7309\n",
      "reconstruction loss = 0.0402, similarity loss: 0.2318\n",
      "Epoch 239, loss = 0.1239, time: 16.7639\n",
      "reconstruction loss = 0.0372, similarity loss: 0.2106\n",
      "Epoch 240, loss = 0.1356, time: 16.6999\n",
      "reconstruction loss = 0.0396, similarity loss: 0.2316\n",
      "Epoch 241, loss = 0.1317, time: 16.7100\n",
      "reconstruction loss = 0.0374, similarity loss: 0.2259\n",
      "Epoch 242, loss = 0.1302, time: 16.7078\n",
      "reconstruction loss = 0.0397, similarity loss: 0.2207\n",
      "Epoch 243, loss = 0.1323, time: 16.6959\n",
      "reconstruction loss = 0.0400, similarity loss: 0.2245\n",
      "Epoch 244, loss = 0.1479, time: 16.7897\n",
      "reconstruction loss = 0.0395, similarity loss: 0.2563\n",
      "Epoch 245, loss = 0.1498, time: 16.6759\n",
      "reconstruction loss = 0.0373, similarity loss: 0.2624\n",
      "Epoch 246, loss = 0.1478, time: 16.6860\n",
      "reconstruction loss = 0.0405, similarity loss: 0.2552\n",
      "Epoch 247, loss = 0.1461, time: 16.8192\n",
      "reconstruction loss = 0.0377, similarity loss: 0.2545\n",
      "Epoch 248, loss = 0.1170, time: 16.7528\n",
      "reconstruction loss = 0.0393, similarity loss: 0.1947\n",
      "Epoch 249, loss = 0.1274, time: 16.8855\n",
      "reconstruction loss = 0.0375, similarity loss: 0.2174\n",
      "Epoch 250, loss = 0.1336, time: 16.8802\n",
      "reconstruction loss = 0.0372, similarity loss: 0.2300\n",
      "Epoch 251, loss = 0.1348, time: 16.6202\n",
      "reconstruction loss = 0.0384, similarity loss: 0.2312\n",
      "Epoch 252, loss = 0.1219, time: 16.8050\n",
      "reconstruction loss = 0.0413, similarity loss: 0.2024\n",
      "Epoch 253, loss = 0.1304, time: 16.8031\n",
      "reconstruction loss = 0.0369, similarity loss: 0.2238\n",
      "Epoch 254, loss = 0.1448, time: 16.7785\n",
      "reconstruction loss = 0.0371, similarity loss: 0.2524\n",
      "Epoch 255, loss = 0.1310, time: 16.9106\n",
      "reconstruction loss = 0.0375, similarity loss: 0.2246\n",
      "Epoch 256, loss = 0.1367, time: 16.8272\n",
      "reconstruction loss = 0.0372, similarity loss: 0.2363\n",
      "Epoch 257, loss = 0.1529, time: 16.5968\n",
      "reconstruction loss = 0.0386, similarity loss: 0.2672\n",
      "Epoch 258, loss = 0.1256, time: 16.6253\n",
      "reconstruction loss = 0.0366, similarity loss: 0.2147\n",
      "Epoch 259, loss = 0.1252, time: 16.8096\n",
      "reconstruction loss = 0.0364, similarity loss: 0.2140\n",
      "Epoch 260, loss = 0.1312, time: 16.9121\n",
      "reconstruction loss = 0.0377, similarity loss: 0.2247\n",
      "Epoch 261, loss = 0.1312, time: 16.7381\n",
      "reconstruction loss = 0.0373, similarity loss: 0.2250\n",
      "Epoch 262, loss = 0.1400, time: 17.0261\n",
      "reconstruction loss = 0.0373, similarity loss: 0.2428\n",
      "Epoch 263, loss = 0.1289, time: 17.3219\n",
      "reconstruction loss = 0.0383, similarity loss: 0.2195\n",
      "Epoch 264, loss = 0.1222, time: 17.3308\n",
      "reconstruction loss = 0.0399, similarity loss: 0.2044\n",
      "Epoch 265, loss = 0.1353, time: 17.5649\n",
      "reconstruction loss = 0.0355, similarity loss: 0.2351\n",
      "Epoch 266, loss = 0.1181, time: 17.2990\n",
      "reconstruction loss = 0.0382, similarity loss: 0.1979\n",
      "Epoch 267, loss = 0.1365, time: 17.4036\n",
      "reconstruction loss = 0.0374, similarity loss: 0.2356\n",
      "Epoch 268, loss = 0.1357, time: 17.2515\n",
      "reconstruction loss = 0.0389, similarity loss: 0.2325\n",
      "Epoch 269, loss = 0.1543, time: 17.4177\n",
      "reconstruction loss = 0.0363, similarity loss: 0.2723\n",
      "Epoch 270, loss = 0.1181, time: 17.3261\n",
      "reconstruction loss = 0.0397, similarity loss: 0.1966\n",
      "Epoch 271, loss = 0.1204, time: 17.3636\n",
      "reconstruction loss = 0.0369, similarity loss: 0.2040\n",
      "Epoch 272, loss = 0.1362, time: 17.3020\n",
      "reconstruction loss = 0.0408, similarity loss: 0.2315\n",
      "Epoch 273, loss = 0.1375, time: 17.2252\n",
      "reconstruction loss = 0.0361, similarity loss: 0.2389\n",
      "Epoch 274, loss = 0.1151, time: 17.2700\n",
      "reconstruction loss = 0.0409, similarity loss: 0.1893\n",
      "Epoch 275, loss = 0.1260, time: 17.4532\n",
      "reconstruction loss = 0.0371, similarity loss: 0.2149\n",
      "Epoch 276, loss = 0.1245, time: 17.1640\n",
      "reconstruction loss = 0.0398, similarity loss: 0.2092\n",
      "Epoch 277, loss = 0.1420, time: 17.3891\n",
      "reconstruction loss = 0.0341, similarity loss: 0.2499\n",
      "Epoch 278, loss = 0.1177, time: 17.2284\n",
      "reconstruction loss = 0.0385, similarity loss: 0.1969\n",
      "Epoch 279, loss = 0.1268, time: 17.2316\n",
      "reconstruction loss = 0.0352, similarity loss: 0.2183\n",
      "Epoch 280, loss = 0.1383, time: 17.2909\n",
      "reconstruction loss = 0.0367, similarity loss: 0.2399\n",
      "Epoch 281, loss = 0.1277, time: 17.3061\n",
      "reconstruction loss = 0.0362, similarity loss: 0.2191\n",
      "Epoch 282, loss = 0.1375, time: 17.2998\n",
      "reconstruction loss = 0.0375, similarity loss: 0.2375\n",
      "Epoch 283, loss = 0.1257, time: 17.5494\n",
      "reconstruction loss = 0.0347, similarity loss: 0.2167\n",
      "Epoch 284, loss = 0.1235, time: 17.5521\n",
      "reconstruction loss = 0.0387, similarity loss: 0.2084\n",
      "Epoch 285, loss = 0.1301, time: 17.3632\n",
      "reconstruction loss = 0.0362, similarity loss: 0.2239\n",
      "Epoch 286, loss = 0.1295, time: 17.4218\n",
      "reconstruction loss = 0.0372, similarity loss: 0.2219\n",
      "Epoch 287, loss = 0.1243, time: 17.2989\n",
      "reconstruction loss = 0.0374, similarity loss: 0.2113\n",
      "Epoch 288, loss = 0.1248, time: 17.2801\n",
      "reconstruction loss = 0.0376, similarity loss: 0.2121\n",
      "Epoch 289, loss = 0.1332, time: 17.2961\n",
      "reconstruction loss = 0.0375, similarity loss: 0.2289\n",
      "Epoch 290, loss = 0.1418, time: 17.2781\n",
      "reconstruction loss = 0.0360, similarity loss: 0.2476\n",
      "Epoch 291, loss = 0.1207, time: 17.2783\n",
      "reconstruction loss = 0.0374, similarity loss: 0.2040\n",
      "Epoch 292, loss = 0.1220, time: 17.5014\n",
      "reconstruction loss = 0.0373, similarity loss: 0.2067\n",
      "Epoch 293, loss = 0.1257, time: 17.2525\n",
      "reconstruction loss = 0.0391, similarity loss: 0.2122\n",
      "Epoch 294, loss = 0.1291, time: 17.4887\n",
      "reconstruction loss = 0.0368, similarity loss: 0.2214\n",
      "Epoch 295, loss = 0.1219, time: 17.3711\n",
      "reconstruction loss = 0.0357, similarity loss: 0.2081\n",
      "Epoch 296, loss = 0.1392, time: 17.3118\n",
      "reconstruction loss = 0.0368, similarity loss: 0.2415\n",
      "Epoch 297, loss = 0.1167, time: 16.7335\n",
      "reconstruction loss = 0.0363, similarity loss: 0.1972\n",
      "Epoch 298, loss = 0.1144, time: 16.7036\n",
      "reconstruction loss = 0.0339, similarity loss: 0.1950\n",
      "Epoch 299, loss = 0.1150, time: 16.7062\n",
      "reconstruction loss = 0.0352, similarity loss: 0.1948\n",
      "Train Classifier\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (layer0): Sequential(\n",
      "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (activation): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (conv): Conv2d(64, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n",
      "Sequential(\n",
      "  (aux): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (fc): Linear(in_features=8192, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "CrossEntropyLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch 0, loss = 1.8462, val.acc = 0.5184\n",
      "Epoch 1, loss = 1.4774, val.acc = 0.5548\n",
      "Epoch 2, loss = 1.3590, val.acc = 0.5716\n",
      "Epoch 3, loss = 1.2912, val.acc = 0.5846\n",
      "Epoch 4, loss = 1.2445, val.acc = 0.5918\n",
      "Epoch 5, loss = 1.2089, val.acc = 0.5962\n",
      "Epoch 6, loss = 1.1799, val.acc = 0.6016\n",
      "Epoch 7, loss = 1.1554, val.acc = 0.6074\n",
      "Epoch 8, loss = 1.1339, val.acc = 0.6142\n",
      "Epoch 9, loss = 1.1148, val.acc = 0.6174\n",
      "Epoch 10, loss = 1.0975, val.acc = 0.6194\n",
      "Epoch 11, loss = 1.0817, val.acc = 0.6216\n",
      "Epoch 12, loss = 1.0670, val.acc = 0.6248\n",
      "Epoch 13, loss = 1.0534, val.acc = 0.6270\n",
      "Epoch 14, loss = 1.0406, val.acc = 0.6284\n",
      "Epoch 15, loss = 1.0286, val.acc = 0.6312\n",
      "Epoch 16, loss = 1.0172, val.acc = 0.6322\n",
      "Epoch 17, loss = 1.0064, val.acc = 0.6328\n",
      "Epoch 18, loss = 0.9961, val.acc = 0.6326\n",
      "Epoch 19, loss = 0.9863, val.acc = 0.6332\n",
      "Epoch 20, loss = 0.9769, val.acc = 0.6330\n",
      "Epoch 21, loss = 0.9678, val.acc = 0.6354\n",
      "Epoch 22, loss = 0.9591, val.acc = 0.6368\n",
      "Epoch 23, loss = 0.9508, val.acc = 0.6354\n",
      "Epoch 24, loss = 0.9427, val.acc = 0.6362\n",
      "Epoch 25, loss = 0.9349, val.acc = 0.6370\n",
      "Epoch 26, loss = 0.9273, val.acc = 0.6376\n",
      "Epoch 27, loss = 0.9200, val.acc = 0.6380\n",
      "Epoch 28, loss = 0.9129, val.acc = 0.6382\n",
      "Epoch 29, loss = 0.9060, val.acc = 0.6392\n",
      "Epoch 30, loss = 0.8994, val.acc = 0.6392\n",
      "Epoch 31, loss = 0.8929, val.acc = 0.6398\n",
      "Epoch 32, loss = 0.8866, val.acc = 0.6406\n",
      "Epoch 33, loss = 0.8805, val.acc = 0.6408\n",
      "Epoch 34, loss = 0.8745, val.acc = 0.6410\n",
      "Epoch 35, loss = 0.8686, val.acc = 0.6410\n",
      "Epoch 36, loss = 0.8628, val.acc = 0.6400\n",
      "Epoch 37, loss = 0.8572, val.acc = 0.6404\n",
      "Epoch 38, loss = 0.8516, val.acc = 0.6398\n",
      "Epoch 39, loss = 0.8461, val.acc = 0.6390\n",
      "Epoch 40, loss = 0.8407, val.acc = 0.6390\n",
      "Epoch 41, loss = 0.8355, val.acc = 0.6386\n",
      "Epoch 42, loss = 0.8303, val.acc = 0.6390\n",
      "Epoch 43, loss = 0.8252, val.acc = 0.6402\n",
      "Epoch 44, loss = 0.8203, val.acc = 0.6398\n",
      "Epoch 45, loss = 0.8154, val.acc = 0.6410\n",
      "Epoch 46, loss = 0.8107, val.acc = 0.6406\n",
      "Epoch 47, loss = 0.8060, val.acc = 0.6416\n",
      "Epoch 48, loss = 0.8014, val.acc = 0.6418\n",
      "Epoch 49, loss = 0.7969, val.acc = 0.6406\n",
      "Epoch 50, loss = 0.7925, val.acc = 0.6400\n",
      "Epoch 51, loss = 0.7882, val.acc = 0.6404\n",
      "Epoch 52, loss = 0.7839, val.acc = 0.6404\n",
      "Epoch 53, loss = 0.7797, val.acc = 0.6408\n",
      "Epoch 54, loss = 0.7756, val.acc = 0.6416\n",
      "Epoch 55, loss = 0.7715, val.acc = 0.6420\n",
      "Epoch 56, loss = 0.7675, val.acc = 0.6418\n",
      "Epoch 57, loss = 0.7636, val.acc = 0.6420\n",
      "Epoch 58, loss = 0.7597, val.acc = 0.6414\n",
      "Epoch 59, loss = 0.7559, val.acc = 0.6410\n",
      "Epoch 60, loss = 0.7521, val.acc = 0.6398\n",
      "Epoch 61, loss = 0.7484, val.acc = 0.6404\n",
      "Epoch 62, loss = 0.7447, val.acc = 0.6394\n",
      "Epoch 63, loss = 0.7411, val.acc = 0.6396\n",
      "Epoch 64, loss = 0.7376, val.acc = 0.6396\n",
      "Epoch 65, loss = 0.7340, val.acc = 0.6394\n",
      "Epoch 66, loss = 0.7306, val.acc = 0.6396\n",
      "Epoch 67, loss = 0.7271, val.acc = 0.6390\n",
      "Epoch 68, loss = 0.7238, val.acc = 0.6384\n",
      "Epoch 69, loss = 0.7204, val.acc = 0.6384\n",
      "Epoch 70, loss = 0.7171, val.acc = 0.6384\n",
      "Epoch 71, loss = 0.7139, val.acc = 0.6390\n",
      "Epoch 72, loss = 0.7107, val.acc = 0.6388\n",
      "Epoch 73, loss = 0.7075, val.acc = 0.6392\n",
      "Epoch 74, loss = 0.7044, val.acc = 0.6392\n",
      "Epoch 75, loss = 0.7013, val.acc = 0.6392\n",
      "Epoch 76, loss = 0.6983, val.acc = 0.6398\n",
      "Epoch 77, loss = 0.6953, val.acc = 0.6394\n",
      "Epoch 78, loss = 0.6923, val.acc = 0.6388\n",
      "Epoch 79, loss = 0.6893, val.acc = 0.6386\n",
      "Epoch 80, loss = 0.6864, val.acc = 0.6380\n",
      "Epoch 81, loss = 0.6836, val.acc = 0.6378\n",
      "Epoch 82, loss = 0.6807, val.acc = 0.6372\n",
      "Epoch 83, loss = 0.6779, val.acc = 0.6376\n",
      "Epoch 84, loss = 0.6751, val.acc = 0.6370\n",
      "Epoch 85, loss = 0.6724, val.acc = 0.6368\n",
      "Epoch 86, loss = 0.6697, val.acc = 0.6364\n",
      "Epoch 87, loss = 0.6670, val.acc = 0.6368\n",
      "Epoch 88, loss = 0.6644, val.acc = 0.6366\n",
      "Epoch 89, loss = 0.6617, val.acc = 0.6374\n",
      "Epoch 90, loss = 0.6591, val.acc = 0.6374\n",
      "Epoch 91, loss = 0.6566, val.acc = 0.6362\n",
      "Epoch 92, loss = 0.6541, val.acc = 0.6360\n",
      "Epoch 93, loss = 0.6516, val.acc = 0.6356\n",
      "Epoch 94, loss = 0.6491, val.acc = 0.6354\n",
      "Epoch 95, loss = 0.6466, val.acc = 0.6350\n",
      "Epoch 96, loss = 0.6442, val.acc = 0.6346\n",
      "Epoch 97, loss = 0.6418, val.acc = 0.6346\n",
      "Epoch 98, loss = 0.6395, val.acc = 0.6348\n",
      "Epoch 99, loss = 0.6371, val.acc = 0.6350\n",
      "Rep: 1, te.acc = 0.6322\n",
      "\n",
      "All reps test.acc:\n",
      "[0.6322]\n"
     ]
    }
   ],
   "source": [
    "vis = visdom.Visdom(port=8097,env='lam_0_5')\n",
    "train_unsupervised_ae(pars,vis=vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- average reconstruction loss\n",
    "- reconstruction result\n",
    "- zero weight on BT\n",
    "- lambda from small to large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = PARS(device, datapath, savepath)\n",
    "pars.architecture = 'CONV6'\n",
    "pars.LR = 0.0001\n",
    "pars.clf_lr = 0.001\n",
    "pars.epochs = 300\n",
    "pars.clf_epochs = 100\n",
    "pars.nonlinear = 'hardtanh'\n",
    "pars.repeat = 1\n",
    "pars.loss = \"BarlowTwins\"\n",
    "pars.lam = 0.5\n",
    "print(pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BarlowTwinsLoss(pars.batch_size, pars.lam, pars.device)\n",
    "train_unsupervised(pars, criterion=criterion, clf_criterion=None, optimizer=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd034ed54560f0698c2946b7ca675e493afbd7ee3c0ecf162ae3deac3cf4477b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
